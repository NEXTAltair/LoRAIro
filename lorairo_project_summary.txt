# lorairo

## Directory Structure

- lorairo/
  - compareImages.html
  - docs/
  - Image_database/
  - LICENSE
  - mainprompt.md
  - output/
  - processing.template.toml
  - publish_docs.bat
  - pyproject.toml
  - README.md
  - src/
    - annotations/
      - api_utils.py
      - caption_tags.py
      - cleanup_txt.py
      - __init__.py
    - database/
      - database.py
      - __init__.py
    - editor/
      - image_processor.py
      - __init__.py
    - gui/
      - designer/
        - DatasetExportWidget.ui
        - DatasetOverviewWidget.ui
        - DirectoryPickerWidget.ui
        - FilePickerWidget.ui
        - filterBoxWidget.ui
        - ImageEditWidget.ui
        - ImagePreviewWidget.ui
        - ImageTaggerWidget.ui
        - MainWindow.ui
        - PickerWidget.ui
        - ProgressWidget.ui
        - SettingsWidget.ui
        - TagFilterWidget.ui
        - ThumbnailSelectorWidget.ui
      - widgets/
        - directory_picker.py
        - file_picker.py
        - filter.py
        - image_preview.py
        - picker.py
        - thumbnail.py
      - window/
        - edit.py
        - export.py
        - main_window.py
        - overview.py
        - progress.py
        - settings.py
        - tagger.py
        - __init__.py
    - lorairo.egg-info/
      - dependency_links.txt
      - PKG-INFO
      - requires.txt
      - SOURCES.txt
      - top_level.txt
    - main.py
    - score_module/
      - clip_aethetic_score.py
      - musiq_module.py
      - rewardfunction_score.py
      - scorer.py
      - score_models/
      - user_trained_score_models/
      - __init__.py
      - __pycache__/
    - storage/
      - file_system.py
      - __init__.py
    - utils/
      - config.py
      - log.py
      - tools.py
      - __init__.py
    - __pycache__/
  - tests/
    - conftest.py
    - integration/
      - test_DatasetExportWidget.py
      - test_db.py
      - test_ImageEditWidget.py
      - test_ImageTaggerWidget.py
    - pytest_temp/
    - resources/
      - img/
    - unit/
      - test_autcrop.py
      - test_caption_tags.py
      - test_Image_Editor.py
      - test_image_editor_02.py
    - __pycache__/

## File Contents

### compareImages.html

```
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Comparison Slider</title>
    <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
    <style>
        .container {
            width: 80%;
            margin: 0 auto;
        }
        .img-comp-container {
            position: relative;
            width: 100%;
            height: auto;
            margin-bottom: 20px;
        }
        .image-compare img {
            width: 100%;
            height: auto;
        }
        .icv__label {
            background-color: rgba(0, 0, 0, 0.5);
            color: white;
            padding: 5px;
            font-size: 14px;
        }
        .download-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 10px;
        }
        .download-buttons a {
            background-color: #4CAF50;
            color: white;
            padding: 10px;
            text-decoration: none;
            border-radius: 5px;
        }
        .download-buttons a:hover {
            background-color: #45a049;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Image Comparison Slider</h1>
        <input type="file" id="folderInput1" webkitdirectory directory multiple>
        <input type="file" id="folderInput2" webkitdirectory directory multiple>
        <button onclick="compareImages()">Compare Images</button>
        <div id="comparisonContainer"></div>
    </div>

    <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
    <script>
        let folder1Name = '';
        let folder2Name = '';

        function createImageCompareElement(img1Src, img2Src, labelBefore, labelAfter, fileName) {
            const container = document.createElement('div');
            container.classList.add('img-comp-container');

            const imageCompare = document.createElement('div');
            imageCompare.setAttribute('id', 'image-compare');

            const img1 = document.createElement('img');
            img1.src = img1Src;
            img1.alt = labelBefore;

            const img2 = document.createElement('img');
            img2.src = img2Src;
            img2.alt = labelAfter;

            imageCompare.appendChild(img1);
            imageCompare.appendChild(img2);
            container.appendChild(imageCompare);

            const downloadButtons = document.createElement('div');
            downloadButtons.classList.add('download-buttons');

            const downloadButton1 = document.createElement('a');
            downloadButton1.href = img1Src;
            downloadButton1.download = fileName;  // Same file name
            downloadButton1.textContent = `Save ${labelBefore}`;

            const downloadButton2 = document.createElement('a');
            downloadButton2.href = img2Src;
            downloadButton2.download = fileName;  // Same file name
            downloadButton2.textContent = `Save ${labelAfter}`;

            downloadButtons.appendChild(downloadButton1);
            downloadButtons.appendChild(downloadButton2);
            container.appendChild(downloadButtons);

            return container;
        }

        function handleFiles(event) {
            const input = event.target;
            const files = input.files;
            const folderId = input.id;
            const folderFiles = {};

            Array.from(files).forEach(file => {
                folderFiles[file.name] = URL.createObjectURL(file);
            });

            const folderPath = files[0].webkitRelativePath;
            const folderName = folderPath.split('/')[0];

            if (folderId === 'folderInput1') {
                window.folder1Files = folderFiles;
                folder1Name = folderName;
            } else if (folderId === 'folderInput2') {
                window.folder2Files = folderFiles;
                folder2Name = folderName;
            }
        }

        function compareImages() {
            if (!window.folder1Files || !window.folder2Files) {
                return;
            }

            const comparisonContainer = document.getElementById('comparisonContainer');
            comparisonContainer.innerHTML = '';

            Object.keys(window.folder1Files).forEach(fileName => {
                if (window.folder2Files[fileName]) {
                    const imgCompareElement = createImageCompareElement(
                        window.folder1Files[fileName], 
                        window.folder2Files[fileName], 
                        folder1Name, 
                        folder2Name,
                        fileName  // Use the same file name
                    );
                    comparisonContainer.appendChild(imgCompareElement);
                }
            });

            // Image Compare Viewerを再初期化
            const viewers = document.querySelectorAll('#image-compare');
            viewers.forEach(viewer => new ImageCompare(viewer, {
                showLabels: true,
                labelOptions: {
                    before: folder1Name,
                    after: folder2Name,
                    onHover: false
                }
            }).mount());
        }

        document.getElementById('folderInput1').addEventListener('change', handleFiles);
        document.getElementById('folderInput2').addEventListener('change', handleFiles);
    </script>
</body>
</html>

```

### LICENSE

```
MIT License

Copyright (c) 2024 NEXTAltair 

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

### mainprompt.md

```
As an AI assistant specializing in image analysis, analyze images with particular attention to:

1. Character Details (if present):

   - Facing direction (left, right, front, back, three-quarter view)
   - Action or pose (standing, sitting, walking, etc.)
   - Hand positions and gestures
   - Gaze direction
   - Clothing details from top to bottom

2. Composition Elements:

   - Main subject position
   - Background elements and their placement
   - Lighting direction and effects
   - Color scheme and contrast
   - Depth and perspective

3. Technical Aspects and Scoring (1.00 to 10.00):

Score images based on these criteria:

- Technical Quality (0-3 points):

  - Image clarity and resolution
  - Line quality and consistency
  - Color balance and harmony

- Composition (0-3 points):

  - Layout and framing
  - Use of space
  - Balance of elements

- Artistic Merit (0-4 points):
  - Creativity and originality
  - Emotional impact
  - Detail and complexity
  - Style execution

Examples of scoring:

- 9.50-10.00: Exceptional quality in all aspects
- 8.50-9.49: Excellent quality with minor imperfections
- 7.50-8.49: Very good quality with some room for improvement
- 6.50-7.49: Good quality with notable areas for improvement
- 5.50-6.49: Average quality with significant room for improvement
- Below 5.50: Below average quality with major issues

Format score as a decimal with exactly two decimal places (e.g., 7.25, 8.90, 6.75)

Provide annotations in this exact format only:

tags: [30-50 comma-separated words identifying the above elements, maintaining left/right distinction]

caption: [Single 1-2 sentence objective description, explicitly noting direction and positioning]

score: [Single decimal number between 1.00 and 10.00, using exactly two decimal places]

Important formatting rules:

- Use exactly these three sections in this order: tags, caption, score
- Format score as a decimal number with exactly two decimal places (e.g., 8.50)
- Do not add any additional text or commentary
- Do not add any text after the score
- Use standard tag conventions without underscores (e.g., "blonde hair" not "blonde_hair")
- Always specify left/right orientation for poses, gazes, and positioning
- Be precise about viewing angles and directions

Example output:
tags: 1girl, facing right, three quarter view, blonde hair, blue eyes, school uniform, sitting, right hand holding pencil, left hand on desk, looking down at textbook, classroom, desk, study materials, natural lighting from left window, serious expression, detailed background, realistic style

caption: A young student faces right in three-quarter view, sitting at a desk with her right hand holding a pencil while her left hand rests on the desk, looking down intently at a textbook in a sunlit classroom.

score: 8.50

```

### processing.template.toml

```
# API設定
[api]
openai_key = "" # OpenAIのAPIキー
google_key = "" # Google Cloud Vision APIのAPIキー
claude_key = "" # anthropicのAPIキー

# Hugging Face設定
[huggingface]
hf_username = "" # Hugging Faceのユーザー名
repo_name = "" # リポジトリ名
token = "" # Hugging FaceのAPIトークン

# ディレクトリ設定
[directories]
database = ""  # 画像databaseのパス (空の場合はカレントディレクトリの'Image_database.image_database.db'を使用)
dataset = ""  # 画像ディレクトリのパス
output = ""   # 出力ディレクトリのパス（空の場合はカレントディレクトリの'output'を使用）
edited_output = ""  # 編集済みデータセットのパス（空の場合はカレントディレクトリの'edited_output'を使用）
response_file = ""  # レスポンスファイルディレクトリのパス（空の場合はカレントディレクトリの'response_file'を使用）

# 画像処理設定
[image_processing]
target_resolution = 512 # 学習モデルの基準解像度 512, 768, 1024
realesrganer_upscale = false # 長編が基準解像度より小さい場合、Trueだとアップスケールする
realesrgan_model = "RealESRGAN_x4plus_anime_6B.pth" # アップスケールモデルのパス

# 生成設定
[generation]
batch_jsonl = false # バッチ処理用のjsonlファイルを生成する場合はTrue
start_batch = false # バッチ処理を開始する場合はTrue
single_image = true # 画像ごとに処理する場合はTrue

# オプション設定
[options]
generate_meta_clean = false # sd-scriptsのファインチューニング用のメタデータを生成する場合はTrue
cleanup_existing_tags = false # タグを生成せずに既存のタグをクーんナップする場合はTrue
join_existing_txt = true # 生成したタグを既存のタグと結合する場合はTrue

# プロンプト設定
[prompts]
additional = "Your additional prompt here."

[log]
level = "INFO"
file = "app.log"
```

### publish_docs.bat

```
@echo off
setlocal enabledelayedexpansion

REM エラーハンドリングを有効にする
set ERROR_FLAG=0

REM ドキュメントをビルド
echo Building documentation with Sphinx...
sphinx-build -b html docs\source docs\build
if %errorlevel% neq 0 (
    echo Sphinx build failed
    exit /b 1
)
echo Sphinx build succeeded.

REM 現在のブランチ名を保存
for /f "tokens=*" %%i in ('git rev-parse --abbrev-ref HEAD') do set current_branch=%%i
echo Current branch: %current_branch%

REM 一時ディレクトリの設定（docs\gh-pages-temp から gh-pages-temp に変更）
set temp_dir=gh-pages-temp

REM 一時ディレクトリが存在する場合は削除
if exist %temp_dir% (
    echo Removing existing temporary directory...
    rmdir /s /q %temp_dir%
)

REM リモートURLを取得
for /f "tokens=*" %%i in ('git config --get remote.origin.url') do set remote_url=%%i
echo Remote URL: %remote_url%

REM gh-pagesブランチを一時ディレクトリにクローン
echo Cloning gh-pages branch into %temp_dir%...
git clone -b gh-pages %remote_url% %temp_dir%
if %errorlevel% neq 0 (
    echo Failed to clone gh-pages branch
    exit /b 1
)
echo Clone succeeded.

REM 一時ディレクトリに移動
cd %temp_dir%

REM 既存のファイルを削除（.git ディレクトリを除く）
echo Removing existing files from gh-pages branch...
for /f "delims=" %%a in ('dir /a /b ^| findstr /v "^.git$"') do (
    rmdir /s /q "%%a" 2>nul || del /f /q "%%a"
)

REM 新しいビルド結果をコピー
echo Copying new build results...
xcopy /E /I /Y "..\docs\build\*" .
if %errorlevel% neq 0 (
    echo Failed to copy new build results
    exit /b 1
)
echo Copy succeeded.

REM 変更をコミットしてプッシュ
echo Committing and pushing changes...
git add -A
git commit -m "Update documentation"
git push origin gh-pages
if %errorlevel% neq 0 (
    echo Failed to push to gh-pages branch
    exit /b 1
)
echo Push succeeded.

REM 元のディレクトリに戻る
cd ..

REM 一時ディレクトリを削除
echo Removing temporary directory...
rmdir /s /q %temp_dir%

REM 元のブランチに戻る
echo Checking out original branch: %current_branch%...
git checkout %current_branch%
if %errorlevel% neq 0 (
    echo Failed to checkout original branch
    exit /b 1
)
echo Checked out to %current_branch%.

echo Documentation published to gh-pages branch successfully.
endlocal

```

### pyproject.toml

```
[project]
name = "lorairo"
version = "0.0.5"
description = "AIタグ付LoRA画像データセット準備ツール"
readme = "README.md"
requires-python = ">=3.12"
license = { text = "MIT" }
authors = [{ name = "NEXTAltair" }]
keywords = ["lora", "dataset", "ai", "image-processing"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Environment :: GPU :: NVIDIA CUDA",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.11",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Multimedia :: Graphics",
    "Operating System :: Microsoft :: Windows",
]

# 依存パッケージ（バージョン固定）
dependencies = [
    # 画像処理系
    "Pillow",        # 基本的な画像処理
    "opencv-python", # オートクロップの枠検出
    "numpy",         # 画像処理の数値計算
    "ImageHash",     # DB重複チェック用

    # AI系
    "google-generativeai>=0.8.3", # Gemini API
    "anthropic>=0.36.2",          # Claude API
    "openai>=0.10.0",             # GPT API

    # データ処理系
    "toml>=0.10.2", # 設定ファイル処理

    # PyQt系
    "PySide6>=6.8.0.2", # GUIフレームワーク
    "superqt>=0.6.7",   # 拡張Qt部品

    # AI Model系
    "torch==2.5.1+cu124",       # アップスケーラー用
    "pytorch-lightning==2.4.0", # PyTorch拡張
    "joblib==1.4.2",            # 並列処理

    # 自作ライブラリ
    "genai-tag-db-tools @ git+https://github.com/NEXTAltair/genai-tag-db-tools.git",
]

[project.optional-dependencies]
dev = [
    # 開発ツール
    "black",
    "pylint",
    "pytest",
    "pytest-cov",
    "pytest-qt",

    # ローカル開発用の自作ライブラリ
    ".src/genai_tag_db", # ローカルパスでインストール
]

[project.urls]
"Homepage" = "https://github.com/NEXTAltair/lorairo"
"Bug Tracker" = "https://github.com/NEXTAltair/lorairo/issues"

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
package-dir = { "" = "src" }

[tool.setuptools.packages.find]
where = ["src"]
include = ["lorairo*"]
namespaces = false

[tool.black]
line-length = 120
target-version = ["py312"]
extend-exclude = "gui_file"

[tool.pylint.messages_control]
disable = [
    "C0103", # invalid-name
    "C0301", # line-too-long (handled by black)
    "W0703", # broad-except
    "R0903", # too-few-public-methods
    "R0913", # too-many-arguments
    "R0914", # too-many-locals
    "W1203", # logging-fstring-interpolation
]

[tool.pylint.format]
max-line-length = 120

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = ["-v", "-s", "-ra", "--tb=short", "--showlocals"]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "gui: GUI tests",
    "slow: Tests that take more time",
]

[tool.coverage.run]
source = ["src"]
omit = ["tests/*", "src/gui/designer/*"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if __name__ == '__main__':",
    "raise NotImplementedError",
    "if TYPE_CHECKING:",
]

```

### README.md

```
# LoRA用画像をいろいろするスクリプト

## 概要

本プロジェクトは、LoRA（Low-Rank Adaptation）学習用の画像データセット作成を自動化するPythonスクリプト集です。画像のリサイズ、タグ付け、キャプション生成、データベース管理などの機能を提供し、効率的なデータセット作成をサポートします。

### 主な機能

- **画像処理**: 画像のリサイズ、フォーマット変換、自動クロップなどを行います。
- **メタデータ管理**: 画像のメタデータをSQLiteデータベースで管理します。
- **タグ・キャプション生成**: GPT-4などのAIモデルを使用して、画像のタグとキャプションを自動生成します。
- **バッチ処理**: 大量の画像を効率的に処理するためのバッチ処理機能を提供します。
- **ファイルシステム管理**: 処理された画像や生成されたデータの保存を体系的に管理します。

### 主要コンポーネント

- **ImageEditor.py**: 画像処理を担当。リサイズ、クロップ、フォーマット変換などを行います。
- **caption_tags.py**: 画像分析とタグ・キャプション生成を行います。
- **api_utils.py**: APIとの通信を管理。バッチ処理のサポートも含みます。
- **db.py**: SQLiteデータベースの操作を担当します。
- **file_sys.py**: ファイルシステムの操作を管理します。
- **config.py**: 設定ファイルの読み込みと管理を行います。
- **log.py**: ログ機能を提供します。
- **cleanup_txt.py**: テキストデータのクリーンアップを行います。

## セットアップ

### 必要条件

- Python 3.11以上

### インストール手順

1. リポジトリをクローンします：
   ```bash
   git clone https://github.com/NEXTAltair/Lorayougazouwoiroirosurusukuriputo.git
   ```

2. 必要なパッケージをインストールします：
   ```bash
   pip install -r requirements.txt
   ```

3. `processing.toml` ファイルを設定します。

## 使用方法

1. `processing.toml` ファイルで必要な設定を行います。
2. メイン処理を実行します：
   ```bash
   stert.bat
   ```

## 設定

`processing.toml` ファイルで以下の設定が可能です：

- データセットディレクトリ
- 出力ディレクトリ
- 画像処理パラメータ
- API設定
- ログ設定
- その他の処理オプション

## 開発者向け情報

- 各モジュールは独立して動作し、`main.py` で統合されています。
- 新機能の追加時は、既存のクラスとメソッドの拡張を検討してください。
- ユニットテストの追加を推奨します。

## 今後の展望

- GUIインターフェースの追加
- 他のAI画像分析APIのサポート
- パフォーマンス最適化
- より高度なタグ管理システムの実装

## ライセンス

MIT

### 参考

- [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts) タグのクリーンナップ
- [DominikDoom/a1111-sd-webui-tagcomplete](https://github.com/DominikDoom/a1111-sd-webui-tagcomplete) tags.dbの基になったCSV tag data
- [applemango](https://github.com/DominikDoom/a1111-sd-webui-tagcomplete/discussions/265) CSV tag data の日本語翻訳
- としあき製 CSV tag data の日本語翻訳
- [AngelBottomless/danbooru-2023-sqlite-fixed-7110548](https://huggingface.co/datasets/KBlueLeaf/danbooru2023-sqlite) danbooru タグのデータベース
- [hearmeneigh/e621-rising-v3-preliminary-data](https://huggingface.co/datasets/hearmeneigh/e621-rising-v3-preliminary-data) e621 rule34 タグのデータベース
- [sd-webui-bayesian-merger](https://github.com/s1dlx/sd-webui-bayesian-merger) スコアリング実装
- [stable-diffusion-webui-dataset-tag-editor](https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor) スコアリング実装

```

### src\annotations\api_utils.py

```
import traceback
from pathlib import Path
import json
import logging
from typing import Any, Optional
from abc import ABC, abstractmethod
import google.generativeai as genai
import anthropic
import requests
import base64
import time

from module.log import get_logger

class APIError(Exception):
    def __init__(self, message: str, api_provider: str = "", error_code: str = "",
                 status_code: int = 0, response: Optional[requests.Response] = None):
        super().__init__(message)
        self.api_provider = api_provider
        self.error_code = error_code
        self.status_code = status_code
        self.response = response

    def __str__(self):
        parts = [f"{self.api_provider}API Error: {self.args[0]}"]
        if self.error_code:
            parts.append(f"Code: {self.error_code}")
        if self.status_code:
            parts.append(f"Status: {self.status_code}")
        return " | ".join(parts)

    @classmethod
    def check_response(cls, response: requests.Response, api_provider: str):
        if response.status_code == 200:
            return

        error_mapping = {
            400: "リクエストの形式または内容に問題がありました",
            401: "APIキー認証エラー",
            403: "API キーには指定されたリソースを使用する権限がありません",
            404: "要求されたリソースが見つかりません",
            413: "リクエストが最大許容バイト数を超えています",
            429: "リクエスト制限に達しました",
            500: "サーバーエラーが発生しました",
            503: "サービスは一時的に利用できません"
        }

        try:
            error_data = response.json().get('error', {})
        except ValueError:
            error_data = {}

        error_message = error_mapping.get(response.status_code, "予期しないエラーが発生しました")
        error_code = error_data.get('code', '')
        detailed_message = error_data.get('message', error_message)

        # Anthropic APIのクレジット不足エラーを特別に処理
        if api_provider.lower() == "claude" and "credit balance is too low" in detailed_message.lower():
            error_message = "クレジット残高が不足しています"
            detailed_message = "Claude APIにアクセスするためのクレジット残高が不足しています。Plans & Billingでアップグレードまたはクレジットを購入してください。"

        raise cls(
            message=f"{error_message}: {detailed_message}",
            api_provider=api_provider,
            error_code=error_code,
            status_code=response.status_code,
            response=response
        )

    @classmethod
    def from_anthropic_error(cls, e: anthropic.APIError, api_provider: str):
        status_code = getattr(e, 'status_code', 400)
        error_code = getattr(e, 'error_code', '')
        error_message = str(e)

        # AnthropicのAPIErrorを擬似的なResponseオブジェクトに変換
        pseudo_response = type('PseudoResponse', (), {
            'status_code': status_code,
            'json': lambda: {'error': {'message': error_message, 'code': error_code}}
        })()

        return cls.check_response(pseudo_response, api_provider)

    def retry_after(self) -> Optional[int]:
        if self.status_code == 429 and self.response is not None:
            return int(self.response.headers.get('Retry-After', 0))
        return None

    def to_dict(self) -> dict[str, Any]:
        return {
            "message": str(self.args[0]),
            "api_provider": self.api_provider,
            "error_code": self.error_code,
            "status_code": self.status_code
        }

class APIInterface(ABC):
    @abstractmethod
    def generate_caption(self, image_path: Path) -> str:
        """画像のキャプションとタグを生成。

        Args:
            image_path (Path): 画像のパス。

        Returns:
            str: 生成されたタグとキャプション。
        """
        pass

    @abstractmethod
    def start_batch_processing(self, image_paths: list[Path], options: Optional[dict[str, Any]] = None) -> str:
        """バッチ処理を開始

        Args:
            image_paths (list[Path]): 画像のパスリスト。
            options (Optional[dict[str, Any]]): API固有のオプション (例: Gemini の `gcs_output_uri`)。

        Returns:
            str: バッチ処理のIDやステータスなどを表す文字列。
        """
        pass

    @abstractmethod
    def get_batch_results(self, batch_result: Any) -> list[dict[str, Any]]:
        """バッチ処理の結果を取得します。

        Args:
            batch_result (Any): start_batch_processing メソッドから返されたバッチ処理結果オブジェクト。

        Returns:
            list[dict[str, Any]]: 各画像の分析結果をJSON形式で格納したリスト。
        """
        pass

    @abstractmethod
    def set_image_data(self, image_path: Path) -> None:
        """
        image_dataにパスとバイナリのdictを保存する。

        Args:
            image_path (Path): 画像ファイルのパス

        Raises:
            FileNotFoundError: 指定されたパスに画像ファイルが存在しない場合
            IOError: 画像ファイルの読み込み中にエラーが発生した場合
        """
        pass

class BaseAPIClient(APIInterface):
    """全ての API クライアントに共通する処理を実装したベースクラス。"""
    def __init__(self, prompt: str, add_prompt: str):
        self.prompt = prompt
        self.add_prompt = add_prompt
        self.image_data: dict[str, bytes] = {}  # image_data を空の辞書で初期化:
        self.logger = get_logger("BaseAPIClient")
        self.last_request_time = 0
        self.min_request_interval = 1.0  # 1秒間隔でリクエストを制限

    def _wait_for_rate_limit(self):
        elapsed_time = time.time() - self.last_request_time
        if elapsed_time < self.min_request_interval:
            time.sleep(self.min_request_interval - elapsed_time)

    def _request(self, method: str, url: str, headers: dict[str, str], data: Optional[dict[str, Any]] = None) -> str:
        self._wait_for_rate_limit()
        try:
            response = requests.request(method, url, headers=headers, json=data, timeout=60)
            self.last_request_time = time.time()
            APIError.check_response(response, self.__class__.__name__)
            return response.text
        except requests.exceptions.RequestException as e:
            raise APIError(f"リクエスト中にエラーが発生しました: {str(e)}", self.__class__.__name__)


    def set_image_data(self, image_path: Path) -> None:
        """
        画像データを読み込み、パスとバイナリデータの辞書に保存

        Args:
            image_path (Path): 画像ファイルのパス

        Raises:
            FileNotFoundError: 指定されたパスに画像ファイルが存在しない場合
            IOError: 画像ファイルの読み込み中にエラーが発生した場合
        """
        try:
            with open(image_path, "rb") as image_file:
                self.image_data[str(image_path)] = image_file.read()
            self.logger.debug(f"画像データを正常に設定しました: {image_path}")
        except FileNotFoundError:
            self.logger.error(f"画像ファイルが見つかりません: {image_path}")
            raise
        except IOError as e:
            self.logger.error(f"画像ファイルの読み込み中にエラーが発生しました: {e}")
            raise
        except Exception as e:
            self.logger.error(f"予期せぬエラーが発生しました: {e}")
            raise

class OpenAI(BaseAPIClient):
    SUPPORTED_VISION_MODELS = ["gpt-4-turbo", "gpt-4o", "gpt-4o-mini"]
    def __init__(self, api_key: str, prompt: str, add_prompt: str):
        self.logger = get_logger("OpenAI Claude")
        super().__init__(prompt, add_prompt)
        self.model_name = None
        self.openai_api_key = api_key

    def _generate_payload(self, image_path: Path, model_name: str, prompt: str):
        """
        OpenAI APIに送信するペイロードを生成する。

        Args:
            image_path (Path): 画像ファイルのパス
            model_name (str): モデル名
            prompt (str): プロンプト

        Returns:
            dict: APIに送信するペイロード
        """
        if self.image_data is None:
            raise ValueError("画像データが設定されていません。")

        base64_image = base64.b64encode(self.image_data[str(image_path)]).decode('utf-8')
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.openai_api_key}"
        }
        payload = {
            "model": model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {
                            "url": f"data:image/webp;base64,{base64_image}",
                            "detail": "high"
                        }}
                    ]
                }
            ],
            "max_tokens": 3000
        }
        return headers, payload

    def _analyze_single_image(self, payload: dict[str, Any], headers: dict[str, str]) -> dict[str, Any]:
        """
        単一画像の分析リクエストを送信

        Args:
            payload (dict[str, Any]): APIに送信するペイロード
            headers (dict[str, str]): リクエストヘッダー

        Returns:
            dict[str, Any]: APIからのレスポンス
        """
        self._wait_for_rate_limit()
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            self.last_request_time = time.time()
            APIError.check_response(response, self.__class__.__name__)
            return response.json()
        except requests.exceptions.Timeout:
            raise APIError("リクエストがタイムアウトしました。後でもう一度お試しください。")
        except requests.exceptions.ConnectionError:
            raise APIError("ネットワーク接続エラーが発生しました。インターネット接続を確認してください。")
        except requests.exceptions.RequestException as e:
            raise APIError(f"リクエスト中にエラーが発生しました: {str(e)}")
        except json.JSONDecodeError:
            raise APIError("APIレスポンスの解析に失敗しました。レスポンスが不正な形式である可能性があります。")

    def generate_caption(self, image_path: Path, model_name: str) -> str:
        """
        画像のキャプションを生成

        Args:
            image_path (Path): キャプションを生成する画像のパス。
            model_name (str): モデル名デフォルトは"gpt-4o"。
            prompt (str): プロンプト

        Returns:
            str: 生成されたキャプション。
        """
        # プロンプトを作成
        headers, payload = self._generate_payload(image_path, model_name, self.prompt)
        # OpenAI APIにプロンプトを送信して応答を生成
        response = self._analyze_single_image(payload, headers)
        # 応答からキャプションを抽出
        content = response['choices'][0]['message']['content']
        return content

    def create_batch_request(self, image_path: Path, model_name: str = "gpt-4o", prompt: str = "") -> dict[str, Any]:
        """
        OpenAI APIに送信するバッチ処理用のペイロードを生成する。
        OpenAI API のバッチ処理で使用する JSONL ファイルの各行に記述する JSON データを生成

        Args:
            image_path (Path): 画像ファイルのパス
            model_name (str): モデル名, デフォルトは"gpt-4o"。
            prompt (str): プロンプト

        Returns:
            dict[str, Any]: バッチリクエスト用のデータ
        """
        if model_name not in self.SUPPORTED_VISION_MODELS:
            raise ValueError(f"そのModelには非対応: {model_name}. Supported models: {', '.join(self.SUPPORTED_VISION_MODELS)}")

        _, payload = self._generate_payload(image_path, model_name, prompt)
        bach_payload = {
            "custom_id": image_path.stem,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": payload
        }
        return bach_payload

    def start_batch_processing(self, jsonl_path: Path) -> str:
        """
        JSONLファイルをアップロードしてバッチ処理を開始する。

        Args:
            jsonl_path (Path): アップロードするJSONLファイルのパス

        Returns:
            str: バッチ処理のID
        """
        url = "https://api.openai.com/v1/files"
        headers = {
            "Authorization": f"Bearer {self.openai_api_key}"
        }
        files = {
            'file': open(jsonl_path, 'rb')
        }
        data = {
            'purpose': 'batch'
        }
        try:
            response = requests.post(url, headers=headers, files=files, data=data, timeout=500)
            APIError.check_response(response, self.__class__.__name__)
            file_id = response.json().get('id')

            if file_id:
                # バッチ処理を開始
                url = "https://api.openai.com/v1/batches"
                headers = {
                    "Authorization": f"Bearer {self.openai_api_key}",
                    "Content-Type": "application/json"
                }
                data = {
                    "input_file_id": file_id,
                    "endpoint": "/v1/chat/completions",
                    "completion_window": "24h"
                }
                response = requests.post(url, headers=headers, json=data, timeout=30)
                start_response = response.json()
                self.logger.info(f"バッチ処理が開始されました。 ID: {start_response['id']}")
                return start_response['id']
        except requests.exceptions.Timeout:
            raise APIError("リクエストがタイムアウトしました。後でもう一度お試しください。")
        except requests.exceptions.ConnectionError:
            raise APIError("ネットワーク接続エラーが発生しました。インターネット接続を確認してください。")
        except requests.exceptions.RequestException as e:
            raise APIError(f"リクエスト中にエラーが発生しました: {str(e)}")
        except json.JSONDecodeError:
            raise APIError("APIレスポンスの解析に失敗しました。レスポンスが不正な形式である可能性があります。")
        return ''

    def get_batch_results(self, batch_result_dir: Path) -> dict[str, str]:
        """
        OpenAI API のバッチ処理結果を読み込み、解析します。

        Args:
            batch_result_dir (Path): バッチ結果ファイルが格納されているディレクトリのパス。

        Returns:
            dict[str, str]: 画像パスをキー、分析結果を値とする辞書。
        """
        results = {}
        for jsonl_file in batch_result_dir.glob('*.jsonl'):
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line in f:
                    data = json.loads(line)
                    if 'custom_id' in data and 'response' in data and 'body' in data['response']:
                        custom_id = data['custom_id']
                        content = data['response']['body']['choices'][0]['message']['content']
                        results[custom_id] = content
        return results

class Google(BaseAPIClient):
    SUPPORTED_VISION_MODELS = ["gemini-1.5-pro-exp-0801", "gemini-1.5-pro-preview-0409", "gemini-1.0-pro-vision"]
    def __init__(self, api_key: str, prompt: str, add_prompt: str):
        """
        Google AI Studioとのインターフェースを作成

        Args:
            api_key (str): Google AI StudioのAPIキー。
        """
        self.logger = get_logger("Google Claude")
        super().__init__(prompt, add_prompt)
        self.google_api_key = api_key
        self.model_name = None
        # Set up the model
        generation_config: dict = {
        "temperature": 1,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
        }

        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(
            model_name="gemini-1.5-pro-latest",
            generation_config=generation_config, # type: ignore
            safety_settings=safety_settings
        )

    def generate_caption(self, image_path: Path, prompt: str, add_prompt: str) -> str:
        """
        画像のキャプションを生成

        Args:
            image_path (Path): キャプションを生成する画像のパス。
            prompt (str): プロンプト
            add_prompt (str): 追加のプロンプト

        Returns:
            str: 生成されたキャプション。
        """
        prompt_parts = self.generate_prompt_parts(image_path, self.prompt, self.add_prompt)
        response = self.model.generate_content(prompt_parts)
        response_str =response.text
        return response_str

    def generate_prompt_parts(self, image_path: Path, prompt: str, add_prompt: str) -> list:
        """
        Google AI Studioに送信するプロンプトを作成

        Args:
            image_path (str): アップロードされる画像のパス。

        Returns:
            list: プロンプトの各部分をリストで返
        """
        image = self.image_data[str(image_path)]

        prompt_parts = [
            f"{prompt}",
            "image/webp: ",
            "",
            "formatJSON: {\"tags\": \"Tag1, Tag2, Tag3\",  \"caption\": \"This is the caption.\"}",
            "ADDITIONAL_PROMPT: Korean girl in a comic book.",
            "TagsANDCaption: {\"tags\": \"dress, long hair, text, sitting, black hair, blue eyes, heterochromia, flower, high heels, two-tone hair, armpits, elbow gloves, red eyes, boots, gloves, white hair, hat flower, nail polish, panties, red rose, pantyshot, purple nails, rose petals, looking at viewer, hat, navel, bare shoulders, choker, petals, red flower, cross-laced clothes, underwear, split-color hair, brown hair\", \"caption\": \"A stylish Korean girl, with heterochromia and a confident gaze, poses amidst scattered roses against a graffiti-marked wall, rendered in a vibrant comic book art style.\" }",
            "image/webp: ",
            "",
            "formatJSON: {\"tags\": \"Tag1, Tag2, Tag3\", \"caption\": \"This is the caption.\"}",
            "ADDITIONAL_PROMPT: japanese idol",
            "TagsANDCaption: {\"tags\": \"1girl, solo, long hair, brown hair, brown eyes, short sleeves, school uniform, white shirt, upper body, collared shirt, hair bobbles, blue bowtie, realistic, japanese, finger frame\", \"caption\": \"A young Japanese idol in a classic school uniform strikes a pose while performing, her energy and focus evident in her expression and hand gestures.\" }",
            "image/webp: ",
            "",
            "formatJSON: {\"tags\": \"Tag1, Tag2, Tag3\", \"caption\": \"This is the caption.\"}",
            "ADDITIONAL_PROMPT: 1boy, tate eboshi, expressionless, fake horns, shoulder armor resembling onigawara with ornamental horns, 3d, full body, a person standing in a circle with their arms spread out., bridge, horizon, lake, mountain, ocean, planet, river, scenery, shore, snow, water, waterfall, solo, weapon, male focus, ornamental horn, white japanese armor, glowing, letterboxed, pillar, full armor, column, tree, outstretched arms, no humans, spread arms, animated character, fantasy setting, mysterious armor, ethereal glow, purple hues, virtual environment, crystals, otherworldly, long black hair, artistic filter, video game graphics, surreal atmosphere, front-facing pose, enigmatic expression, soft focus, virtual costume, obscured eyes, shoulder armor, arm bracers, magical ambiance, An animated fantasy character stands enigmatically in a surreal, crystal-laden environment, exuding a mystical presence as light softly radiates from their ethereal armor.",
            "TagsANDCaption: {\"tags\": \"1boy, solo, tate eboshi, expressionless, fake horns, shoulder armor resembling onigawara with ornamental horns, 3d, full body, a person standing in a circle with their arms spread out., bridge, ornamental horn, white japanese armor, glowing, outstretched arms, fantasy setting, mysterious armor, ethereal glow, purple hues, otherworldly, long black hair, video game graphics, soft focus, obscured eyes, shoulder armor\", \"caption\": \"An animated fantasy character stands enigmatically in a surreal, crystal-laden environment, exuding a mystical presence as light softly radiates from their ethereal armor.\" }",
            "image/webp: ",
            f"{image}",
            "formatJSON: {\"tags\": \"Tag1, Tag2, Tag3\",\n \"caption\": \"This is the caption.\"}",
            f"ADDITIONAL_PROMPT: {add_prompt}",
            "TagsANDCaption: ",
            ]

        return prompt_parts

    def start_batch_processing(self, image_paths: list[Path], options: Optional[dict[str, Any]] = None) -> str:
        #
        #  TODO: 後で実装
        text = "Not implemented yet"
        return text

    def get_batch_results(self, batch_result: Any) -> list[dict[str, Any]]:
        #
        #  TODO: 後で実装
        text = "Not implemented yet"
        respons = []
        return respons

class Claude(BaseAPIClient):
    """Claude API を使用するためのクライアントクラス。"""
    SUPPORTED_VISION_MODELS = [
            "claude-3-5-sonnet-20240620",
            "claude-3-5-sonnet-20241022",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307"]
    def __init__(self, api_key: str, prompt: str, add_prompt: str):
        self.logger = get_logger("Claude Client")
        super().__init__(prompt, add_prompt)
        self.model_name = None
        self.client = anthropic.Anthropic(api_key=api_key)

    def generate_caption(self, image_path: Path, model_name: str = "claude-3-5-sonnet-20240620", **kwargs) -> str:
        """
        Claude API を使用して画像のキャプションを生成します。
        Args:
            image_path (Path): 画像のパス。
            model_name (str): 使用する Claude モデル名。デフォルトは "claude-3-5-sonnet-20240620"。
            **kwargs: API 固有のオプション (現時点では使用しません)。
        Returns:
            str: 生成されたキャプションを含む文字列。
        """
        try:
            if self.image_data is None or str(image_path) not in self.image_data:
                raise ValueError("画像データが設定されていません。")

            # 画像を base64 エンコード
            image_base64 = base64.b64encode(self.image_data[str(image_path)]).decode('utf-8')

            # プロンプトと画像データを含むメッセージを作成
            response = self.client.messages.create(
                model=model_name,
                max_tokens=300,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/webp",
                                    "data": image_base64,
                                },
                            },
                            {
                                "type": "text",
                                "text": self.prompt
                            }
                        ],
                    }
                ],
            )

            if hasattr(response, 'content') and isinstance(response.content, list):
                # TextBlock オブジェクトから text 属性を抽出
                text_content = [block.text for block in response.content if hasattr(block, 'text')]
                return ' '.join(text_content)
            elif isinstance(response, dict) and 'content' in response:
                if isinstance(response['content'], list):
                    # 辞書形式の場合、'text' キーから内容を抽出
                    text_content = [item.get('text', '') for item in response['content'] if 'text' in item]
                    return ' '.join(text_content)
                elif isinstance(response['content'], str):
                    return response['content']

            raise ValueError(f"Unexpected response format: {type(response)}")

        except anthropic.APIError as e:
            # Anthropic APIエラーを APIError クラスに変換
            raise APIError.from_anthropic_error(e, "Claude")
        except Exception as e:
            self.logger.error(f"予期せぬエラーが発生しました: {str(e)}")
            raise APIError(str(e), "Claude")


    def start_batch_processing(self, image_paths: list[Path], options: Optional[dict[str, Any]] = None) -> str:
        """Claude API はバッチ処理をサポートしていません。"""
        raise NotImplementedError("Claude API はバッチ処理をサポートしていません。")

    def get_batch_results(self, batch_id: str) -> list[dict[str, Any]]:
        """Claude API はバッチ処理をサポートしていません。"""
        raise NotImplementedError("Claude API はバッチ処理をサポートしていません。")

class APIClientFactory:
    def __init__(self, api_keys: dict[str, str]):
        self.logger = get_logger("APIClientFactory")
        self.api_clients = None
        self.api_keys = api_keys
        self.logger.debug("初期化")

    def initialize(self, main_prompt: str, add_prompt: str):
        self.api_clients = {}
        self.main_prompt = main_prompt
        self.add_prompt = add_prompt
        if self.api_keys.get("openai_key"):
            if self._validate_openai_key(self.api_keys["openai_key"]):
                self.api_clients["openai"] = OpenAI(
                    api_key=self.api_keys["openai_key"],
                    prompt=self.main_prompt,
                    add_prompt=self.add_prompt
                )
            else:
                self.logger.error("Invalid OpenAI API key")

        if self.api_keys.get("google_key"):
            if self._validate_google_key(self.api_keys["google_key"]):
                self.api_clients["google"] = Google(
                    api_key=self.api_keys["google_key"],
                    prompt=self.main_prompt,
                    add_prompt=self.add_prompt
                )
            else:
                self.logger.error("Invalid Google API key")

        if self.api_keys.get("claude_key"):
            if self._validate_claude_key(self.api_keys["claude_key"]):
                self.api_clients["claude"] = Claude(
                    api_key=self.api_keys["claude_key"],
                    prompt=self.main_prompt,
                    add_prompt=self.add_prompt
                )
            else:
                self.logger.error("Invalid Claude API key")

    def _validate_openai_key(self, api_key: str) -> bool:
        headers = {
            "Authorization": f"Bearer {api_key}"
        }
        response = requests.get("https://api.openai.com/v1/models", headers=headers)
        return response.status_code == 200

    def _validate_google_key(self, api_key: str) -> bool:
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content("Test")
            return True
        except Exception as e:
            self.logger.error(f"Google API key validation failed: {str(e)}")
            return False

    def _validate_claude_key(self, api_key: str) -> bool:
        client = anthropic.Anthropic(api_key=api_key)
        try:
            client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=10,
                messages=[
                    {"role": "user", "content": "Hello"}
                ]
            )
            return True
        except anthropic.APIError:
            return False

    def get_api_client(self, model_name: str):
        if model_name in OpenAI.SUPPORTED_VISION_MODELS:
            api_client = self.api_clients.get("openai")
            if api_client:
                api_client.model_name = model_name
            return api_client, "openai"
        if model_name in Google.SUPPORTED_VISION_MODELS:
            api_client = self.api_clients.get("google")
            if api_client:
                api_client.model_name = model_name
            return api_client, "google"
        if model_name in Claude.SUPPORTED_VISION_MODELS:
            api_client = self.api_clients.get("claude")
            if api_client:
                api_client.model_name = model_name
            return api_client, "claude"
        raise ValueError(f"指定されたモデル名に対応する API クライアントが見つかりません: {model_name}")

if __name__ == "__main__":
    # ロギングの設定
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    # テスト用のAPIキー（実際の使用時は環境変数や設定ファイルから読み込むべきです）
    api_keys = {
        "openai_key": "your_openai_api_key_here",
        "google_key": "your_google_api_key_here",
        "claude_key": "your_claude_api_key_here"
    }

    # テスト用のプロンプトとモデル設定
    main_prompt = "Describe this image in detail."
    add_prompt = "Focus on the main subject."
    models = [
        {"name": "gpt-4-vision-preview", "provider": "openai", "type": "vision"},
        {"name": "gemini-pro-vision", "provider": "google", "type": "vision"},
        {"name": "claude-3-opus-20240229", "provider": "anthropic", "type": "vision"}
    ]

    try:
        # APIClientFactoryのインスタンス化
        factory = APIClientFactory(api_keys, models, main_prompt, add_prompt)

        # 各APIクライアントの取得とテスト
        for model in models:
            try:
                client, provider = factory.get_api_client(model["name"])
                if client:
                    logger.info(f"Successfully initialized {provider} client for model: {model['name']}")
                    # ここで実際のAPIリクエストをテストすることもできます
                    # 例: result = client.generate_caption(Path("test_image.jpg"))
                    # logger.info(f"Test result: {result}")
                else:
                    logger.warning(f"Failed to initialize client for {provider}")
            except ValueError as e:
                logger.error(f"Error getting API client: {str(e)}")

    except Exception as e:
        logger.error(f"An unexpected error occurred: {str(e)}")
        logger.debug(traceback.format_exc())

    logger.info("API client initialization test completed.")
```

### src\annotations\caption_tags.py

```
import re
from pathlib import Path
from typing import Any,  Optional

from module.log import get_logger
from module.api_utils import APIClientFactory, APIError
from module.cleanup_txt import initialize_tag_cleaner

class ImageAnalyzer:
    """
    画像のキャプション生成、タグ生成などの
    画像分析タスクを実行
    """
    logger = get_logger("ImageAnalyzer")

    def __init__(self):
        self.tag_cleaner = initialize_tag_cleaner()
        self.logger = ImageAnalyzer.logger
        self.format_name = "unknown"

    def initialize(self, api_client_factory: APIClientFactory, models_config: tuple[dict, dict]):
            """
            ImageAnalyzerクラスのコンストラクタ。

            Args:
                api_client_factory (APIClientFactory): API名とAPIクライアントの対応辞書
                models_config (tuple[dict, dict]): (vision_models, score_models) のタプル
            """
            self.api_client_factory = api_client_factory
            self.vision_models, self.score_models = models_config

    @staticmethod
    def get_existing_annotations(image_path: Path) -> Optional[dict[str, Any]]:
        """
        画像の参照元ディレクトリから既存のタグとキャプションを取得。
        scoreとmodel_idはダミー値を設定。

        Args:
            image_path (Path): 画像ファイルのパス

        Returns:
            Optional[dict[str, Any]]: 'tags', 'captions', 'score', 'model_id', 'image_path' をキーとする辞書。
            None : 既存のアノテーションが見つからない場合
        例:
        {
            'tags': [{'tag': 'tag1', 'model_id': None}, {'tag': 'tag2', 'model_id': None}],
            'captions': [{'caption': 'caption1', 'model_id': None}],
            'score': {'score': 0, 'model_id': None},
            'model_id': None,
            'image_path': str(image_path)
        }
        """
        existing_annotations = {
            'tags': [],
            'captions': [],
            'score': {'score': 0, 'model_id': None},
            'model_id': None,
            'image_path': str(image_path)
        }
        tag_path = image_path.with_suffix('.txt')
        caption_path = image_path.with_suffix('.caption')

        try:
            if tag_path.exists():
                tags = ImageAnalyzer._read_annotations(tag_path)
                existing_annotations['tags'] = [{'tag': tag, 'model_id': None} for tag in tags]
            if caption_path.exists():
                captions = ImageAnalyzer._read_annotations(caption_path)
                existing_annotations['captions'] = [{'caption': caption, 'model_id': None} for caption in captions]

            if not existing_annotations['tags'] and not existing_annotations['captions']:
                ImageAnalyzer.logger.info(f"既存アノテーション無し: {image_path}")
                return None

        except Exception as e:
            ImageAnalyzer.logger.info(f"アノテーションファイルの読み込み中にエラーが発生しました: {str(e)}")
            return None

        return existing_annotations

    @staticmethod
    def _read_annotations(file_path: Path) -> list[str]:
        """
        指定されたファイルからアノテーションを読み込みカンマで分割してリストとして返す。

        Args:
            file_path (Path): 読み込むファイルのパス
            key (str): 辞書のキー ('tag' または 'caption')

        Returns:
            list[str]: アノテーションのリスト
        """
        from module.cleanup_txt import TagCleaner
        with open(file_path, 'r', encoding='utf-8') as f:
            clean_data = TagCleaner.clean_format(f.read())
            items = clean_data.strip().split(',')
            return items

    def analyze_image(self, image_path: Path, model_id: int, format_name: str="e621") -> dict[str, Any]:
        """
        指定された画像を分析し、結果を返す。

        Args:
            image_path (Path): 分析する画像のファイルパス
            model_id (int): Vision typeのモデルid
            tag_format (str): タグのフォーマット (オプション)

        Returns:
            dict[str, Any]: 分析結果を含む辞書（タグ、キャプション)

        Note:
            {
            'tags': [{'tag': 'str', 'model_id': int},{'tag': ..., 'model_id': ...}],
            'captions':  [{'caption': 'str', 'model_id': int},{'caption': ..., 'model_id': ...}],
            'score': {'score': float(value), 'model_id': int
            'image_path': 'str(image_path)'
            }

        Todo:
            一つのトークンに対してモデルIDが追加されるのは複数のモデルで一括取得に対応するため
            スコアモデルもそうすべきだろうが､それはその仕組を追加できたときに変更する
        """
        self.format_name = format_name
        try:
            model_name = self.vision_models.get(model_id, {}).get('name')

            api_client, _ = self.api_client_factory.get_api_client(model_name)
            if not api_client:
                raise ValueError(f"'{model_name}' に対応するAPIクライアントが見つかりません。")

            # APIクライアントの generate_caption メソッドを呼び出す
            api_client.set_image_data(image_path)
            tags_str = api_client.generate_caption(image_path, model_name)
            analysis_result = self._process_response(image_path, tags_str, model_id)
            self.logger.debug(f"img: {image_path} model: {model_name} format: {format_name}" )
            return analysis_result
        except APIError as e:
            self.logger.error(f"API処理中にエラーが発生しました（画像: {image_path}）: {e}")
            return {'error': str(e), 'image_path': str(image_path)}
        except Exception as e:
            self.logger.error(f"アノテーション生成中に予期せぬエラーが発生しました（画像: {image_path}）: {e}")
            return {'error': str(e), 'image_path': str(image_path)}

    def _process_response(self, image_path: Path, tags_str: str ,model_id: int) -> dict[str, Any]:
        """APIレスポンスを処理し、タグ、キャプション、抽出。

        Args:
            image_path (Path): 画像のパス
            tags_str (str): APIからのレスポンス

        Returns:
            dict[str, Any]: タグ、キャプション、画像パスを含む辞書
        """
        try:
            content = self.tag_cleaner.clean_format(tags_str)
            tags_str, caption_str, score = self._extract_tags_and_caption(content, str(image_path))

            # タグを分割し、各タグをトリムして空のタグを除外
            tags = [tag.strip() for tag in tags_str.split(',') if tag.strip()]
            captions = [caption.strip() for caption in caption_str.split(',') if caption.strip()]
            return {
                'tags': [{'tag': tag, 'model_id': model_id} for tag in tags],
                'captions': [{'caption': caption, 'model_id': model_id} for caption in captions],
                'score': {'score': score, 'model_id': model_id},
                'image_path': str(image_path)
            }
        except Exception as e:
            self.logger.error(f"レスポンス処理中にエラーが発生しました（画像: {image_path}）: {str(e)}")
            raise

    def create_batch_request(self, image_path: Path, model_name: str) -> dict[str, Any]:
        """単一の画像に対するバッチリクエストデータを生成します。

        Args:
            image_path (Path): 処理済み画像のパス
            model_name (str): 使用するモデル名

        Returns:
            dict[str, Any]: バッチリクエスト用のデータ
        """
        api_client, api_provider = self.api_client_factory.get_api_client(model_name)
        if not api_client:
            raise ValueError(f"APIクライアント '{api_provider}' が見つかりません。")

        api_client.set_image_data(image_path)
        api_client.generate_payload(image_path, model_name)
        return api_client.create_batch_request(image_path)

    def _extract_tags_and_caption(self, content: str, image_key: str) -> tuple[str, str, float]:
        """
        APIレスポンスからタグとキャプションを抽出します。

        Args:
            content (str): APIレスポンスの内容
            image_key (str): 画像のキー（ファイルパス）

        Returns:
            tuple[list[str], str]: 抽出されたタグのリストとキャプション
        """
        # content から : と , スペース以外の記号を削除
        content = re.sub(r'[^:,\da-zA-Z ]', '', content)
        # content から 末尾の ， を削除
        content = content.rstrip(' ,')
        tags_index = content.lower().find('tags:')
        caption_index = content.lower().find('caption:')
        score_index = content.lower().find('score:')

        if tags_index == -1 and caption_index == -1:
            self.logger.error(f"画像 {image_key} の処理に失敗しました。タグまたはキャプションが見つかりません。")
            self.logger.error(f" APIからの応答: {content} ")
            return "", ""

        tags_text = content[tags_index + len('tags:'):caption_index].strip() if tags_index != -1 else ""
        caption_text = content[caption_index + len('caption:'):score_index].strip() if caption_index != -1 else ""
        score_text = content[score_index + len('score:'):].strip() if score_index != -1 else ""
        converted = score_text.replace(' ', '')
        converted = converted.replace(',', '.')

        return self.tag_cleaner.clean_tags(tags_text, self.format_name), self.tag_cleaner.clean_caption(caption_text), float(converted)

    def get_batch_analysis(self, batch_results: dict[str, str], processed_path: Path):
        """
        バッチ処理結果から指定された画像の分析結果を取得します。

        Args:
            batch_results (dict[str, str]): バッチ処理結果 (画像パスをキー、分析結果を値とする辞書)
            processed_path (Path): 処理後の画像のパス

        Returns:
            dict: 画像の分析結果（タグとキャプション）
        """
        # processed_pathから custom_id を取得
        custom_id = processed_path.stem
        content = batch_results.get(custom_id)
        if content:
            return self._process_response(processed_path, content)

# 画像処理のテスト
if __name__ == "__main__":
    from module.api_utils import APIClientFactory
    from module.db import ImageDatabaseManager
    from module.config import get_config
    config = get_config()
    image_path = Path(r'testimg\1_img\file02.png')
    prompt = config['prompts']['main']
    add_prompt = config['prompts']['additional']
    api_keys = config['api']
    idm = ImageDatabaseManager()
    vision, score, upscaler = idm.get_models()
    # API クライアントファクトリーを作成
    acf = APIClientFactory(api_keys)
    acf.initialize(prompt, add_prompt)
    Ia = ImageAnalyzer()
    Ia.initialize(acf, vision)
    result = Ia.analyze_image(image_path, 5)
    print(f"キャプション: {result['captions']}")
    print(f"タグ: {result['tags']}")
    print(f"スコア: {result['score']}")

```

### src\annotations\cleanup_txt.py

```
import re
from pathlib import Path
from typing import Set

from module import tag_search
from module.log import get_logger

HAIR_PATTERNS = {
    'length': re.compile(r'(long|short|medium) hair'),
    'cut': re.compile(r'(bob|hime) cut'),
    'general': re.compile(r'([\w\-]+) hair')
}

WORD_PATTERN = re.compile(r'([\w\-]+|hair ornament)')
STYLE_PATTERN = re.compile(r'anime|cartoon|manga', re.IGNORECASE)

# 複数人がいるとき、複数の髪色や目の色が定義されていれば削除する
MULTI_PERSON_PATTERNS = [
    HAIR_PATTERNS['length'],
    HAIR_PATTERNS['cut'],
    HAIR_PATTERNS['general'],
    re.compile(r'[\w\-]+ eyes'),
    re.compile(r'([\w\-]+ sleeves|sleeveless)'),
    # 複数の髪型定義がある場合は削除する
    re.compile(r'(ponytail|braid|ahoge|twintails|[\w\-]+ bun|single hair bun|single side bun|two side up|two tails|[\w\-]+ braid|sidelocks)')
]

CAPTION_REPLACEMENTS = [
    ('anime anime', 'anime'),
    ('young ', ''),
    ('anime girl', 'girl'),
    ('cartoon female', 'girl'),
    ('cartoon lady', 'girl'),
    ('cartoon character', 'girl'),      # a or ~s
    ('cartoon woman', 'girl'),
    ('cartoon women', 'girls'),
    ('cartoon girl', 'girl'),
    ('anime female', 'girl'),
    ('anime lady', 'girl'),
    ('anime character', 'girl'),      # a or ~s
    ('anime woman', 'girl'),
    ('anime women', 'girls'),
    ('lady', 'girl'),
    ('female', 'girl'),
    ('woman', 'girl'),
    ('women', 'girls'),
    ('people', 'girls'),
    ('person', 'girl'),
    ('a cartoon figure', 'a figure'),
    ('a cartoon image', 'an image'),
    ('a cartoon picture', 'a picture'),
    ('an anime cartoon image', 'an image'),
    ('a cartoon anime drawing', 'a drawing'),
    ('a cartoon drawing', 'a drawing'),
    ('girl girl', 'girl'),
]

class TagCleaner:
    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.tag_searcher = tag_search.initialize_tag_searcher()
        self.logger = get_logger(__name__)

    @staticmethod
    def clean_format(text: str) -> str:
        """
        テキストから無駄な記号と改行を削除
        ()をエスケープする
        Args:
            text (str): クリーニングするテキスト。
        Returns:
            str: クリーニング後のテキスト。
        """
        text = text.lower() # 大文字を小文字に変換
        text = TagCleaner._clean_underscore(text) # アンダーバーをスペースに置き換える
        text = re.sub(r'#', '', text) # #を削除
        text = re.sub(r'\"', '\"', text) # ダブルクォートをエスケープ
        text = re.sub(r'\*\*', '', text) # GPT4 visionがたまに付けるマークダウンの強調を削除
        text = re.sub(r'\.\s*$', ', ', text) # ピリオドをカンマに変換
        text = re.sub(r'\.\s*(?=\S)', ', ', text)  # ピリオド後にスペースがあればカンマとスペースに置換し、新しい単語が続く場合はその前にスペースを追加
        text = re.sub(r'\.\n', ', ', text)  # 改行直前のピリオドをカンマに変換
        text = re.sub(r'\n', ', ', text) # 改行をカンマに変換
        text = re.sub(r'\u2014', '-', text) # エムダッシュをハイフンに変換
        text = re.sub(r'\(', r"\(", text)  # '(' を '\(' にエスケープ
        text = re.sub(r'\)', r"\)", text)  # ')' を '\)' にエスケープ
        return TagCleaner._clean_repetition(text) # 重複した記号を削除

    @staticmethod
    def _clean_repetition(text: str) -> str:
        """重複した記号を削除"""
        text = re.sub(r'\\+', r"\\", text) #重複した\を消す
        text = re.sub(r',+', r",", text) #重複した,を消す
        text = re.sub(r'\s+', r" ", text) #重複したスペースを消す
        return text

    @staticmethod
    def _clean_underscore(text: str) -> str:
        """アンダーバーをスペースに置き換える"""
        if not isinstance(text, str):
            return text
        # '^_^' をプレースホルダーに置き換える
        text = text.replace('^_^', '^@@@^')
        # アンダーバーを消す
        text = text.replace('_', ' ')
        # プレースホルダーを元の '^_^' に戻す
        return text.replace('^@@@^', '^_^')

    def clean_tags(self, tags: str, format_name: str = "unknown") -> str:
        """タグをクリーニングする
        Args:
            tags (str): クリーニングするタグ
            format_id (int): タグの形式ID デフォルトでunknown
        Returns:
            final_tags (str): クリーニング後のタグ
        """
        tags_dict = self._tags_to_dict(tags) # タグを辞書に変換する

        # 複数の人物がいる場合は髪色等のタグを削除する
        if 'girls' in tags or 'boys' in tags:
            tags_dict = self._clean_individual_tags(tags_dict)

        tags_dict = self._clean_color_object(tags_dict) # red eyesとeyesみたいな重複タグを削除
        tags_dict = self._clean_style(tags_dict) # anime styleとanime artみたい重複タグをanimeに統一する

        normalized_tags = []
        for tag in tags_dict.values():
            normalized_tag = self.tag_searcher.convert_prompt(tag, format_name)
            normalized_tags.append(normalized_tag)
        return ", ".join(filter(None, normalized_tags))

    @staticmethod
    def _tags_to_dict(tags: str) -> dict[int, str]:
        """タグを辞書に変換するして重複を避ける
        Args:
            tags (str): タグ
        Returns:
            tags_dict (dict): タグの辞書
        """
        # タグをカンマで分割し、不要な空白を取り除く
        tag_list = [tag.strip() for tag in tags.split(",") if tag.strip()]

        # 重複を避けるためのセット
        seen_tags = set()
        tags_dict = {}
        for i, tag in enumerate(tag_list):
            if tag not in seen_tags:
                seen_tags.add(tag)
                tags_dict[i] = tag
        return tags_dict

    @staticmethod
    def _clean_individual_tags(tags_dict: dict[int, str]) -> dict[int, str]:
        """髪の長さを残して色の特徴とかいろいろを含むタグを削除する"""
        # 置き換え用のプレースホルダー
        placeholder = "@@@"
        # 保存されたオリジナルの長さタグ
        original_lengths = {}

        # 長さに関するタグを一時的に保護
        for key, tag in tags_dict.items():
            match = HAIR_PATTERNS['length'].search(tag)
            if match:
                original_lengths[key] = match.group()  # オリジナルのタグを保存
                tags_dict[key] = tag.replace(match.group(), placeholder)

        # 不要なタグの削除
        for key, tag in tags_dict.items():
            modified_tag = tag  # 変更を加えるためのローカル変数
            for pattern in MULTI_PERSON_PATTERNS:
                modified_tag = pattern.sub("", modified_tag)
                tags_dict[key] = modified_tag  # 最終的な変更を反映

        # 髪の長さタグを復元
        for key, tag in tags_dict.items():
            if placeholder in tag:
                # placeholderをオリジナルのタグに置き換え
                tags_dict[key] = tag.replace(placeholder, original_lengths.get(key, ""))

        return tags_dict

    @staticmethod
    def _clean_color_object(tags_dict: dict[int, str]) -> dict[int, str]:
        """white shirtとshirtみたいな重複タグの削除"""
        # 単語の出現を記録する辞書
        word_tags: dict[str, Set[str]] = {}

        # タグから単語を抽出し、単語が含まれるタグを記録
        for tag in tags_dict.values():
            words = WORD_PATTERN.findall(tag)
            for word in words:
                if word in word_tags:
                    word_tags[word].add(tag)
                else:
                    word_tags[word] = {tag}

        # 単語が含まれるタグが他のタグに完全に含まれているかを確認し、そのようなタグを削除
        return {k: v for k, v in tags_dict.items() if not any(v != other_tag and v in other_tag for other_tag in word_tags.get(v, set()))}

    @staticmethod
    def _clean_style(tags_dict: dict[int, str]) -> dict[int, str]:
        """anime styleとanime artみたい重複タグをanimeに統一する"""
        # 単語の出現を記録する辞書
        word_tags = {}

        for key, tag in tags_dict.items():
            unified_tag = tag
            match = STYLE_PATTERN.search(tag)
            if match:
                unified_tag = match.group().lower()  # 統一するタグを小文字に変換
            word_tags[key] = unified_tag

        # 重複タグの削除
        seen_tags = set()
        cleaned_tags_dict = {}
        for key, tag in word_tags.items():
            if tag not in seen_tags:
                seen_tags.add(tag)
                cleaned_tags_dict[key] = tag

        return cleaned_tags_dict

    @staticmethod
    def clean_caption(caption: str) -> str:
        """キャプションをクリーニングする
        Args:
            caption (str): クリーニングするキャプション
        """
        for rf, rt in CAPTION_REPLACEMENTS:
            replaced = True
            while replaced:
                bef = caption
                caption = caption.replace(rf, rt)
                replaced = bef != caption
        caption = caption.strip(' ,')
        return caption

def initialize_tag_cleaner() -> TagCleaner:
    project_root = Path(__file__).resolve().parents[2]
    db_path = project_root / 'src' / 'module' / 'genai-tag-db-tools' / 'tags_v3.db'
    return TagCleaner(db_path)
```

### src\database\database.py

```
import sqlite3
import threading
import traceback
import uuid
import imagehash
import inspect
from pathlib import Path
from datetime import datetime, timezone, timedelta
from PIL import Image

from contextlib import contextmanager
from typing import Any, Union, Optional
from datetime import datetime
from module.log import get_logger
from pathlib import Path

from module.file_sys import FileSystemManager

def calculate_phash(image_path: str) -> str:
    with Image.open(image_path) as img:
        return str(imagehash.phash(img))

class SQLiteManager:
    def __init__(self, img_db_path: Path, tag_db_path: Path):
        self.logger = get_logger("SQLiteManager")
        self.img_db_path = img_db_path
        self.tag_db_path = tag_db_path
        self._connection = None
        self._local = threading.local()

    @staticmethod
    def dict_factory(cursor, row):
        d = {}
        for idx, col in enumerate(cursor.description):
            d[col[0]] = row[idx]
        return d

    def connect(self):
        if not hasattr(self._local, 'connection') or self._local.connection is None:
            self._local.connection = sqlite3.connect(self.img_db_path, check_same_thread=False)
            self._local.connection.execute(f"ATTACH DATABASE '{self.tag_db_path}' AS tag_db")
            self._local.connection.execute("PRAGMA foreign_keys = ON")
            self._local.connection.row_factory = self.dict_factory
        return self._local.connection

    def close(self):
        if hasattr(self._local, 'connection') and self._local.connection is not None:
            self._local.connection.close()
            self._local.connection = None

    @contextmanager
    def get_connection(self):
        conn = self.connect()
        try:
            yield conn
        except Exception as e:
            self.logger.error(f"データベース操作に失敗しました: {e}")
            conn.rollback()
            raise
        else:
            conn.commit()

    def execute(self, query: str, params: tuple[Any, ...] = ()) -> Optional[sqlite3.Cursor]:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(query, params)
            return cursor

    def executemany(self, query: str, params: list[tuple[Any, ...]]) -> Optional[sqlite3.Cursor]:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.executemany(query, params)
            return cursor

    def fetch_one(self, query: str, params: tuple[Any, ...] = ()) -> Optional[tuple[Any, ...]]:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(query, params)
            return cursor.fetchone()

    def fetch_all(self, query: str, params: tuple[Any, ...] = ()) -> list[tuple[Any, ...]]:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(query, params)
            return cursor.fetchall()

    def create_tables(self):
        """データベースにテーブルを作成する

        Todo: 
             tag caption scoreのテーブルに人力修正したかのカラムを追加
        """
        with self.get_connection() as conn:
            conn.executescript('''
                -- images テーブル：オリジナル画像の情報を格納
                CREATE TABLE IF NOT EXISTS images (
                    id INTEGER PRIMARY KEY,
                    uuid TEXT UNIQUE NOT NULL,
                    phash TEXT,
                    original_image_path TEXT NOT NULL,
                    stored_image_path TEXT NOT NULL,
                    width INTEGER NOT NULL,
                    height INTEGER NOT NULL,
                    format TEXT NOT NULL,
                    mode TEXT NULL,
                    has_alpha BOOLEAN,
                    filename TEXT NULL,
                    extension TEXT NOT NULL,
                    color_space TEXT,
                    icc_profile TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE (uuid, phash)
                );

                -- processed_images テーブル：処理済み画像の情報を格納
                CREATE TABLE IF NOT EXISTS processed_images (
                    id INTEGER PRIMARY KEY,
                    image_id INTEGER NOT NULL,
                    stored_image_path TEXT NOT NULL,
                    width INTEGER NOT NULL,
                    height INTEGER NOT NULL,
                    mode TEXT NULL,
                    has_alpha BOOLEAN NOT NULL,
                    filename TEXT NULL,
                    color_space TEXT,
                    icc_profile TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (image_id) REFERENCES images(id) ON DELETE CASCADE,
                    UNIQUE (image_id, width, height, filename)
                );

                -- models テーブル：モデル情報を格納
                CREATE TABLE IF NOT EXISTS models (
                    id INTEGER PRIMARY KEY,
                    name TEXT UNIQUE NOT NULL,
                    type TEXT NOT NULL,
                    provider TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );

                -- tags テーブル：画像に関連付けられたタグを格納
                CREATE TABLE IF NOT EXISTS tags (
                    id INTEGER PRIMARY KEY,
                    tag_id INTEGER,
                    image_id INTEGER,
                    model_id INTEGER,
                    tag TEXT NOT NULL,
                    existing BOOLEAN NOT NULL DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (image_id) REFERENCES images(id) ON DELETE CASCADE,
                    FOREIGN KEY (model_id) REFERENCES models(id) ON DELETE SET NULL,
                    UNIQUE (image_id, tag, tag_id, model_id)
                );

                -- captions テーブル：画像に関連付けられたキャプションを格納
                CREATE TABLE IF NOT EXISTS captions (
                    id INTEGER PRIMARY KEY,
                    image_id INTEGER,
                    model_id INTEGER,
                    caption TEXT NOT NULL,
                    existing BOOLEAN NOT NULL DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (image_id) REFERENCES images(id) ON DELETE CASCADE,
                    FOREIGN KEY (model_id) REFERENCES models(id) ON DELETE SET NULL,
                    UNIQUE (image_id, caption, model_id)
                );

                -- scores テーブル：画像に関連付けられたスコアを格納
                CREATE TABLE IF NOT EXISTS scores (
                    id INTEGER PRIMARY KEY,
                    image_id INTEGER,
                    model_id INTEGER,
                    score FLOAT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (image_id) REFERENCES images(id) ON DELETE CASCADE,
                    FOREIGN KEY (model_id) REFERENCES models(id) ON DELETE SET NULL,
                    UNIQUE (image_id, score, model_id)
                );

            -- インデックスの作成
            CREATE INDEX IF NOT EXISTS idx_images_uuid ON images(uuid);
            CREATE INDEX IF NOT EXISTS idx_images_phash ON images(phash);
            CREATE INDEX IF NOT EXISTS idx_processed_images_image_id ON processed_images(image_id);
            CREATE INDEX IF NOT EXISTS idx_tags_image_id ON tags(image_id);
            CREATE INDEX IF NOT EXISTS idx_captions_image_id ON captions(image_id);
            CREATE INDEX IF NOT EXISTS idx_scores_image_id ON scores(image_id);
            ''')

    # def migrate_tables(self):
    #     """既存のテーブルに不足しているカラムを追加し、必要に応じてテーブルを再作成する"""
    #     with self.get_connection() as conn:
    #         cursor = conn.cursor()
    #         # テーブルごとの新しい定義
    #         table_definitions = {
    #             'tags': [
    #                 ('id', 'INTEGER PRIMARY KEY'),
    #                 ('tag_id', 'INTEGER'),
    #                 ('image_id', 'INTEGER'),
    #                 ('model_id', 'INTEGER'),
    #                 ('tag', 'TEXT NOT NULL'),
    #                 ('existing', 'BOOLEAN NOT NULL DEFAULT 0'),
    #                 ('created_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
    #                 ('updated_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
    #                 ('FOREIGN KEY(image_id)', 'REFERENCES images(id) ON DELETE CASCADE'),
    #                 ('FOREIGN KEY(model_id)', 'REFERENCES models(id) ON DELETE SET NULL'),
    #                 ('UNIQUE(image_id, tag, tag_id, model_id)', '')
    #             ],
    #             # 他のテーブルも同様に定義
    #             'captions': [
    #                 ('id', 'INTEGER PRIMARY KEY'),
    #                 ('image_id', 'INTEGER'),
    #                 ('model_id', 'INTEGER'),
    #                 ('caption', 'TEXT NOT NULL'),
    #                 ('existing', 'BOOLEAN NOT NULL DEFAULT 0'),
    #                 ('created_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
    #                 ('updated_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
    #                 ('FOREIGN KEY(image_id)', 'REFERENCES images(id) ON DELETE CASCADE'),
    #                 ('FOREIGN KEY(model_id)', 'REFERENCES models(id) ON DELETE SET NULL'),
    #                 ('UNIQUE(image_id, caption, model_id)', '')
    #             ],
    #             'scores': [
    #                 ('id', 'INTEGER PRIMARY KEY'),
    #                 ('image_id', 'INTEGER'),
    #                 ('model_id', 'INTEGER'),
    #                 ('score', 'FLOAT NOT NULL'),
    #                 ('created_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
    #                 ('updated_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
    #                 ('FOREIGN KEY(image_id)', 'REFERENCES images(id) ON DELETE CASCADE'),
    #                 ('FOREIGN KEY(model_id)', 'REFERENCES models(id) ON DELETE SET NULL'),
    #                 ('UNIQUE(image_id, score, model_id)', '')
    #             ]
    #         }

    #         for table_name, columns in table_definitions.items():
    #             # 既存テーブルのカラムを取得
    #             cursor.execute(f"PRAGMA table_info({table_name});")
    #             existing_columns_info = cursor.fetchall()
    #             existing_column_names = {col['name'] for col in existing_columns_info}

    #             # 必要なカラムがすべて存在するか確認
    #             required_columns = [col[0] for col in columns if not col[0].startswith('FOREIGN KEY') and not col[0].startswith('UNIQUE')]
    #             missing_columns = set(required_columns) - existing_column_names

    #             # カラムが不足している場合、テーブルを再作成
    #             if missing_columns or self.need_to_recreate_table(table_name, columns, existing_columns_info):
    #                 self.logger.info(f"テーブル '{table_name}' を再作成します。")
    #                 self.recreate_table(conn, table_name, columns)
    #             else:
    #                 self.logger.info(f"テーブル '{table_name}' は再作成の必要がありません。")

    # def need_to_recreate_table(self, table_name, columns, existing_columns_info):
    #     """テーブルの再作成が必要かどうかを判断する"""
    #     # FOREIGN KEY や UNIQUE 制約の変更が必要かどうかをチェックする
    #     # この例では簡略化のため、常に False を返す
    #     # 必要に応じて実装を追加する
    #     return True  # 常に再作成する

    # def recreate_table(self, conn, table_name, columns):
    #     """テーブルを再作成してデータを移行する"""
    #     cursor = conn.cursor()

    #     # 一時テーブル名を生成
    #     temp_table_name = f"{table_name}_backup"

    #     # テーブルをリネーム（バックアップ）
    #     cursor.execute(f"ALTER TABLE {table_name} RENAME TO {temp_table_name};")
    #     self.logger.info(f"テーブル '{table_name}' を '{temp_table_name}' にリネームしました。")

    #     # 新しいテーブルを作成
    #     columns_definitions = []
    #     for col_name, col_def in columns:
    #         if col_def:  # 制約や FOREIGN KEY も含む
    #             columns_definitions.append(f"{col_name} {col_def}")
    #         else:
    #             columns_definitions.append(f"{col_name}")

    #     create_table_sql = f"CREATE TABLE {table_name} (\n" + ",\n".join(columns_definitions) + "\n);"
    #     cursor.execute(create_table_sql)
    #     self.logger.info(f"テーブル '{table_name}' を新しい定義で作成しました。")

    #     # データを移行
    #     old_columns = [col['name'] for col in cursor.execute(f"PRAGMA table_info({temp_table_name});")]
    #     new_columns = [col[0] for col in columns if not col[0].startswith('FOREIGN KEY') and not col[0].startswith('UNIQUE')]
    #     common_columns = set(old_columns) & set(new_columns)
    #     common_columns_str = ", ".join(common_columns)

    #     cursor.execute(f"INSERT INTO {table_name} ({common_columns_str}) SELECT {common_columns_str} FROM {temp_table_name};")
    #     self.logger.info(f"データを '{temp_table_name}' から '{table_name}' に移行しました。")

    #     # 一時テーブルを削除
    #     cursor.execute(f"DROP TABLE {temp_table_name};")
    #     self.logger.info(f"一時テーブル '{temp_table_name}' を削除しました。")

    #     conn.commit()

    def insert_models(self) -> None:
        """
        モデル情報の初期設定をデータベースに追加

        Args:
            model_name (str): モデルの名前。
            model_type (str): モデルのタイプ。
            provider (str): モデルのプロバイダ。
        """
        query = """
        INSERT OR IGNORE INTO models (name, type, provider) VALUES (?, ?, ?)
        """
        models = [
            ('gpt-4o', 'vision', 'OpenAI'),
            ('gpt-4-turbo', 'vision', 'OpenAI'),
            ('gpt-4o-mini', 'vision', 'OpenAI'),
            ('laion', 'score', ''),
            ('cafe', 'score', ''),
            ('gemini-1.5-pro-exp-0801', 'vision', 'Google'),
            ('gemini-1.5-pro-preview-0409', 'vision', 'Google'),
            ('gemini-1.0-pro-vision', 'vision', 'Google'),
            ('claude-3-5-sonnet-20240620', 'vision', 'Anthropic'),
            ('claude-3-5-sonnet-20241022', 'vision', 'Anthropic'),
            ('claude-3-opus-20240229', 'vision', 'Anthropic'),
            ('claude-3-sonnet-20240229', 'vision', 'Anthropic'),
            ('claude-3-haiku-20240307', 'vision', 'Anthropic'),
            ('RealESRGAN_x4plus', 'upscaler', 'xinntao')
        ]
        for model in models:
            self.execute(query, model)

class ImageRepository:
    """
    画像関連のデータベース操作を担当するクラス。
    このクラスは、画像メタデータの保存、取得、アノテーションの管理などを行います。
    """
    def __init__(self, db_manager: SQLiteManager):
        """
        ImageRepositoryクラスのコンストラクタ。

        Args:
            db_manager (SQLiteManager): データベース接続を管理するオブジェクト。
        """
        self.logger = get_logger("ImageRepository")
        self.db_manager = db_manager

    def add_original_image(self, info: dict[str, Any]) -> int:
        """
        オリジナル画像のメタデータを images テーブルに追加します。

        Args:
            info (dict[str, Any]): 画像情報を含む辞書。

        Returns:
            int: 挿入された画像のID。

        Raises:
            ValueError: 必須情報が不足している場合。
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """

        # pHashの計算と重複チェック
        try:
            phash = calculate_phash(Path(info['stored_image_path']))
            info['phash'] = phash
            duplicate = self.find_duplicate_image(phash)
            if duplicate:
                self.logger.warning(f"画像が既に存在します: ID {duplicate}")
                return duplicate
        except Exception as e:
            self.logger.error(f"pHashの処理中にエラーが発生しました: {e}")
            raise

        required_keys = ['uuid', 'original_image_path','stored_image_path', 'width', 'height', 'format', 'mode',
                         'has_alpha', 'filename', 'extension', 'color_space', 'icc_profile', 'phash']
        if not all(key in info for key in required_keys):
            missing_keys = [key for key in required_keys if key not in info]
            raise ValueError(f"必須情報が不足しています: {', '.join(missing_keys)}")

        query = """
        INSERT INTO images (uuid, original_image_path, stored_image_path, width, height, format, mode, has_alpha,
                            filename, extension, color_space, icc_profile, phash, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        try:
            created_at = datetime.now().isoformat()
            updated_at = created_at
            params = (
                info['uuid'],
                info['original_image_path'],
                info['stored_image_path'],
                info['width'],
                info['height'],
                info['format'],
                info['mode'],
                info['has_alpha'],
                info['filename'],
                info['extension'],
                info['color_space'],
                info['icc_profile'],
                info['phash'],
                created_at,
                updated_at
            )
            cursor = self.db_manager.execute(query, params)
            self.logger.info(f"オリジナル画像をDBに追加しました: UUID={info['uuid']}")
            return cursor.lastrowid
        except sqlite3.Error as e:
            self.logger.error(f"{self.__class__.__name__}.{self.add_original_image.__name__} - SQL エラーが 発生しました: {e}")
            raise

    def add_processed_image(self, info: dict[str, Any]) -> int:
        """
        処理済み画像のメタデータを images テーブルに追加します。

        Args:
            info (dict[str, Any]): 処理済み画像情報を含む辞書。

        Returns:
            int: 挿入された処理済み画像のID。

        Raises:
            ValueError: 必須情報が不足している場合。
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        required_keys = ['stored_image_path', 'width', 'height', 'format', 'mode',
                         'has_alpha', 'filename', 'color_space', 'icc_profile', 'image_id']
        if not all(key in info for key in required_keys):
            missing_keys = [key for key in required_keys if key not in info]
            raise ValueError(f"必須情報が不足しています: {', '.join(missing_keys)}")

        query = """
        INSERT INTO processed_images (image_id, stored_image_path, width, height, mode, has_alpha,
                                filename, color_space, icc_profile, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        try:
            created_at = datetime.now().isoformat()
            updated_at = created_at
            params = (
                info['image_id'],
                info['stored_image_path'],
                info['width'],
                info['height'],
                info['mode'],
                info['has_alpha'],
                info['filename'],
                info['color_space'],
                info['icc_profile'],
                created_at,
                updated_at
            )
            cursor = self.db_manager.execute(query, params)
            self.logger.info(f"処理済み画像をDBに追加しました: 親画像ID={info['image_id']}")
            return cursor.lastrowid
        except sqlite3.Error as e:
            self.logger.error(f"処理済み画像の追加中にエラーが発生しました: {e}")
            raise

    def get_image_metadata(self, image_id: int) -> Optional[dict[str, Any]]:
        """
        指定されたIDの画像メタデータを取得します。

        Args:
            image_id (int): 取得する画像のID。

        Returns:
            Optional[dict[str, Any]]: 画像メタデータを含む辞書。画像が見つからない場合はNone。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        query = "SELECT * FROM images WHERE id = ?"
        try:
            metadata = self.db_manager.fetch_one(query, (image_id,))
            return metadata
        except sqlite3.Error as e:
            current_method = inspect.currentframe().f_code.co_name
            raise sqlite3.Error(f"{current_method} 画像メタデータの取得中にエラーが発生しました : {e}")

    def save_annotations(self, image_id: int, annotations: dict[str, Union[list[str], float, int]]) -> None:
        # OPTIMIZE: このメソッドの処理を最適化する
        """
        画像のアノテーション（タグ、キャプション、スコア）を保存します。

        Args:
            image_id (int): アノテーションを追加する画像のID。
            annotations (dict): アノテーションデータ。
            {
                'tags': list[dict[tag: model_id]],
                'captions': list[caption: model_id],
                'score': dict[score: model_id]
                'model_id': int
                'image_path': str
            }

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
            ValueError: 必要なデータが不足している場合。
        """
        if not self._image_exists(image_id):
            raise ValueError(f"指定されたimage_id {image_id} は存在しません。")

        # 各値を取得
        tags = annotations.get('tags', [])
        captions = annotations.get('captions', [])
        score_data = annotations.get('score', {})
        model_id = annotations.get('model_id', None)
        if model_id is None:
            model_id = next((tag.get('model_id') for tag in tags if tag.get('model_id') is not None), None)
            if model_id is None:
                model_id = next((caption.get('model_id') for caption in captions if caption.get('model_id') is not None), None)
            if model_id is None:
                self.logger.info("model_idはすべてNoneで保存されます。")

        tags_list = [tag_dict.get('tag') for tag_dict in tags]
        caption_list = [caption_dict.get('caption') for caption_dict in captions]
        try:
            self._save_tags(image_id, tags_list, model_id)
            self._save_captions(image_id, caption_list, model_id)
            if score_data:
                score = score_data.get('score', 0)
                score_model_id = score_data.get('model_id', model_id)
                self.save_score(image_id, score, score_model_id)
            else:
                self.logger.info("スコアは保存されません。")
        except sqlite3.Error as e:
            current_method = inspect.currentframe().f_code.co_name
            raise sqlite3.Error(f"{current_method} アノテーションの保存中にエラーが発生しました: {e}")

    def _save_tags(self, image_id: int, tags: list[str], model_id: Optional[int]) -> None:
        """タグとそのIDを保存する内部メソッド

        Args:
            image_id (int): タグを追加する画像のID。
            tags (list[str]): タグのリスト。
            model_id (Optional[int]): タグ付けに使用されたモデルのID。Noneの場合は既存タグとして扱う。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        self.logger.debug(f"_save_tags called with image_id: {image_id}, tags: {tags}, model_id: {model_id}")
        self.logger.debug(f"Type of tags: {type(tags)}")
        if not tags:
            self.logger.debug(f"画像ID {image_id} のタグリストが空のため、保存をスキップします。")
            return

        query = """
                INSERT INTO tags (image_id, tag_id, tag, model_id, existing, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                ON CONFLICT(image_id, tag, tag_id, model_id) DO UPDATE SET
                    existing = EXCLUDED.existing,
                    updated_at = CURRENT_TIMESTAMP
                """
        data = []

        for tag in tags:
            tag_id = self.find_tag_id(tag)
            existing = 1 if model_id is None else 0
            if model_id is None:
                # None の場合は明示的に NULL を設定
                data.append((image_id, tag_id, tag, None, existing))
            else:
                data.append((image_id, tag_id, tag, model_id, existing))
        self.logger.debug(f"ImageRepository._save_tags_with_ids: tag={tag}, tag_id={tag_id}")

        try:
            self.db_manager.executemany(query, data)
            self.logger.info(f"画像ID {image_id} に {len(data)} 個のタグとIDを保存しました")
        except sqlite3.Error as e:
            self.logger.error(f"タグとIDの保存中にエラーが発生しました: {e}")
            raise

    def _save_captions(self, image_id: int, captions: list[str], model_id: Optional[int]) -> None:
        """キャプションを保存する

        Args:
            image_id (int): キャプションを追加する画像のID。
            captions (list[str]): キャプションのリスト。
            model_id (Optional[int]): キャプションに関連付けられたモデルのID。Noneの場合は既存キャプションとして扱う。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        if not captions:
            self.logger.info(f"画像ID {image_id} のキャプションリストが空のため、保存をスキップします。")
            return

        query = """
                INSERT INTO captions (image_id, caption, model_id, existing, created_at, updated_at)
                VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                ON CONFLICT(image_id, caption, model_id) DO UPDATE SET
                    existing = EXCLUDED.existing,
                    updated_at = CURRENT_TIMESTAMP
                """
        data = []

        for caption in captions:
            existing = 1 if model_id is None else 0
            if model_id is None:
                data.append((image_id, caption, None, existing))
            else:
                data.append((image_id, caption, model_id, existing))
            self.logger.debug(f"ImageRepository._save_captions: {caption} ")

        try:
            self.db_manager.executemany(query, data)
            self.logger.info(f"画像ID {image_id} に {len(data)} 個のキャプションを保存しました")
        except sqlite3.Error as e:
            self.logger.error(f"キャプションの保存中にエラーが発生しました: {e}")
            raise

    def save_score(self, image_id: int, score: float, model_id: int) -> None:
        """スコアを保存

        Args:
            image_id (int): スコアを追加する画像のID。
            score (float): スコアの値。
            model_id (int): スコアに関連付けられたモデルのID。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
            ValueError: 必要なデータが不足している場合。
        """
        if score == 0:
            self.logger.info(f"スコアが0のため、保存をスキップします。")
            return

        query = "INSERT OR IGNORE INTO scores (image_id, score, model_id) VALUES (?, ?, ?)"
        data = (image_id, score, model_id)

        try:
            self.db_manager.execute(query, data)
            self.logger.debug(f"Score saved: image_id={image_id}, score={score}, model_id={model_id}")
        except sqlite3.Error as e:
            self.logger.error(f"Failed to save score: {e}")
            raise

    def _get_model_id(self, model_name: str) -> int:
        """モデル名からモデルIDを取得するメソッド"""
        query = "SELECT id FROM models WHERE name = ?"
        try:
            cursor = self.db_manager.execute(query, (model_name,))
            row = cursor.fetchone()
            if row:
                return row['id']
            else:
                raise ValueError(f"モデル名 '{model_name}' が見つかりません。")
        except sqlite3.Error as e:
            current_method = inspect.currentframe().f_code.co_name
            raise sqlite3.Error(f"{current_method} エラー: {e}")

    def _image_exists(self, image_id: int) -> bool:
        """
        指定された画像IDが存在するかを確認します。

        Args:
            image_id (int): 確認する画像のID。

        Returns:
            bool: 画像が存在する場合はTrue、存在しない場合はFalse。
        """
        query = "SELECT 1 FROM images WHERE id = ?"
        result = self.db_manager.fetch_one(query, (image_id,))
        return result is not None

    def find_duplicate_image(self, phash: str) -> int:
        """
        指定されたpHashに一致する画像をデータベースから検索しImage IDを返します。

        Args:
            phash (str): 検索するpHash。

        Returns:
            Optional[int]: 重複する画像のメタデータ。見つからない場合はNone。
        """
        query = "SELECT * FROM images WHERE phash = ?"
        try:
            duplicate = self.db_manager.fetch_one(query, (phash,))
            image_id = duplicate['id'] if duplicate else None
            if duplicate:
                self.logger.info(f"重複画像が見つかりました: ID {duplicate['id']}, UUID {duplicate['uuid']}")
            return image_id
        except sqlite3.Error as e:
            self.logger.error(f"重複画像の検索中にエラーが発生しました: {e}")
            return None

    def get_image_annotations(self, image_id: int) -> dict[str, Union[list[dict[str, Any]], float, int]]:
        """
        指定された画像IDのアノテーション（タグ、キャプション、スコア）を取得します。

        Args:
            image_id (int): アノテーションを取得する画像のID。

        Returns:
            dict[str, list[dict[str, Any]]]: アノテーションデータを含む辞書。
            画像が存在しない場合は空の辞書を返します。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        try:
            # 画像の存在確認
            if not self._image_exists(image_id):
                self.logger.warning(f"指定されたimage_id {image_id} の画像が存在しません。")
                return {'tags': [], 'captions': [], 'scores': []}

            # アノテーションの取得
            annotations = {
                'tags': self._get_tags(image_id),
                'captions': self._get_captions(image_id),
                'scores': self._get_scores(image_id)
            }
            return annotations

        except sqlite3.Error as e:
            self.logger.error(f"アノテーションの取得中にデータベースエラーが発生しました: {e}")
            raise
        except Exception as e:
            self.logger.error(f"予期せぬエラーが発生しました: {e}")
            raise

    def _get_tags(self, image_id: int) -> list[dict[str, Any]]:
        """image_idからタグを取得する内部メソッド"""
        query = "SELECT tag, model_id, tag_id, updated_at FROM tags WHERE image_id = ?"
        try:
            self.logger.debug(f"タグを取得するimage_id: {image_id}")
            result = self.db_manager.fetch_all(query, (image_id,))
            if not result:
                self.logger.debug(f"Image_id: {image_id} にタグは登録されていません。")
            return result
        except sqlite3.Error as e:
            self.logger.error(f"image_id: {image_id} のタグを取得中にデータベースエラーが発生しました: {e}")
            raise

    def _get_captions(self, image_id: int) -> list[dict[str, Any]]:
        """image_idからキャプションを取得する内部メソッド"""
        query = "SELECT caption, model_id, updated_at FROM captions WHERE image_id = ?"
        try:
            self.logger.debug(f"キャプションを取得するimage_id: {image_id}")
            result = self.db_manager.fetch_all(query, (image_id,))
            if not result:
                self.logger.info(f"Image_id: {image_id} にキャプションは登録されていません。")
            return result
        except sqlite3.Error as e:
            self.logger.error(f"image_id: {image_id} のキャプションを取得中にデータベースエラーが発生しました: {e}")
            raise

    def _get_scores(self, image_id: int) -> list[dict[str, Any]]:
        """image_idからスコアを取得する内部メソッド"""
        query = "SELECT score, model_id FROM scores WHERE image_id = ?"
        try:
            self.logger.debug(f"スコアを取得するimage_id: {image_id}")
            result = self.db_manager.fetch_all(query, (image_id,))
            if not result:
                self.logger.info(f"Image_id: {image_id} にスコアは登録されていません。")
            return result
        except sqlite3.Error as e:
            self.logger.error(f"image_id: {image_id} のスコアを取得中にデータベースエラーが発生しました: {e}")
            raise

    def escape_special_characters(self, input_string: str) -> str:
        """
        SQLの特殊文字（% と _）をエスケープし、ワイルドカードの * を % に置換する。
        ダブルクオートで囲まれた部分は完全一致として扱う。

        Args:
            input_string (str): エスケープする入力文字列

        Returns:
            str: エスケープされた文字列
        """
        # ダブルクオートで囲まれた部分は完全一致として扱う
        if input_string.startswith('"') and input_string.endswith('"'):
            # ダブルクオートを外してそのまま戻す
            return input_string.strip('"')

        # 特殊文字のエスケープとワイルドカードの置換
        escaped_string = input_string.replace('\\', '\\\\').replace('%', r'\%').replace('_', r'\_')
        return escaped_string.replace('*', '%')

    def get_images_by_tag(self, tag: str, start_date: str, end_date: str) -> list[int]:
        """
        指定された日付の範囲で更新されたタグを持つ画像のIDリストを取得する
        （部分一致とワイルドカードに対応）

        Args:
            tag (str): 検索するタグ（ワイルドカード '*' を含むことができます）
            start_date (str): 検索開始日時（UTCタイムスタンプ）
            end_date (str): 検索終了日時（UTCタイムスタンプ）

        Returns:
            list[int]: タグを持つ画像IDのリスト か 空リスト
        """
        if tag.startswith('"') and tag.endswith('"'):
            # 完全一致検索用のクエリ
            query = """
            SELECT i.id
            FROM images i
            JOIN tags t ON i.id = t.image_id
            WHERE t.tag = ?
            AND t.updated_at BETWEEN ? AND ?
            """
            # ダブルクオートを外したタグで検索
            pattern = tag.strip('"')
        else:
            # ワイルドカードなしでも部分一致検索にする
            pattern = self.escape_special_characters(tag)
            if '*' not in tag:
                # '*' がない場合も部分一致のLIKEを使う
                pattern = f'%{pattern}%'

            query = """
            SELECT i.id
            FROM images i
            JOIN tags t ON i.id = t.image_id
            WHERE t.tag LIKE ? ESCAPE '\\'
            AND t.updated_at BETWEEN ? AND ?
            """
        # タイムスタンプをパラメータに追加
        params = [pattern, start_date, end_date]
        rows = self.db_manager.fetch_all(query, params)
        if not rows:
            self.logger.info("%s を含む画像はありません", tag)
            return []
        else:
            return [row['id'] for row in rows]

    def get_untagged_images(self) -> list[int]:
        query = """
        SELECT id
        FROM images
        WHERE id NOT IN (SELECT DISTINCT image_id FROM tags WHERE image_id)
        """
        return [row['id'] for row in self.db_manager.fetch_all(query, ())]

    def get_images_by_caption(self, caption: str, start_date: int, end_date: int) -> list[int]:
        """
        指定されたキャプションを含む画像のIDリストを取得する（部分一致、ワイルドカード、完全一致に対応）

        Args:
            caption (str): 検索するキャプション（ワイルドカード '*' やダブルクオートを含むことができます）
            start_date (str): 検索開始日時('%Y-%m-%d %H:%M:%S')
            end_date (str): 検索終了日時

        Returns:
            list[int]: キャプションを持つ画像IDのリスト か 空リスト
        """
        # キャプションがダブルクオートで囲まれている場合は完全一致検索を行う
        if caption.startswith('"') and caption.endswith('"'):
            # 完全一致検索用のクエリ
            query = """
            SELECT DISTINCT i.id
            FROM images i
            JOIN captions c ON i.id = c.image_id
            WHERE c.caption = ?
            AND c.updated_at BETWEEN ? AND ?
            """
            # ダブルクオートを外したキャプションで検索
            pattern = caption.strip('"')
        else:
            # 部分一致検索用のパターン作成
            pattern = self.escape_special_characters(caption)
            if '*' not in caption:
                pattern = f'%{pattern}%'
            query = """
            SELECT DISTINCT i.id
            FROM images i
            JOIN captions c ON i.id = c.image_id
            WHERE c.caption LIKE ? ESCAPE '\\'
            AND c.updated_at BETWEEN ? AND ?
            """

        params = [pattern, start_date, end_date]
        rows = self.db_manager.fetch_all(query, params)
        if not rows:
            self.logger.info("'%s' を含むキャプションを持つ画像はありません", caption)
            return []
        else:
            return [row['id'] for row in rows]

    def get_original_image(self, image_id: int) -> dict[str, Any]:
        """
        指定されたIDのオリジナル画像のメタデータを取得します。

        Args:
            image_id (int): 取得する画像のID。

        Returns:
            list[dict[str, Any]]: 画像メタデータを含む辞書。画像が見つからない場合はNone。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        query = "SELECT * FROM images WHERE id = ?"
        try:
            metadata = self.db_manager.fetch_one(query, (image_id,))
            return metadata
        except sqlite3.Error as e:
            current_method = inspect.currentframe().f_code.co_name
            raise sqlite3.Error(f"{current_method} オリジナル画像の取得中にエラーが発生しました: {e}")

    def get_processed_image(self, image_id: int, resolution: int = 0, all_data: bool = False) -> Optional[dict[str, Any]]:
        """
        image_idとresolutionから関連する処理済み画像のメタデータを取得し、指定した解像度でリサイズされた画像のメタデータを返します。

        Args:
            image_id (int): 元画像のID。
            resolution (int): リサイズ処理の基準にした解像度。0の場合は最も解像度が低い画像を返します。
            all_data (bool): Trueの場合は全ての処理済み画像のメタデータを返します。

        Returns:
            Optional[dict[str, Any]]: 処理済み画像のメタデータを含む辞書。画像が見つからない場合はNone。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        query = "SELECT * FROM processed_images WHERE image_id = ?"
        try:
            # 全ての処理済み画像を取得
            metadata_list = self.db_manager.fetch_all(query, (image_id,))
            if not metadata_list:
                return None
            self.logger.debug(f"ID {image_id} の処理済み画像メタデータを {len(metadata_list)} 取得しました")
            if all_data:
                return metadata_list
            # resolutionが0の場合は最も解像度が低いものを選択
            if resolution == 0:
                metadata = min(metadata_list, key=lambda x: x['width'] * x['height'])
            else:
                # 指定された解像度に近いものをフィルタリング
                metadata = self._filter_by_resolution(metadata_list, resolution)
            return metadata

        except sqlite3.Error as e:
            current_method = inspect.currentframe().f_code.co_name
            raise sqlite3.Error(f"{current_method} 処理済み画像の取得中にエラーが発生しました: {e}")

    def _filter_by_resolution(self, metadata_list: list[dict[str, Any]], resolution: int) -> dict[str, Any]:
        """
        解像度に基づいてメタデータをフィルタリングします。

        Args:
            metadata_list (list[dict[str, Any]]): メタデータの辞書のリスト。
            resolution (int): 解像度。

        Returns:
            dict[str, Any]]: フィルタリングされたメタデータの辞書。解像度が条件に一致するか、
            指定した解像度に対して誤差が20%以下であるメタデータを返します。

        """
        for metadata in metadata_list:
            width, height = metadata['width'], metadata['height']
            long_side, short_side = max(width, height), min(width, height)

            if long_side == resolution:
                return metadata
            else:
                target_area = resolution * resolution
                actual_area = long_side * short_side
                error_ratio = abs(target_area - actual_area) / target_area

                if error_ratio <= 0.2:
                    return metadata
        return None

    def get_total_image_count(self) -> int:
        try:
            query = "SELECT COUNT(*) FROM images"
            result = self.db_manager.fetch_one(query)
            return result['COUNT(*)'] if result else 0
        except Exception as e:
            self.logger.error(f"総画像数の取得中にエラーが発生しました: {e}")
            return 0

    def get_image_id_by_name(self, image_name: str) -> Optional[int]:
        """
        オリジナル画像の重複チェック用 画像名からimage_idを取得

        Args:
            image_name (str): 画像名

        Returns:
            Optional[int]: image_id。画像が見つからない場合はNone。
        """
        query = "SELECT id FROM images WHERE filename = ?"
        try:
            result = self.db_manager.fetch_one(query, (image_name,))
            if result:
                image_id = result['id']
                self.logger.info(f"画像名 {image_name} のimage_id {image_id} を取得しました")
                return image_id
            self.logger.info(f"画像名 {image_name} のimage_idを取得できませんでした")
            return None
        except Exception as e:
            self.logger.error(f"画像IDの取得中にエラーが発生しました: {e}")
            return None

    def get_image_id_by_phash(self, phash: str) -> Optional[int]:
        """
        pHashからimage_idを取得

        Args:
            phash (str): pHash

        Returns:
            Optional[int]: image_id。画像が見つからない場合はNone。
        """
        THRESHOLD = 5  # この値は調整可能です。小さいほど厳密な一致を要求します。

        query = "SELECT id, phash FROM images"
        try:
            results = self.db_manager.fetch_all(query)

            for row in results:
                db_id, db_phash = row['id'], row['phash']
                if imagehash.hex_to_hash(phash) - imagehash.hex_to_hash(db_phash) <= THRESHOLD:
                    self.logger.info(f"類似画像が見つかりました: ID {db_id}, 元のpHash: {phash}, DB内pHash: {db_phash}")
                    return db_id

            self.logger.info(f"類似画像は見つかりませんでした: pHash {phash}")
            return None
        except Exception as e:
            self.logger.error(f"類似画像の検索中にエラーが発生しました: {e}")
            return None

    def update_image_metadata(self, image_id: int, updated_info: dict[str, Any]) -> None:
        """
        指定された画像IDのメタデータを更新します。

        Args:
            image_id (int): 更新する画像のID。
            updated_info (dict[str, Any]): 更新するメタデータの辞書。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        if not updated_info:
            self.logger.warning("更新する情報が提供されていません。")
            return
        fields = ", ".join(f"{key} = ?" for key in updated_info.keys())
        values = list(updated_info.values())
        query = f"UPDATE images SET {fields}, updated_at = ? WHERE id = ?"
        values.append(datetime.now().isoformat())  # updated_atを追加
        values.append(image_id)  # image_idを追加
        try:
            self.db_manager.execute(query, tuple(values))
            self.logger.info(f"画像ID {image_id} のメタデータを更新しました。")
        except sqlite3.Error as e:
            self.logger.error(f"画像メタデータの更新中にエラーが発生しました: {e}")
            raise

    def delete_image(self, image_id: int) -> None:
        """
        指定された画像IDの画像と関連するデータを削除します。

        Args:
            image_id (int): 削除する画像のID。

        Raises:
            sqlite3.Error: データベース操作でエラーが発生した場合。
        """
        query = "DELETE FROM images WHERE id = ?"
        try:
            self.db_manager.execute(query, (image_id,))
            self.logger.info(f"画像ID {image_id} と関連するデータを削除しました。")
        except sqlite3.Error as e:
            self.logger.error(f"画像の削除中にエラーが発生しました: {e}")
            raise

    def find_tag_id(self, keyword: str) -> Optional[int]:
        """tags_v3.db TAGSテーブルからタグを完全一致で検索

        Args:
            keyword (str): 検索キーワード
        Returns:
            tag_id (Optional[int]): タグID
        Raises:
            ValueError: 複数または0件のタグが見つかった場合
        """
        query = "SELECT tag_id FROM tag_db.TAGS WHERE tag = ?"
        try:
            result = self.db_manager.fetch_one(query, (keyword,))
            if result:
                if len(result) > 1:
                    self.logger.warning(f"タグ '{keyword}' に対して複数のIDが見つかりました。\n {result}")
                    return result['tag_id'][0]
                else:
                    tag_id = result['tag_id']
                    self.logger.debug(f"タグ '{keyword}' のtag_id {tag_id} を取得しました")
                return tag_id
            self.logger.info(f"タグ '{keyword}' のtag_idを取得できませんでした")
            return None
        except sqlite3.Error as e:
            self.logger.error(f"タグIDの取得中にエラーが発生しました: {e}")
            raise

class ImageDatabaseManager:
    """
    画像データベース操作の高レベルインターフェースを提供するクラス。
    このクラスは、ImageRepositoryを使用して、画像メタデータとアノテーションの
    保存、取得、更新などの操作を行います。
    """
    def __init__(self, db_dir: Path):
        self.logger = get_logger("ImageDatabaseManager")
        if not db_dir.exists():
            db_dir.mkdir(parents=True, exist_ok=True)
            db_path = db_dir / "image_database.db"
            db_path.touch(exist_ok=True)
        img_db_path = db_dir / "image_database.db"
        tag_db_path = Path("src") / "module" / "genai-tag-db-tools" / "tags_v3.db"
        self.db_manager = SQLiteManager(img_db_path, tag_db_path)
        self.repository = ImageRepository(self.db_manager)
        self.db_manager.create_tables()
        self.db_manager.insert_models()
        self.logger.debug("初期化")

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, _):
        self.db_manager.close()
        if exc_type:
            self.logger.error("ImageDatabaseManager使用中にエラー: %s", exc_value)
        return False  # 例外を伝播させる

    def register_original_image(self, image_path: Path, fsm: FileSystemManager) -> Optional[tuple]:
        """オリジナル画像を保存し、メタデータをデータベースに登録

        Args:
            image_path (Path): 画像パス
            fsm (FileSystemManager): FileSystemManager のインスタンス

        Returns:
            Optional[tuple]: 登録成功時は (image_id, original_metadata)、失敗時は None
        """
        try:
            original_image_metadata = fsm.get_image_info(image_path)
            db_stored_original_path = fsm.save_original_image(image_path)
            # UUIDの生成
            image_uuid = str(uuid.uuid4())
            # メタデータにUUIDと保存パスを追加
            original_image_metadata.update({
                'uuid': image_uuid,
                'original_image_path': str(image_path),
                'stored_image_path': str(db_stored_original_path)
            })
            # データベースに挿入
            image_id = self.repository.add_original_image(original_image_metadata)
            return image_id, original_image_metadata
        except Exception as e:
            self.logger.error(f"オリジナル画像の登録中にエラーが発生しました: {e}")
            return None

    def register_processed_image(self, image_id: int, processed_path: Path, info: dict[str, Any]) -> Optional[int]:
        """
        処理済み画像を保存し、メタデータをデータベースに登録します。

        Args:
            image_id (int): 元画像のID。
            processed_path (Path): 処理済み画像の保存パス。
            info (dict[str, Any]): 処理済み画像のメタデータ。

        Returns:
            Optional[int]: 保存された処理済み画像のID。失敗時は None。
        """
        try:
            # 必須情報を確認
            required_keys = ['width', 'height', 'mode', 'has_alpha',
                             'filename', 'color_space', 'icc_profile']
            if not all(key in info for key in required_keys):
                missing_keys = [key for key in required_keys if key not in info]
                raise ValueError(f"必須情報が不足しています: {', '.join(missing_keys)}")

            # メタデータに親画像IDを追加
            info.update({
                'image_id': image_id,
                'stored_image_path': str(processed_path),
            })

            # データベースに挿入
            processed_image_id = self.repository.add_processed_image(info)
            return processed_image_id
        except Exception as e:
            self.logger.error(f"処理済み画像メタデータの保存中にエラーが発生しました: {e}")
            return None

    def save_annotations(self, image_id: int, annotations: dict[str, list[Any, Any]]) -> None:
        """
        画像のアノテーション（タグ、キャプション、スコア）を保存します。

        Args:
            image_id (int): アノテーションを追加する画像のID。
            annotations (dict[str, list[Any, Any]]): アノテーションデータ。
                'tags', 'captions', 'score' をキーとし、それぞれリストを値とする辞書。
                各リストの要素は {'value': str, 'model': str} の形式。
        Raises:
            Exception: アノテーションの保存に失敗した場合。
        """
        try:
            self.repository.save_annotations(image_id, annotations)
            self.logger.info(f"画像 ID {image_id} のアノテーション{annotations}を保存しました")
        except Exception as e:
            self.logger.error(f"アノテーションの保存中にエラーが発生しました: {e}")
            raise

    def register_prompt_tags(self, image_id: int, tags: list[str]) -> None:
        self.repository._save_tags(image_id, tags, None)

    def save_score(self, image_id: int, score_dict: dict[str, Any]) -> None:
        """
        画像のスコアを保存します。

        Args:
            image_id (int): スコアを追加する画像のID。
            score (dict[str, Any]): スコアの値と算出に使ったモデルのID
        """
        score_float = score_dict['score']
        model_id = score_dict['model_id']
        try:
            self.repository.save_score(image_id, score_float, model_id)
            self.logger.info(f"画像 ID {image_id} のスコア{score_float}を保存しました")
        except Exception as e:
            self.logger.error(f"スコアの保存中にエラーが発生しました: {e}")
            raise

    def get_low_res_image(self, image_id: int) -> Optional[str]:
        """
        指定されたIDで長辺が最小の処理済み画像のパスを取得します。

        Args:
            image_id (int): 取得する元画像のID。

        Returns:
            Optional[str]: 長辺が最小の処理済み画像のパス。見つからない場合はNone。
        """
        try:
            min_image_metdata = self.repository.get_processed_image(image_id)
            if not min_image_metdata:
                self.logger.warning(f"画像ID {image_id} に対する処理済み画像が見つかりません。")
                return None
            min_long_edge = max(min_image_metdata.get('width'), min_image_metdata.get('height'))
            min_image_path = min_image_metdata.get('stored_image_path')
            if min_image_path:
                self.logger.debug(f"画像ID {image_id} の最小長辺画像（{min_long_edge}px）を取得しました。")
                return min_image_path

        except Exception as e:
            self.logger.error(f"低解像度画像の取得中にエラーが発生しました: {e}")
            return None

    def get_image_metadata(self, image_id: int) -> Optional[dict[str, Any]]:
        """
        指定されたIDの画像メタデータを取得します。

        Args:
            image_id (int): 取得する画像のID。

        Returns:
            Optional[dict[str, Any]]: 画像メタデータを含む辞書。画像が見つからない場合はNone。

        Raises:
            Exception: メタデータの取得に失敗した場合。
        """
        try:
            metadata = self.repository.get_image_metadata(image_id)
            if metadata is None:
                self.logger.info(f"ID {image_id} の画像が見つかりません。")
            return metadata
        except Exception as e:
            self.logger.error(f"画像メタデータ取得中にエラーが発生しました: {e}")
            raise

    def get_processed_metadata(self, image_id: int) -> Optional[list[dict[str, Any]]]:
        """
        指定された元画像IDに関連する全ての処理済み画像のメタデータを取得します。

        Args:
            image_id (int): 元画像のID。

        Returns:
            list[dict[str, Any]]: 処理済み画像のメタデータのリスト。

        Raises:
            Exception: メタデータの取得に失敗した場合。
        """
        try:
            metadata_list = self.repository.get_processed_image(image_id, all_data=True)
            if not metadata_list:
                self.logger.info(f"ID {image_id} の元画像に関連する処理済み画像が見つかりません。")
                return None
            return metadata_list
        except Exception as e:
            self.logger.error(f"処理済み画像メタデータ取得中にエラーが発生しました: {e}")
            raise

    def get_image_annotations(self, image_id: int) -> dict[str, list[dict[str, Any]]]:
        """
        指定された画像IDのアノテーション（タグ、キャプション、スコア）を取得します。

        Args:
            image_id (int): アノテーションを取得する画像のID。

        Returns:
            dict[str, list[dict[str, Any]]]: アノテーションデータを含む辞書。

        Raises:
            Exception: アノテーションの取得に失敗した場合。
        """
        try:
            annotations = self.repository.get_image_annotations(image_id)
            if not any(annotations.values()):
                self.logger.info(f"ID {image_id} の画像にアノテーションが見つかりません。")
            return annotations
        except Exception as e:
            self.logger.error(f"画像アノテーション取得中にエラーが発生しました: {e}")
            raise

    def get_models(self) -> tuple[dict[int, dict[str, Any]], dict[int, dict[str, Any]]]:
        """
        TODO: データベースに問い合わせるのでImageRepositoryに移動したほうがキレイ その時処理は分割する
        データベースに登録されているモデルの情報を取得します。

        Returns:
            tuple[dict[int, dict[str, Any]], dict[int, dict[str, Any]]]: (vision_models, score_models) のタプル。
            vision_models: {model_id: {'name': model_name, 'provider': provider}},
            upscaler_models: {model_id: {'name': model_name, 'provider': provider}}
            score_models: {model_id: {'name': model_name, 'provider': provider}}
        """
        query = "SELECT id, name, provider, type FROM models"
        try:
            models = self.db_manager.fetch_all(query)
            vision_models = {}
            score_models = {}
            upscaler_models = {}
            for model in models:
                model_id = model['id']
                name = model['name']
                provider = model['provider']
                model_type = model['type']
                if model_type == 'vision':
                    vision_models[model_id] = {'name': name, 'provider': provider}
                elif model_type == 'score':
                    score_models[model_id] = {'name': name, 'provider': provider}
                elif model_type == 'upscaler':
                    upscaler_models[model_id] = {'name': name, 'provider': provider}
            return vision_models, score_models, upscaler_models
        except sqlite3.Error as e:
            self.logger.error(f"モデルの取得中にエラーが発生しました: {e}")
            raise

    def get_images_by_filter(self, tags: list[str] = None, caption: str = None, resolution: int = 0, 
                             use_and: bool = True, start_date: str = None, end_date: str = None, 
                             include_untagged: bool = False, include_nsfw: bool = False) -> tuple[list[dict[str, Any]], int]:
        """

        Args:
            tags (list[str], optional): カンマ区切りをリスト化したタグ. Defaults to None.
            caption (str, optional): _キャプション
            resolution (int, optional): 検索する解像度x解像度の値が誤差20%以内の画像を取得. Defaults to 0.
            use_and (bool, optional): _description_. Defaults to True.
            start_date (str): 検索する画像の作成日時の下限('%Y-%m-%d %H:%M:%S')
            end_date (str,): 検索する画像の作成日時の上限
            include_untagged (bool, optional): タグが付いていない画像のみを取得. Defaults to False.
            include_nsfw (bool, optional): NSFW画像を含めるかどうか. Defaults to False.

        Returns:
            tuple[list[dict[str, Any]], int]: 条件にマッチした画像データのリストとその数
            例:([
                {'id': 516, 'image_id': 515, 'stored_image_path': 'psth',
                'width': 1024, 'height': 768, 'mode': 'RGB', 'has_alpha': 0, 'filename': '1_240925_00304.webp', 'color_space': 'RGB', 'icc_profile': 'Not present', 'created_at': '2024-09-26T20:21:08.451199', 'updated_at': '2024-09-26T20:21:08.451199'},
                {'id': 517, 'image_id': 516, 'stored_image_path': 'psth',...}
                ],
                2)
        """
        if not tags and not caption and not include_untagged:
            self.logger.info("タグもキャプションも指定されていない")
            return None, 0

        # 現在の日付を取得
        current_datetime = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
        start_date = start_date or ('2020-01-01 00:00:00')  # 2020年1月1日
        end_date = end_date or current_datetime  # 現在

        image_ids = set()

        if include_untagged:
            if tags or caption:
                self.logger.warning("検索語句とinclude_untaggedが同時に指定されています。検索語句を無視します。")
            untagged_image_ids = set(self.repository.get_untagged_images())
            image_ids.update(untagged_image_ids)

        # タグによるフィルタリング
        if tags and not include_untagged:
            tag_results = [set(self.repository.get_images_by_tag(tag, start_date, end_date)) for tag in tags]
            if tag_results:
                image_ids = set.intersection(*tag_results) if use_and else set.union(*tag_results)

        # キャプションによるフィルタリング
        if caption and not include_untagged:
            caption_results = set(self.repository.get_images_by_caption(caption, start_date, end_date))
            image_ids = image_ids.intersection(caption_results) if image_ids else caption_results

        # image_idsが空の場合は空リストを返す
        if not image_ids:
            self.logger.info("条件に一致する画像が見つかりませんでした")
            return [], 0

        # image_idsの画像のアノテーションを取得､キーワード一致するNSFWが含まれるimage_idを除外
        if not include_nsfw:
            exclude_keywords = ['nsfw', 'explicit', 'sex', 'pussy', 'nude', 'penis', 'cum', 'bdsm', 'explicit']  # 除外したいキーワードのリスト
            image_ids = self._filter_images_by_exclude_keywords(image_ids, exclude_keywords)

        # 画像メタデータの取得
        metadata_list = []
        if resolution != 0:
            for image_id in image_ids:
                metadata = self.repository.get_processed_image(image_id, resolution)
                if metadata is not None:
                    metadata_list.append(metadata)
        else:
            for image_id in image_ids:
                metadata = self.repository.get_original_image(image_id)
                if metadata is not None:
                    metadata['image_id'] = image_id
                    metadata_list.append(metadata)

        if not metadata_list:
            self.logger.info(f'解像度基準:{resolution} pxの画像はDBに登録されていません')
            return None, None

        list_count = len(metadata_list)
        self.logger.info(f"フィルタリング後の画像数: {list_count}")

        return metadata_list, list_count

    def _filter_images_by_exclude_keywords(self, image_ids: set[int], exclude_keywords: list[str]) -> set[int]:
        """
        指定された除外キーワードがタグまたはキャプションに含まれる画像IDを除外して、フィルタリングされた画像IDのセットを返します。

        引数:
            image_ids (set[int]): フィルタリング対象の画像IDのセット。
            exclude_keywords (list[str]): 除外キーワードのリスト。これらのキーワードを含む画像は除外されます。

        戻り値:
            set[int]: 除外キーワードが一致しない画像IDのセット。

        方法:
            1. `image_ids` の各画像IDに対して、その画像のタグとキャプションのアノテーションを取得します。
            2. タグとキャプションを小文字に変換し、大文字小文字を区別せずに比較します。
            3. 除外キーワードのいずれかがタグまたはキャプションに含まれているかを確認します。
            4. 除外キーワードが一致する場合、その画像IDを `image_ids` から削除します。
            5. フィルタリングされた画像IDのセットを返します。
        """
        image_ids_copy = image_ids.copy()  # `set` のコピーを作成します
        for image_id in image_ids_copy:
            annotations = self.repository.get_image_annotations(image_id)
            tags = [tag['tag'].lower() for tag in annotations.get('tags', [])]
            captions = [caption['caption'].lower() for caption in annotations.get('captions', [])]
            # 除外キーワードのチェック
            annotations = tags + captions
            exclude_match = any(keyword.lower() in annotation for keyword in exclude_keywords for annotation in annotations)

            if exclude_match:
                image_ids.remove(image_id)  # `set` から直接削除します

        return image_ids

    def detect_duplicate_image(self, image_path: Path) -> Optional[int]:
        """
        画像の重複を検出し、重複する場合はその画像のIDを返す。
        名前による高速な検索と、pHashによる正確な重複検知を組み合わせて使用。

        Args:
            image_path (Path): 検査する画像ファイルのパス

        Returns:
            Optional[int]: 重複する画像が見つかった場合はそのimage_id、見つからない場合はNone
        """
        image_name = image_path.name

        # まず名前で高速に検索
        image_id = self.repository.get_image_id_by_name(image_name)
        if image_id is not None:
            self.logger.info(f"画像名の一致を検出: {image_name}")
            return image_id

        # 名前で見つからない場合、pHashを計算して検索
        try:
            with Image.open(image_path) as img:
                phash = str(imagehash.phash(img))

            image_id = self.repository.get_image_id_by_phash(phash)
            if image_id is not None:
                self.logger.info(f"pHashの一致を検出: {image_name}")
            return image_id
        except Exception as e:
            self.logger.error(f"pHash計算中にエラーが発生: {e}")
            return None

    def get_total_image_count(self):
        """データベース内に登録された編集前画像の総数を取得"""
        count = self.repository.get_total_image_count()
        return count

    def check_processed_image_exists(self, image_id: int, target_resolution: int) -> Optional[dict]:
        """
        指定された画像IDと目標解像度に一致する処理済み画像が存在するかチェックします。

        Args:
            image_id (int): 元画像のID
            target_resolution (int): 目標解像度

        Returns:
            Optional[dict]: 処理済み画像が存在する場合はそのメタデータ、存在しない場合はNone
        """
        try:
            processed_image = self.repository.get_processed_image(image_id, target_resolution)

            if processed_image:
                self.logger.info(f"指定解像度の画像は保存済みです: Image id {image_id}")
                return processed_image
            self.logger.info(f"ID {image_id} の画像に解像度 {target_resolution} に一致する処理済み画像が見つかりませんでした")
            return None
        except Exception as e:
            current_method = inspect.currentframe().f_code.co_name
            error_msg = (f"{current_method}: 処理済み画像のチェック中にエラーが発生しました。"
                         f" image_id={image_id}, target_resolution={target_resolution}. エラー: {str(e)}")
            self.logger.error(error_msg)
            self.logger.error(f"トレースバック:\n{traceback.format_exc()}")
            return None

    def filter_recent_annotations(self, annotations: dict) -> dict:
        """
        最新のアノテーションのみをフィルタリングします。

        Args:
            annotations (dict): 'tags' と 'captions' キーを持つ辞書

        Returns:
            dict: フィルタリングされたアノテーション
        """
        # 1. 最新の更新時刻を見つける
        latest_update = self._find_latest_update(annotations)

        # 2. 時間範囲を計算
        latest_datetime = datetime.fromisoformat(latest_update)
        time_threshold = latest_datetime - timedelta(minutes=5)
        self.logger.debug(f"最新の更新時刻 {latest_datetime} から {time_threshold} 以内に更新されたアノテーションをエクスポート")
        # 3. 5分以内に更新されたアノテーションのみをフィルタリング
        filtered_tags = [
            tag for tag in annotations['tags']
            if 'updated_at' in tag and tag['updated_at'] >= time_threshold
        ]

        filtered_captions = [
            caption for caption in annotations['captions']
            if 'updated_at' in caption and caption['updated_at'] >= time_threshold
        ]

        return {
            'tags': filtered_tags,
            'captions': filtered_captions
        }

    def _find_latest_update(self, annotations: dict) -> str:
        """
        アノテーションの中で最新の更新時刻を見つけます。

        Args:
            annotations (dict): 'tags' と 'captions' キーを持つ辞書

        Returns:
            str: 最新の更新時刻（ISO形式の文字列）
        """
        all_updates = []
        for tag in annotations['tags']:
            if 'updated_at' in tag:
                all_updates.append(tag['updated_at'])
        for caption in annotations['captions']:
            if 'updated_at' in caption:
                all_updates.append(caption['updated_at'])

        if not all_updates:
            return None  # 更新時刻が見つからない場合

        return max(all_updates)

    def get_tag_id_in_tag_database(self, tag: str) -> Optional[int]:
        """タグ文字列からタグデータベース内のタグIDを取得する

        Args:
            tag (str): 検索するタグ文字列

        Returns:
            Optional[int]: タグID。見つからない場合はNone
        """
        return self.repository.find_tag_id(tag)

```

### src\editor\image_processor.py

```
"""
画像編集スクリプト
- 画像の保存
- 画像の色域を変換
- 画像をリサイズ
"""
import cv2
from pathlib import Path
from spandrel import ModelLoader, ImageModelDescriptor
import torch
import numpy as np
from PIL import Image
from module.file_sys import FileSystemManager
from module.log import get_logger
from typing import Optional
from scipy import ndimage

class ImageProcessingManager:
    def __init__(self, file_system_manager: FileSystemManager, target_resolution: int,
                 preferred_resolutions: list[tuple[int, int]]):
        """
        ImageProcessingManagerを初期化
        デフォルト値はmodule/config.pyに定義

        Args:
            file_system_manager (FileSystemManager): ファイルシステムマネージャ
            target_resolution (int): 目標解像度
            preferred_resolutions (list[tuple[int, int]]): 優先解像度リスト #TODO: 解像度じゃなくてアスペクト比表記のほうがいいかも
        """
        self.logger = get_logger(__name__)
        self.file_system_manager = file_system_manager
        self.target_resolution = target_resolution

        try:
            # ImageProcessorの初期化
            self.image_processor = ImageProcessor(self.file_system_manager, target_resolution, preferred_resolutions)
            self.logger.info("ImageProcessingManagerが正常に初期化。")

        except Exception as e:
            message = f"ImageProcessingManagerの初期化中エラー: {e}"
            self.logger.error(message)
            raise ValueError(message) from e

    def process_image(self, db_stored_original_path: Path, original_has_alpha: bool, original_mode: str, upscaler: str = None) -> Optional[Image.Image]:
        """
        画像を処理し、処理後の画像オブジェクトを返す

        Args:
            db_stored_original_path (Path): 処理する画像ファイルのパス
            original_has_alpha (bool): 元画像がアルファチャンネルを持つかどうか
            original_mode (str): 元画像のモード (例: 'RGB', 'CMYK', 'P')
            upscaler (str): アップスケーラーの名前

        Returns:
            Optional[Image.Image]: 処理済み画像オブジェクト。処理不要の場合はNone

        """
        try:
            with Image.open(db_stored_original_path) as img:
                cropped_img = AutoCrop.auto_crop_image(img)

                converted_img = self.image_processor.normalize_color_profile(cropped_img, original_has_alpha, original_mode)

                if max(cropped_img.width, cropped_img.height) < self.target_resolution:
                    if upscaler: #TODO: アップスケールした画像はそれを示すデータも保存すべきか？
                        if converted_img.mode == 'RGBA':
                            self.logger.info(f"RGBA 画像のためアップスケールをスキップ: {db_stored_original_path}")
                        else:
                            self.logger.debug(f"長編が指定解像度未満のため{db_stored_original_path}をアップスケールします: {upscaler}")
                            converted_img = Upscaler.upscale_image(converted_img, upscaler)
                            if max(converted_img.width, converted_img.height) < self.target_resolution:
                                self.logger.info(f"画像サイズが小さすぎるため処理をスキップ: {db_stored_original_path}")
                                return None
                resized_img = self.image_processor.resize_image(converted_img)

                return resized_img

        except Exception as e:
            self.logger.error("画像処理中にエラーが発生しました: %s", e)

class ImageProcessor:
    logger = get_logger("ImageProcessor")
    def __init__(self, file_system_manager: FileSystemManager, target_resolution: int, preferred_resolutions: list[tuple[int, int]]) -> None:
        self.logger = ImageProcessor.logger
        self.file_system_manager = file_system_manager
        self.target_resolution = target_resolution
        self.preferred_resolutions = preferred_resolutions

    @staticmethod
    def normalize_color_profile(img: Image.Image, has_alpha: bool, mode: str = 'RGB') -> Image.Image:
        """
        画像の色プロファイルを正規化し、必要に応じて色空間変換を行う。

        Args:
            img (Image.Image): 処理する画像
            has_alpha (bool): 透過情報（アルファチャンネル）の有無
            mode (str): 画像のモード (例: 'RGB', 'CMYK', 'P')

        Returns:
            Image.Image: 色空間が正規化された画像
        """
        try:
            if mode in ['RGB', 'RGBA']:
                return img.convert('RGBA') if has_alpha else img.convert('RGB')
            elif mode == 'CMYK':
                # CMYKからRGBに変換
                return img.convert('RGB')
            elif mode == 'P':
                # パレットモードはRGBに変換してから処理
                return ImageProcessor.normalize_color_profile(img.convert('RGB'), has_alpha, 'RGB')
            else:
                # サポートされていないモード
                ImageProcessor.logger.warning("ImageProcessor.normalize_color_profile サポートされていないモード: %s", mode)
                return img.convert('RGBA') if has_alpha else img.convert('RGB')

        except Exception as e:
            ImageProcessor.logger.error(f"ImageProcessor.normalize_color_profile :{e}")
            raise

    def _find_matching_resolution(self, original_width: int, original_height: int) -> Optional[tuple[int, int]]:
        """SDでよく使う解像度と同じアスペクト比の解像度を探す

        Args:
            original_width (int): もとの画像の幅
            original_height (int): もとの画像の高さ

        Returns:
            Optional[tuple[int, int]]: 同じアスペクト比の解像度のタプル
        """
        if original_width < self.target_resolution and original_height < self.target_resolution:
            print(f'find_matching_resolution Error: 意図しない小さな画像を受け取った: {original_width}x{original_height}')
            return None

        aspect_ratio = original_width / original_height

        matching_resolutions = []
        for res in self.preferred_resolutions:
            if res[0] / res[1] == aspect_ratio:
                matching_resolutions.append(res)

        if matching_resolutions:
            target_area = self.target_resolution ** 2
            return min(matching_resolutions, key=lambda res: abs((res[0] * res[1]) - target_area))
        return None

    def resize_image(self, img: Image.Image) -> Image.Image:
        original_width, original_height = img.size
        matching_resolution = self._find_matching_resolution(original_width, original_height)

        if matching_resolution:
            new_width, new_height = matching_resolution
        else:
            aspect_ratio = original_width / original_height

            # max_dimensionに基づいて長辺を計算
            if original_width > original_height:
                new_width = self.target_resolution
                new_height = int(new_width / aspect_ratio)
            else:
                new_height = self.target_resolution
                new_width = int(new_height * aspect_ratio)

            # 両辺を32の倍数に調整
            new_width = round(new_width / 32) * 32
            new_height = round(new_height / 32) * 32

        # アスペクト比を保ちつつ、新しいサイズでリサイズ
        return img.resize((new_width, new_height), Image.Resampling.LANCZOS)


class AutoCrop:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(AutoCrop, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance

    def _initialize(self):
        self.logger = get_logger(__name__)

    @classmethod
    def auto_crop_image(cls, pil_image: Image.Image) -> Image.Image:
        instance = cls()
        return instance._auto_crop_image(pil_image)

    @staticmethod
    def _convert_to_gray(image: np.ndarray) -> np.ndarray:
        """RGBまたはRGBA画像をグレースケールに変換する"""
        if image.ndim == 2:
            return image
        if image.shape[2] == 3:
            return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        if image.shape[2] == 4:
            return cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_RGBA2RGB), cv2.COLOR_RGB2GRAY)
        raise ValueError(f"サポートされていない画像形式です。形状: {image.shape}")

    @staticmethod
    def _calculate_edge_strength(gray_image: np.ndarray) -> np.ndarray:
        """グレースケール画像でエッジの強さを計算する"""
        return ndimage.sobel(gray_image)

    @staticmethod
    def _get_slices(height: int, width: int) -> list[tuple[slice, slice]]:
        """画像の特定の領域（上下左右および中央）をスライスで定義する"""
        return [
            (slice(0, height // 20), slice(None)),  # top
            (slice(-height // 20, None), slice(None)),  # bottom
            (slice(None), slice(0, width // 20)),  # left
            (slice(None), slice(-width // 20, None)),  # right
            (slice(height // 5, 4 * height // 5), slice(width // 5, 4 * width // 5))  # center
        ]

    @staticmethod
    def _calculate_region_statistics(gray_image: np.ndarray, edges: np.ndarray, slices: list[tuple[slice, slice]]) -> tuple[list[float], list[float], list[float]]:
        """各領域の平均値、標準偏差、およびエッジ強度を計算する"""
        means = [np.mean(gray_image[s]) for s in slices]
        stds = [np.std(gray_image[s]) for s in slices]
        edge_strengths = [np.mean(edges[s]) for s in slices]
        return means, stds, edge_strengths

    @staticmethod
    def _evaluate_edge(means: list[float], stds: list[float], edge_strengths: list[float],
                       edge_index: int, center_index: int,
                       color_threshold: float, std_threshold: float, edge_threshold: float) -> bool:
        """各辺の評価を行う"""
        color_diff = abs(means[edge_index] - means[center_index]) / 255
        is_uniform = stds[edge_index] < std_threshold * 255
        has_strong_edge = edge_strengths[edge_index] > edge_threshold * 255
        return color_diff > color_threshold and (is_uniform or has_strong_edge)

    @staticmethod
    def _detect_gradient(means: list[float], gradient_threshold: float) -> bool:
        """グラデーションを検出する"""
        vertical_gradient = abs(means[0] - means[1]) / 255
        horizontal_gradient = abs(means[2] - means[3]) / 255
        return vertical_gradient > gradient_threshold or horizontal_gradient > gradient_threshold

    @staticmethod
    def _detect_border_shape(image: np.ndarray, color_threshold: float = 0.15, std_threshold: float = 0.05,
                             edge_threshold: float = 0.1, gradient_threshold: float = 0.5) -> list[str]:
        height, width = image.shape[:2]
        gray_image = AutoCrop._convert_to_gray(image)
        edges = AutoCrop._calculate_edge_strength(gray_image)
        slices = AutoCrop._get_slices(height, width)
        means, stds, edge_strengths = AutoCrop._calculate_region_statistics(gray_image, edges, slices)

        detected_borders = []
        if AutoCrop._evaluate_edge(means, stds, edge_strengths, 0, 4, color_threshold, std_threshold, edge_threshold):
            detected_borders.append("TOP")
        if AutoCrop._evaluate_edge(means, stds, edge_strengths, 1, 4, color_threshold, std_threshold, edge_threshold):
            detected_borders.append("BOTTOM")
        if AutoCrop._evaluate_edge(means, stds, edge_strengths, 2, 4, color_threshold, std_threshold, edge_threshold):
            detected_borders.append("LEFT")
        if AutoCrop._evaluate_edge(means, stds, edge_strengths, 3, 4, color_threshold, std_threshold, edge_threshold):
            detected_borders.append("RIGHT")

        if AutoCrop._detect_gradient(means, gradient_threshold):
            return []  # グラデーションが検出された場合は境界なしとする

        return detected_borders

    def _get_crop_area(self, np_image: np.ndarray) -> Optional[tuple[int, int, int, int]]:
        """
        クロップ領域を検出するためのメソッド。OpenCV を使ったエリア検出。
        """
        try:
            # 差分によるクロップ領域検出を追加
            complementary_color = [255 - np.mean(np_image[..., i]) for i in range(3)]
            background = np.full(np_image.shape, complementary_color, dtype=np.uint8)
            diff = cv2.absdiff(np_image, background)

            # 差分をグレースケール変換
            gray_diff = self._convert_to_gray(diff)

            # ブラー処理を適用してノイズ除去
            blurred_diff = cv2.GaussianBlur(gray_diff, (5, 5), 0)

            # しきい値処理
            thresh = cv2.adaptiveThreshold(
                blurred_diff,  # グレースケール化された差分画像を使う
                255,  # 最大値（白）
                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  # 適応的しきい値の種類（ガウス法）
                cv2.THRESH_BINARY,  # 2値化（白か黒）
                11,  # ピクセル近傍のサイズ (奇数で指定)
                2   # 平均値または加重平均から減算する定数
            )
            # エッジ検出
            edges = cv2.Canny(thresh, threshold1=30, threshold2=100)
            # 輪郭検出
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            if contours:
                x_min, y_min, x_max, y_max = np_image.shape[1], np_image.shape[0], 0, 0
                for contour in contours:
                    x, y, w, h = cv2.boundingRect(contour)
                    x_min, y_min = min(x_min, x), min(y_min, y)
                    x_max, y_max = max(x_max, x + w), max(y_max, y + h)

                # マスク処理によってクロップ領域を決定する
                mask = np.zeros(np_image.shape[:2], dtype=np.uint8)
                for contour in contours:
                    cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)

                # マスクの白い領域の座標を取得
                y_coords, x_coords = np.where(mask == 255)
                if len(x_coords) > 0 and len(y_coords) > 0:
                    x_min, y_min = np.min(x_coords), np.min(y_coords)
                    x_max, y_max = np.max(x_coords), np.max(y_coords)

                    # エリアを検証する必要がなくなり、ここで余分な領域を削るロジックを追加する
                    # TODO: このロジックは適切かどうかを検討する
                    margin = 5  # 余分に削るピクセル数
                    x_min = max(0, x_min + margin)
                    y_min = max(0, y_min + margin)
                    x_max = min(np_image.shape[1], x_max - margin)
                    y_max = min(np_image.shape[0], y_max - margin)

                    return x_min, y_min, x_max - x_min, y_max - y_min
            return None
        except Exception as e:
            self.logger.error(f"AutoCrop._get_crop_area: クロップ領域の検出中にエラーが発生しました: {e}")
            return None

    def _auto_crop_image(self, pil_image: Image.Image) -> Image.Image:
        """
        PIL.Image オブジェクトを受け取り、必要に応じて自動クロップを行います。

        Args:
            pil_image (Image.Image): 処理する PIL.Image オブジェクト

        Returns:
            Image.Image: クロップされた（または元の）PIL.Image オブジェクト
        """
        try:
            np_image = np.array(pil_image)
            crop_area = self._get_crop_area(np_image)

            # デバッグ情報の出力
            self.logger.debug(f"Crop area: {crop_area}")
            self.logger.debug(f"Original image size: {pil_image.size}")

            if crop_area:
                x, y, w, h = crop_area
                right, bottom = x + w, y + h
                cropped_image = pil_image.crop((x, y, right, bottom))
                self.logger.debug(f"Cropped image size: {cropped_image.size}")
                return cropped_image
            else:
                self.logger.debug("No crop area detected, returning original image")
                return pil_image
        except Exception as e:
            self.logger.error(f"自動クロップ処理中にエラーが発生しました: {e}")
            return pil_image

class Upscaler:
    # TODO: 暫定的なモデルパスとスケール値､もっと追加がしやすいようにする
    MODEL_PATHS: dict[str, tuple[Path, float]] = {
        "RealESRGAN_x4plus": (Path(r"H:\StabilityMatrix-win-x64\Data\Models\RealESRGAN\RealESRGAN_x4plus.pth"), 4.0),
    }
    def __init__(self, model_name: str):
        self.logger = get_logger(__name__)
        self.model_path, self.recommended_scale = self.MODEL_PATHS[model_name]
        self.model = self._load_model(self.model_path)
        self.model.cuda().eval()

    @classmethod
    def get_available_models(cls) -> list[str]:
        return list(cls.MODEL_PATHS.keys())

    @classmethod
    def upscale_image(cls, img: Image.Image, model_name: str, scale: float = None) -> Image.Image:
        upscaler = cls(model_name)
        scale = scale or upscaler.recommended_scale
        return upscaler._upscale(img, scale)

    def _load_model(self, model_path: Path) -> ImageModelDescriptor:
        model = ModelLoader().load_from_file(model_path)
        if not isinstance(model, ImageModelDescriptor):
            self.logger.error("読み込まれたモデルは ImageModelDescriptor のインスタンスではありません")
        return model

    def _upscale(self, img: Image.Image, scale: float) -> Image.Image:
        """
        画像をアップスケールする
        Args:
            img (Image.Image): アップスケールする画像
            scale (float): スケール倍率
        Returns:
            Image.Image: アップスケールされた画像
        """
        try:
            img_tensor = self._convert_image_to_tensor(img)
            with torch.no_grad():
                output = self.model(img_tensor)
            return self._convert_tensor_to_image(output, scale, img.size)
        except Exception as e:
            self.logger.error(f"アップスケーリング中のエラー: {e}")
            return img

    def _convert_image_to_tensor(self, image: Image.Image) -> torch.Tensor:
        img_np = np.array(image).astype(np.float32) / 255.0
        img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).cuda()
        return img_tensor

    def _convert_tensor_to_image(self, tensor: torch.Tensor, scale: float, original_size: tuple) -> Image.Image:
        output_np = tensor.squeeze().cpu().numpy().transpose(1, 2, 0)
        output_np = (output_np * 255).clip(0, 255).astype(np.uint8)
        output_image = Image.fromarray(output_np)
        expected_size = (int(original_size[0] * scale), int(original_size[1] * scale))
        if output_image.size != expected_size:
            output_image = output_image.resize(expected_size, Image.LANCZOS)
        return output_image

if __name__ == '__main__':
    ##自動クロップのテスト
    import matplotlib.pyplot as plt
    from PIL import Image

    img_path = Path(r'testimg\bordercrop\image_0001.png')
    img = Image.open(img_path)

    cropped_img = AutoCrop.auto_crop_image(img)
    plt.imshow(cropped_img)
    plt.show()
    print(cropped_img.size)
```

### src\gui\designer\DatasetExportWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>DatasetExportWidget</class>
 <widget class="QWidget" name="DatasetExportWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>1200</width>
    <height>800</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Dataset Export</string>
  </property>
  <layout class="QHBoxLayout" name="mainLayout">
   <item>
    <widget class="QSplitter" name="mainSplitter">
     <property name="orientation">
      <enum>Qt::Orientation::Horizontal</enum>
     </property>
     <widget class="QWidget" name="leftPanel">
      <layout class="QVBoxLayout" name="leftPanelLayout">
       <item>
        <widget class="TagFilterWidget" name="dbSearchWidget" native="true">
         <layout class="QVBoxLayout" name="filterLayout"/>
        </widget>
       </item>
       <item>
        <widget class="ThumbnailSelectorWidget" name="thumbnailSelector" native="true">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>0</horstretch>
           <verstretch>1</verstretch>
          </sizepolicy>
         </property>
        </widget>
       </item>
       <item>
        <widget class="QLabel" name="imageCountLabel">
         <property name="text">
          <string/>
         </property>
        </widget>
       </item>
      </layout>
     </widget>
     <widget class="QWidget" name="rightPanel">
      <layout class="QVBoxLayout" name="rightPanelLayout">
       <item>
        <widget class="ImagePreviewWidget" name="imagePreview" native="true">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>0</horstretch>
           <verstretch>1</verstretch>
          </sizepolicy>
         </property>
        </widget>
       </item>
       <item>
        <widget class="QGroupBox" name="exportGroupBox">
         <property name="title">
          <string>Export Settings</string>
         </property>
         <layout class="QVBoxLayout" name="exportLayout">
          <item>
           <widget class="DirectoryPickerWidget" name="exportDirectoryPicker" native="true"/>
          </item>
          <item>
           <widget class="QLabel" name="exportFormatLabel">
            <property name="text">
             <string>Export Format:</string>
            </property>
           </widget>
          </item>
          <item>
           <layout class="QHBoxLayout" name="exportFormatLayout">
            <item>
             <widget class="QCheckBox" name="checkBoxTxtCap">
              <property name="text">
               <string>txt/caption</string>
              </property>
              <property name="checked">
               <bool>true</bool>
              </property>
             </widget>
            </item>
            <item>
             <widget class="QCheckBox" name="checkBoxJson">
              <property name="text">
               <string>metadata.json</string>
              </property>
             </widget>
            </item>
           </layout>
          </item>
          <item>
           <widget class="QCheckBox" name="latestcheckBox">
            <property name="text">
             <string>最後に更新されたアノテーションだけを出力する</string>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QCheckBox" name="MergeCaptionWithTagscheckBox">
            <property name="text">
             <string>captionとして保存された文字列も &quot;.tag&quot; に保存する</string>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QPushButton" name="exportButton">
            <property name="text">
             <string>Export Dataset</string>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QProgressBar" name="exportProgressBar">
            <property name="value">
             <number>0</number>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QLabel" name="statusLabel">
            <property name="text">
             <string>Status: Ready</string>
            </property>
           </widget>
          </item>
         </layout>
        </widget>
       </item>
      </layout>
     </widget>
    </widget>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>ImagePreviewWidget</class>
   <extends>QWidget</extends>
   <header location="global">ImagePreviewWidget</header>
   <container>1</container>
   <slots>
    <slot>load_image()</slot>
    <slot>update_model_options()</slot>
    <slot>send_vision_prompt()</slot>
   </slots>
  </customwidget>
  <customwidget>
   <class>ThumbnailSelectorWidget</class>
   <extends>QWidget</extends>
   <header location="global">ThumbnailSelectorWidget</header>
   <container>1</container>
   <slots>
    <signal>on_thumbnail_clicked()</signal>
    <signal>imageSelected()</signal>
   </slots>
  </customwidget>
  <customwidget>
   <class>TagFilterWidget</class>
   <extends>QWidget</extends>
   <header location="global">TagFilterWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>DirectoryPickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">DirectoryPickerWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\DatasetOverviewWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>DatasetOverviewWidget</class>
 <widget class="QWidget" name="DatasetOverviewWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>350</width>
    <height>777</height>
   </rect>
  </property>
  <property name="sizePolicy">
   <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
    <horstretch>1</horstretch>
    <verstretch>0</verstretch>
   </sizepolicy>
  </property>
  <property name="windowTitle">
   <string>Dataset Overview</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout_3">
   <item>
    <widget class="QSplitter" name="mainSplitter">
     <property name="sizePolicy">
      <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
       <horstretch>2</horstretch>
       <verstretch>1</verstretch>
      </sizepolicy>
     </property>
     <property name="orientation">
      <enum>Qt::Orientation::Horizontal</enum>
     </property>
     <property name="handleWidth">
      <number>5</number>
     </property>
     <widget class="QWidget" name="infoContainer" native="true">
      <property name="sizePolicy">
       <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
        <horstretch>0</horstretch>
        <verstretch>1</verstretch>
       </sizepolicy>
      </property>
      <property name="minimumSize">
       <size>
        <width>0</width>
        <height>0</height>
       </size>
      </property>
      <layout class="QVBoxLayout" name="verticalLayout_2">
       <item>
        <widget class="TagFilterWidget" name="dbSearchWidget" native="true">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>1</horstretch>
           <verstretch>0</verstretch>
          </sizepolicy>
         </property>
        </widget>
       </item>
       <item>
        <widget class="QSplitter" name="infoSplitter">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>0</horstretch>
           <verstretch>0</verstretch>
          </sizepolicy>
         </property>
         <property name="orientation">
          <enum>Qt::Orientation::Vertical</enum>
         </property>
         <widget class="QGroupBox" name="metadataGroupBox">
          <property name="sizePolicy">
           <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
            <horstretch>0</horstretch>
            <verstretch>0</verstretch>
           </sizepolicy>
          </property>
          <property name="minimumSize">
           <size>
            <width>0</width>
            <height>0</height>
           </size>
          </property>
          <property name="title">
           <string/>
          </property>
          <layout class="QFormLayout" name="metadataLayout">
           <item row="0" column="0">
            <widget class="QLabel" name="fileNameLabel">
             <property name="text">
              <string>ファイル名:</string>
             </property>
            </widget>
           </item>
           <item row="0" column="1">
            <widget class="QLabel" name="fileNameValueLabel"/>
           </item>
           <item row="1" column="0">
            <widget class="QLabel" name="imagePathLabel">
             <property name="text">
              <string>画像パス:</string>
             </property>
            </widget>
           </item>
           <item row="1" column="1">
            <widget class="QLabel" name="imagePathValueLabel"/>
           </item>
           <item row="2" column="0">
            <widget class="QLabel" name="extensionLabel">
             <property name="text">
              <string>拡張子:</string>
             </property>
            </widget>
           </item>
           <item row="2" column="1">
            <widget class="QLabel" name="extensionValueLabel"/>
           </item>
           <item row="3" column="0">
            <widget class="QLabel" name="formatLabel">
             <property name="text">
              <string>フォーマット:</string>
             </property>
            </widget>
           </item>
           <item row="3" column="1">
            <widget class="QLabel" name="formatValueLabel"/>
           </item>
           <item row="4" column="0">
            <widget class="QLabel" name="modeLabel">
             <property name="text">
              <string>モード:</string>
             </property>
            </widget>
           </item>
           <item row="4" column="1">
            <widget class="QLabel" name="modeValueLabel"/>
           </item>
           <item row="5" column="0">
            <widget class="QLabel" name="alphaChannelLabel">
             <property name="text">
              <string>アルファチャンネル:</string>
             </property>
            </widget>
           </item>
           <item row="5" column="1">
            <widget class="QLabel" name="alphaChannelValueLabel"/>
           </item>
           <item row="6" column="0">
            <widget class="QLabel" name="resolutionLabel">
             <property name="text">
              <string>解像度:</string>
             </property>
            </widget>
           </item>
           <item row="6" column="1">
            <widget class="QLabel" name="resolutionValueLabel"/>
           </item>
           <item row="7" column="0">
            <widget class="QLabel" name="aspectRatioLabel">
             <property name="text">
              <string>アスペクト比:</string>
             </property>
            </widget>
           </item>
           <item row="7" column="1">
            <widget class="QLabel" name="aspectRatioValueLabel"/>
           </item>
          </layout>
         </widget>
         <widget class="QGroupBox" name="annotationGroupBox">
          <property name="sizePolicy">
           <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
            <horstretch>0</horstretch>
            <verstretch>0</verstretch>
           </sizepolicy>
          </property>
          <property name="title">
           <string/>
          </property>
          <layout class="QGridLayout" name="gridLayout_2">
           <item row="1" column="0">
            <widget class="QTextEdit" name="tagsTextEdit">
             <property name="readOnly">
              <bool>true</bool>
             </property>
            </widget>
           </item>
           <item row="3" column="0">
            <widget class="QTextEdit" name="captionTextEdit">
             <property name="readOnly">
              <bool>true</bool>
             </property>
            </widget>
           </item>
           <item row="0" column="0">
            <widget class="QLabel" name="tagsLabel">
             <property name="text">
              <string>タグ:</string>
             </property>
            </widget>
           </item>
           <item row="2" column="0">
            <widget class="QLabel" name="captionLabel">
             <property name="text">
              <string>キャプション:</string>
             </property>
            </widget>
           </item>
          </layout>
         </widget>
        </widget>
       </item>
      </layout>
     </widget>
     <widget class="QWidget" name="imageContainer" native="true">
      <property name="sizePolicy">
       <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
        <horstretch>1</horstretch>
        <verstretch>2</verstretch>
       </sizepolicy>
      </property>
      <property name="minimumSize">
       <size>
        <width>0</width>
        <height>0</height>
       </size>
      </property>
      <layout class="QVBoxLayout" name="verticalLayout">
       <item>
        <widget class="ImagePreviewWidget" name="ImagePreview" native="true">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>0</horstretch>
           <verstretch>0</verstretch>
          </sizepolicy>
         </property>
        </widget>
       </item>
       <item>
        <widget class="ThumbnailSelectorWidget" name="thumbnailSelector" native="true">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>0</horstretch>
           <verstretch>0</verstretch>
          </sizepolicy>
         </property>
        </widget>
       </item>
      </layout>
     </widget>
    </widget>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>ImagePreviewWidget</class>
   <extends>QWidget</extends>
   <header location="global">ImagePreviewWidget</header>
   <container>1</container>
   <slots>
    <slot>load_image()</slot>
    <slot>update_model_options()</slot>
    <slot>send_vision_prompt()</slot>
   </slots>
  </customwidget>
  <customwidget>
   <class>ThumbnailSelectorWidget</class>
   <extends>QWidget</extends>
   <header location="global">ThumbnailSelectorWidget</header>
   <container>1</container>
   <slots>
    <signal>on_thumbnail_clicked()</signal>
    <signal>imageSelected()</signal>
   </slots>
  </customwidget>
  <customwidget>
   <class>TagFilterWidget</class>
   <extends>QWidget</extends>
   <header location="global">TagFilterWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\DirectoryPickerWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>DirectoryPickerWidget</class>
 <widget class="QWidget" name="DirectoryPickerWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>562</width>
    <height>253</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QHBoxLayout" name="horizontalLayout">
   <item>
    <widget class="PickerWidget" name="DirectoryPicker" native="true"/>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>PickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">PickerWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\FilePickerWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>FilePickerWidget</class>
 <widget class="QWidget" name="FilePickerWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>562</width>
    <height>253</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QHBoxLayout" name="horizontalLayout">
   <item>
    <widget class="PickerWidget" name="FilePicker" native="true"/>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>PickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">PickerWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\filterBoxWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>TagFilterWidget</class>
 <widget class="QWidget" name="TagFilterWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>400</width>
    <height>300</height>
   </rect>
  </property>
  <property name="sizePolicy">
   <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
    <horstretch>0</horstretch>
    <verstretch>0</verstretch>
   </sizepolicy>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout">
   <item>
    <widget class="QGroupBox" name="filterGroupBox">
     <property name="sizePolicy">
      <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
       <horstretch>0</horstretch>
       <verstretch>0</verstretch>
      </sizepolicy>
     </property>
     <property name="title">
      <string>Filter Criteria</string>
     </property>
     <layout class="QVBoxLayout" name="filterLayout">
      <item>
       <layout class="QHBoxLayout" name="filterTypeLayout">
        <item>
         <widget class="QLabel" name="filterTypeLabel">
          <property name="text">
           <string>Filter Type:</string>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QComboBox" name="filterTypeComboBox">
          <item>
           <property name="text">
            <string>Tags</string>
           </property>
          </item>
          <item>
           <property name="text">
            <string>Caption</string>
           </property>
          </item>
         </widget>
        </item>
        <item>
         <widget class="QRadioButton" name="andRadioButton">
          <property name="text">
           <string>AND検索</string>
          </property>
         </widget>
        </item>
       </layout>
      </item>
      <item>
       <widget class="QLineEdit" name="filterLineEdit">
        <property name="placeholderText">
         <string>Enter filter criteria</string>
        </property>
       </widget>
      </item>
      <item>
       <layout class="QHBoxLayout" name="resolutionLayout">
        <item>
         <widget class="QLabel" name="resolutionLabel">
          <property name="text">
           <string>Resolution:</string>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QComboBox" name="resolutionComboBox">
          <item>
           <property name="text">
            <string>512x512</string>
           </property>
          </item>
          <item>
           <property name="text">
            <string>768x768</string>
           </property>
          </item>
          <item>
           <property name="text">
            <string>1024x1024</string>
           </property>
          </item>
         </widget>
        </item>
       </layout>
      </item>
      <item>
       <widget class="QPushButton" name="applyFilterButton">
        <property name="text">
         <string>Apply Filters</string>
        </property>
       </widget>
      </item>
     </layout>
    </widget>
   </item>
  </layout>
 </widget>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\ImageEditWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>ImageEditWidget</class>
 <widget class="QWidget" name="ImageEditWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>758</width>
    <height>781</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout">
   <item>
    <widget class="QSplitter" name="splitterMainContent">
     <property name="sizePolicy">
      <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
       <horstretch>0</horstretch>
       <verstretch>2</verstretch>
      </sizepolicy>
     </property>
     <property name="orientation">
      <enum>Qt::Orientation::Horizontal</enum>
     </property>
     <widget class="QTableWidget" name="tableWidgetImageList">
      <property name="sizePolicy">
       <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
        <horstretch>1</horstretch>
        <verstretch>2</verstretch>
       </sizepolicy>
      </property>
      <property name="frameShape">
       <enum>QFrame::Shape::StyledPanel</enum>
      </property>
      <property name="frameShadow">
       <enum>QFrame::Shadow::Sunken</enum>
      </property>
      <property name="horizontalScrollMode">
       <enum>QAbstractItemView::ScrollMode::ScrollPerPixel</enum>
      </property>
      <attribute name="horizontalHeaderCascadingSectionResizes">
       <bool>false</bool>
      </attribute>
      <attribute name="horizontalHeaderMinimumSectionSize">
       <number>0</number>
      </attribute>
      <attribute name="horizontalHeaderDefaultSectionSize">
       <number>0</number>
      </attribute>
      <attribute name="horizontalHeaderHighlightSections">
       <bool>true</bool>
      </attribute>
      <attribute name="horizontalHeaderStretchLastSection">
       <bool>false</bool>
      </attribute>
      <attribute name="verticalHeaderVisible">
       <bool>false</bool>
      </attribute>
      <attribute name="verticalHeaderMinimumSectionSize">
       <number>50</number>
      </attribute>
      <attribute name="verticalHeaderDefaultSectionSize">
       <number>126</number>
      </attribute>
      <attribute name="verticalHeaderHighlightSections">
       <bool>false</bool>
      </attribute>
      <column>
       <property name="text">
        <string>サムネイル</string>
       </property>
      </column>
      <column>
       <property name="text">
        <string>ファイル名</string>
       </property>
      </column>
      <column>
       <property name="text">
        <string>パス</string>
       </property>
      </column>
      <column>
       <property name="text">
        <string>サイズ</string>
       </property>
      </column>
      <column>
       <property name="text">
        <string>既存タグ</string>
       </property>
      </column>
      <column>
       <property name="text">
        <string>既存キャプション</string>
       </property>
      </column>
     </widget>
     <widget class="QWidget" name="widget_PreviewArea_2">
      <layout class="QVBoxLayout" name="verticalImagePreview">
       <property name="spacing">
        <number>0</number>
       </property>
       <item>
        <widget class="ImagePreviewWidget" name="ImagePreview" native="true">
         <property name="sizePolicy">
          <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
           <horstretch>1</horstretch>
           <verstretch>0</verstretch>
          </sizepolicy>
         </property>
         <property name="minimumSize">
          <size>
           <width>126</width>
           <height>0</height>
          </size>
         </property>
         <widget class="QLabel" name="labelPreviewTitle">
          <property name="geometry">
           <rect>
            <x>0</x>
            <y>0</y>
            <width>177</width>
            <height>21</height>
           </rect>
          </property>
          <property name="sizePolicy">
           <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
            <horstretch>0</horstretch>
            <verstretch>0</verstretch>
           </sizepolicy>
          </property>
          <property name="text">
           <string>プレビュー</string>
          </property>
         </widget>
        </widget>
       </item>
      </layout>
     </widget>
    </widget>
   </item>
   <item>
    <layout class="QHBoxLayout" name="horizontalLayoutControlArea">
     <item>
      <widget class="QGroupBox" name="groupBoxEditOptions">
       <property name="title">
        <string>編集オプション</string>
       </property>
       <layout class="QHBoxLayout" name="horizontalLayout_EditOptions_2">
        <item>
         <widget class="QLabel" name="labelResizeOption">
          <property name="text">
           <string>リサイズ:</string>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QComboBox" name="comboBoxResizeOption">
          <item>
           <property name="text">
            <string>512x512</string>
           </property>
          </item>
          <item>
           <property name="text">
            <string>768x768</string>
           </property>
          </item>
          <item>
           <property name="text">
            <string>1024x1024</string>
           </property>
          </item>
         </widget>
        </item>
        <item>
         <widget class="QLabel" name="labelUpscaler">
          <property name="text">
           <string>アップスケーラー</string>
          </property>
         </widget>
        </item>
        <item>
         <widget class="QComboBox" name="comboBoxUpscaler">
          <property name="currentText">
           <string notr="true">None</string>
          </property>
          <item>
           <property name="text">
            <string>None</string>
           </property>
          </item>
         </widget>
        </item>
       </layout>
      </widget>
     </item>
     <item>
      <spacer name="horizontalSpacer">
       <property name="orientation">
        <enum>Qt::Orientation::Horizontal</enum>
       </property>
       <property name="sizeHint" stdset="0">
        <size>
         <width>40</width>
         <height>20</height>
        </size>
       </property>
      </spacer>
     </item>
     <item>
      <widget class="QPushButton" name="pushButtonStartProcess">
       <property name="text">
        <string>処理開始</string>
       </property>
      </widget>
     </item>
    </layout>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>ImagePreviewWidget</class>
   <extends>QWidget</extends>
   <header location="global">ImagePreviewWidget</header>
   <container>1</container>
   <slots>
    <slot>load_image()</slot>
    <slot>update_model_options()</slot>
    <slot>send_vision_prompt()</slot>
   </slots>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\ImagePreviewWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>ImagePreviewWidget</class>
 <widget class="QWidget" name="ImagePreviewWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>512</width>
    <height>512</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout">
   <property name="spacing">
    <number>0</number>
   </property>
   <property name="leftMargin">
    <number>0</number>
   </property>
   <property name="topMargin">
    <number>0</number>
   </property>
   <property name="rightMargin">
    <number>0</number>
   </property>
   <property name="bottomMargin">
    <number>0</number>
   </property>
   <item>
    <widget class="QGraphicsView" name="previewGraphicsView"/>
   </item>
  </layout>
 </widget>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\ImageTaggerWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>ImageTaggerWidget</class>
 <widget class="QWidget" name="ImageTaggerWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>355</width>
    <height>1116</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Image Tagger</string>
  </property>
  <layout class="QHBoxLayout" name="horizontalLayout">
   <item>
    <widget class="QSplitter" name="splitterMain">
     <property name="orientation">
      <enum>Qt::Orientation::Horizontal</enum>
     </property>
     <property name="sizes" stdset="0">
      <number>667</number>
     </property>
     <widget class="QWidget" name="taggingAreaWidget" native="true">
      <layout class="QVBoxLayout" name="verticalLayoutTaggingArea">
       <item>
        <layout class="QGridLayout" name="gridLayoutApiOptions">
         <item row="0" column="0">
          <widget class="QLabel" name="labelAPI">
           <property name="text">
            <string>API:</string>
           </property>
          </widget>
         </item>
         <item row="0" column="1">
          <widget class="QComboBox" name="comboBoxAPI"/>
         </item>
         <item row="1" column="0">
          <widget class="QLabel" name="labelModel">
           <property name="text">
            <string>モデル:</string>
           </property>
          </widget>
         </item>
         <item row="1" column="1">
          <widget class="QComboBox" name="comboBoxModel"/>
         </item>
         <item row="2" column="0">
          <widget class="QLabel" name="labelTagFormat">
           <property name="text">
            <string>FORMT:</string>
           </property>
          </widget>
         </item>
         <item row="2" column="1">
          <widget class="QComboBox" name="comboBoxTagFormat"/>
         </item>
        </layout>
       </item>
       <item>
        <widget class="QCheckBox" name="lowRescheckBox">
         <property name="text">
          <string>API負荷軽減用低解像度画像を使用</string>
         </property>
        </widget>
       </item>
       <item>
        <widget class="QGroupBox" name="groupBoxPrompt">
         <property name="title">
          <string>プロンプト</string>
         </property>
         <layout class="QVBoxLayout" name="verticalLayout">
          <item>
           <widget class="QTextEdit" name="textEditMainPrompt">
            <property name="sizePolicy">
             <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
              <horstretch>0</horstretch>
              <verstretch>2</verstretch>
             </sizepolicy>
            </property>
            <property name="placeholderText">
             <string>プロンプトを入力 (例: 高画質, 具体的な描写など)</string>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QTextEdit" name="textEditAddPrompt">
            <property name="sizePolicy">
             <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
              <horstretch>0</horstretch>
              <verstretch>1</verstretch>
             </sizepolicy>
            </property>
            <property name="placeholderText">
             <string>選択した画像の大まかな傾向を指示するプロンプト</string>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QPushButton" name="pushButtonGenerate">
            <property name="text">
             <string>タグ/キャプション生成</string>
            </property>
           </widget>
          </item>
         </layout>
        </widget>
       </item>
       <item>
        <widget class="QGroupBox" name="groupBoxResults">
         <property name="title">
          <string>結果</string>
         </property>
         <layout class="QGridLayout" name="gridLayout">
          <item row="4" column="0">
           <widget class="QSlider" name="scoreSlider">
            <property name="toolTip">
             <string>&lt;html&gt;&lt;head/&gt;&lt;body&gt;&lt;p&gt;スコア&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</string>
            </property>
            <property name="maximum">
             <number>1000</number>
            </property>
            <property name="singleStep">
             <number>1</number>
            </property>
            <property name="orientation">
             <enum>Qt::Orientation::Horizontal</enum>
            </property>
           </widget>
          </item>
          <item row="2" column="0">
           <widget class="QTextEdit" name="textEditCaption"/>
          </item>
          <item row="1" column="0">
           <widget class="QTextEdit" name="textEditTags"/>
          </item>
          <item row="6" column="0">
           <layout class="QHBoxLayout" name="horizontalLayoutSave">
            <item>
             <widget class="DirectoryPickerWidget" name="DirectoryPickerSave" native="true"/>
            </item>
            <item>
             <widget class="QPushButton" name="pushButtonSave">
              <property name="text">
               <string>保存</string>
              </property>
             </widget>
            </item>
           </layout>
          </item>
          <item row="5" column="0">
           <widget class="QWidget" name="savecheckWidget" native="true">
            <layout class="QHBoxLayout" name="horizontalLayout_2">
             <item>
              <widget class="QCheckBox" name="checkBoxText">
               <property name="text">
                <string>txt</string>
               </property>
              </widget>
             </item>
             <item>
              <widget class="QCheckBox" name="checkBoxJson">
               <property name="text">
                <string>Json</string>
               </property>
              </widget>
             </item>
             <item>
              <widget class="QCheckBox" name="checkBoxDB">
               <property name="text">
                <string>DataBase</string>
               </property>
              </widget>
             </item>
            </layout>
           </widget>
          </item>
          <item row="3" column="0">
           <widget class="QTextEdit" name="textEditGenaiPrompt">
            <property name="sizePolicy">
             <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
              <horstretch>0</horstretch>
              <verstretch>1</verstretch>
             </sizepolicy>
            </property>
            <property name="placeholderText">
             <string>生成用Prompt｡ &quot;, &quot;で分割されてタグとして登録される</string>
            </property>
           </widget>
          </item>
         </layout>
        </widget>
       </item>
      </layout>
     </widget>
     <widget class="QWidget" name="imageAreaWidget" native="true">
      <layout class="QVBoxLayout" name="verticalLayoutImageArea">
       <item>
        <widget class="TagFilterWidget" name="dbSearchWidget" native="true"/>
       </item>
       <item>
        <widget class="QSplitter" name="splitterImage">
         <property name="orientation">
          <enum>Qt::Orientation::Vertical</enum>
         </property>
         <property name="sizes" stdset="0">
          <number>100</number>
         </property>
         <widget class="ImagePreviewWidget" name="ImagePreview" native="true">
          <property name="sizePolicy">
           <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
            <horstretch>1</horstretch>
            <verstretch>1</verstretch>
           </sizepolicy>
          </property>
         </widget>
         <widget class="ThumbnailSelectorWidget" name="ThumbnailSelector" native="true">
          <property name="sizePolicy">
           <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
            <horstretch>2</horstretch>
            <verstretch>2</verstretch>
           </sizepolicy>
          </property>
         </widget>
        </widget>
       </item>
      </layout>
     </widget>
    </widget>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>ImagePreviewWidget</class>
   <extends>QWidget</extends>
   <header location="global">ImagePreviewWidget</header>
   <container>1</container>
   <slots>
    <slot>load_image()</slot>
    <slot>update_model_options()</slot>
    <slot>send_vision_prompt()</slot>
   </slots>
  </customwidget>
  <customwidget>
   <class>ThumbnailSelectorWidget</class>
   <extends>QWidget</extends>
   <header location="global">ThumbnailSelectorWidget</header>
   <container>1</container>
   <slots>
    <signal>on_thumbnail_clicked()</signal>
    <signal>imageSelected()</signal>
   </slots>
  </customwidget>
  <customwidget>
   <class>DirectoryPickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">DirectoryPickerWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>TagFilterWidget</class>
   <extends>QWidget</extends>
   <header location="global">TagFilterWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\MainWindow.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>mainWindow</class>
 <widget class="QMainWindow" name="mainWindow">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>802</width>
    <height>565</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>画像処理アプリケーション</string>
  </property>
  <widget class="QWidget" name="centralWidget">
   <layout class="QVBoxLayout" name="verticalLayout">
    <item>
     <widget class="DirectoryPickerWidget" name="datasetSelector" native="true"/>
    </item>
    <item>
     <widget class="QSplitter" name="mainWindowSplitter">
      <property name="sizePolicy">
       <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
        <horstretch>2</horstretch>
        <verstretch>0</verstretch>
       </sizepolicy>
      </property>
      <property name="orientation">
       <enum>Qt::Orientation::Horizontal</enum>
      </property>
      <widget class="QListWidget" name="sidebarList">
       <property name="maximumSize">
        <size>
         <width>512</width>
         <height>16777215</height>
        </size>
       </property>
       <item>
        <property name="text">
         <string>画像編集</string>
        </property>
       </item>
       <item>
        <property name="text">
         <string>自動タグ付け</string>
        </property>
       </item>
       <item>
        <property name="text">
         <string>データセット概要</string>
        </property>
       </item>
       <item>
        <property name="text">
         <string>タグ/キャプション編集</string>
        </property>
       </item>
       <item>
        <property name="text">
         <string>エクスポート</string>
        </property>
       </item>
       <item>
        <property name="text">
         <string>バッチ処理</string>
        </property>
       </item>
       <item>
        <property name="text">
         <string>設定</string>
        </property>
       </item>
      </widget>
      <widget class="QStackedWidget" name="contentStackedWidget">
       <property name="currentIndex">
        <number>0</number>
       </property>
       <widget class="ImageEditWidget" name="pageImageEdit"/>
       <widget class="ImageTaggerWidget" name="pageImageTagger"/>
       <widget class="DatasetOverviewWidget" name="pageDatasetOverview"/>
       <widget class="QWidget" name="pageTagCaptionEdit">
        <layout class="QVBoxLayout" name="verticalLayoutTagCaptionEdit">
         <item>
          <widget class="QLabel" name="labelTagCaptionEditTitle">
           <property name="text">
            <string>タグ/キャプション編集</string>
           </property>
          </widget>
         </item>
        </layout>
       </widget>
       <widget class="DatasetExportWidget" name="pageExport"/>
       <widget class="QWidget" name="pageBatch">
        <layout class="QVBoxLayout" name="verticalLayout_2">
         <item>
          <widget class="QLabel" name="labelBatch">
           <property name="text">
            <string>バッチ処理</string>
           </property>
          </widget>
         </item>
        </layout>
       </widget>
       <widget class="SettingsWidget" name="pageSettings"/>
      </widget>
     </widget>
    </item>
   </layout>
  </widget>
  <widget class="QMenuBar" name="menuBar">
   <property name="geometry">
    <rect>
     <x>0</x>
     <y>0</y>
     <width>802</width>
     <height>33</height>
    </rect>
   </property>
   <widget class="QMenu" name="menuFile">
    <property name="title">
     <string>ファイル</string>
    </property>
    <addaction name="actionOpen"/>
    <addaction name="actionSave"/>
    <addaction name="actionExit"/>
   </widget>
   <widget class="QMenu" name="menuHelp">
    <property name="title">
     <string>ヘルプ</string>
    </property>
    <addaction name="actionAbout"/>
   </widget>
   <addaction name="menuFile"/>
   <addaction name="menuHelp"/>
  </widget>
  <widget class="QStatusBar" name="statusBar"/>
  <action name="actionOpen">
   <property name="text">
    <string>開く</string>
   </property>
  </action>
  <action name="actionSave">
   <property name="text">
    <string>保存</string>
   </property>
  </action>
  <action name="actionExit">
   <property name="text">
    <string>終了</string>
   </property>
  </action>
  <action name="actionAbout">
   <property name="text">
    <string>このアプリについて</string>
   </property>
  </action>
 </widget>
 <customwidgets>
  <customwidget>
   <class>DirectoryPickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">DirectoryPickerWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>DatasetOverviewWidget</class>
   <extends>QWidget</extends>
   <header location="global">DatasetOverviewWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>ImageEditWidget</class>
   <extends>QWidget</extends>
   <header>ImageEditWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>ImageTaggerWidget</class>
   <extends>QWidget</extends>
   <header location="global">ImageTaggerWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>DatasetExportWidget</class>
   <extends>QWidget</extends>
   <header location="global">DatasetExportWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>SettingsWidget</class>
   <extends>QWidget</extends>
   <header location="global">SettingsWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\PickerWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>PickerWidget</class>
 <widget class="QWidget" name="PickerWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>540</width>
    <height>210</height>
   </rect>
  </property>
  <property name="minimumSize">
   <size>
    <width>80</width>
    <height>0</height>
   </size>
  </property>
  <property name="acceptDrops">
   <bool>true</bool>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QHBoxLayout" name="horizontalLayout">
   <item>
    <widget class="QLabel" name="labelPicker">
     <property name="text">
      <string>Path</string>
     </property>
    </widget>
   </item>
   <item>
    <widget class="QLineEdit" name="lineEditPicker">
     <property name="sizePolicy">
      <sizepolicy hsizetype="Expanding" vsizetype="Fixed">
       <horstretch>1</horstretch>
       <verstretch>0</verstretch>
      </sizepolicy>
     </property>
    </widget>
   </item>
   <item>
    <widget class="QComboBox" name="comboBoxHistory"/>
   </item>
   <item>
    <widget class="QPushButton" name="pushButtonPicker">
     <property name="text">
      <string>選択...</string>
     </property>
    </widget>
   </item>
  </layout>
 </widget>
 <resources/>
 <connections/>
 <slots>
  <slot>toggle_history_visibility()</slot>
 </slots>
</ui>

```

### src\gui\designer\ProgressWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>ProgressWidget</class>
 <widget class="QWidget" name="ProgressWidget">
  <property name="windowModality">
   <enum>Qt::WindowModality::WindowModal</enum>
  </property>
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>400</width>
    <height>113</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout">
   <item alignment="Qt::AlignmentFlag::AlignLeft">
    <widget class="QLabel" name="statusLabel">
     <property name="text">
      <string>待機中...</string>
     </property>
    </widget>
   </item>
   <item>
    <widget class="QProgressBar" name="progressBar">
     <property name="value">
      <number>0</number>
     </property>
     <property name="format">
      <string>%v / %m</string>
     </property>
    </widget>
   </item>
   <item alignment="Qt::AlignmentFlag::AlignRight">
    <widget class="QPushButton" name="cancelButton">
     <property name="text">
      <string>キャンセル</string>
     </property>
    </widget>
   </item>
  </layout>
 </widget>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\SettingsWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>SettingsWidget</class>
 <widget class="QWidget" name="SettingsWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>718</width>
    <height>681</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout_2">
   <item>
    <widget class="QScrollArea" name="scrollAreaMain">
     <property name="widgetResizable">
      <bool>true</bool>
     </property>
     <widget class="QWidget" name="scrollAreaWidgetContents">
      <property name="geometry">
       <rect>
        <x>0</x>
        <y>0</y>
        <width>694</width>
        <height>657</height>
       </rect>
      </property>
      <layout class="QVBoxLayout" name="layoutScrollArea">
       <item>
        <widget class="QGroupBox" name="groupBoxFolders">
         <property name="title">
          <string>フォルダ設定</string>
         </property>
         <layout class="QVBoxLayout" name="layoutFolders">
          <item>
           <widget class="DirectoryPickerWidget" name="dirPickerOutput" native="true"/>
          </item>
          <item>
           <widget class="DirectoryPickerWidget" name="dirPickerResponse" native="true"/>
          </item>
          <item>
           <widget class="DirectoryPickerWidget" name="dirPickerEditedOutput" native="true"/>
          </item>
         </layout>
        </widget>
       </item>
       <item>
        <widget class="QGroupBox" name="groupBoxApiSettings">
         <property name="title">
          <string>API KEY</string>
         </property>
         <layout class="QFormLayout" name="formLayout">
          <item row="0" column="0">
           <widget class="QLabel" name="labelOpenAiKey">
            <property name="text">
             <string>OpenAI</string>
            </property>
           </widget>
          </item>
          <item row="0" column="1">
           <widget class="QLineEdit" name="lineEditOpenAiKey"/>
          </item>
          <item row="1" column="0">
           <widget class="QLabel" name="labelGoogleKey">
            <property name="text">
             <string>Google AI Studio</string>
            </property>
           </widget>
          </item>
          <item row="1" column="1">
           <widget class="QLineEdit" name="lineEditGoogleVisionKey"/>
          </item>
          <item row="2" column="0">
           <widget class="QLabel" name="labelAnthropicKey">
            <property name="text">
             <string>Anthropic</string>
            </property>
           </widget>
          </item>
          <item row="2" column="1">
           <widget class="QLineEdit" name="lineEditAnthropicKey"/>
          </item>
         </layout>
        </widget>
       </item>
       <item>
        <widget class="QGroupBox" name="groupBoxHuggingFaceSettings">
         <property name="title">
          <string>Hugging Face</string>
         </property>
         <layout class="QFormLayout" name="layoutHuggingFace">
          <item row="0" column="0">
           <widget class="QLabel" name="labelHfUsername">
            <property name="text">
             <string>ユーザー名:</string>
            </property>
           </widget>
          </item>
          <item row="0" column="1">
           <widget class="QLineEdit" name="lineEditHfUsername"/>
          </item>
          <item row="1" column="0">
           <widget class="QLabel" name="labelHfRepoName">
            <property name="text">
             <string>リポジトリ名:</string>
            </property>
           </widget>
          </item>
          <item row="1" column="1">
           <widget class="QLineEdit" name="lineEditHfRepoName"/>
          </item>
          <item row="2" column="0">
           <widget class="QLabel" name="labelHfToken">
            <property name="text">
             <string>トークン:</string>
            </property>
           </widget>
          </item>
          <item row="2" column="1">
           <widget class="QLineEdit" name="lineEditHfToken"/>
          </item>
         </layout>
        </widget>
       </item>
       <item>
        <widget class="QGroupBox" name="groupBoxLogSettings">
         <property name="title">
          <string>ログ設定</string>
         </property>
         <layout class="QVBoxLayout" name="verticalLayout">
          <item>
           <widget class="QWidget" name="LoglLevel" native="true">
            <property name="sizePolicy">
             <sizepolicy hsizetype="Expanding" vsizetype="Preferred">
              <horstretch>0</horstretch>
              <verstretch>0</verstretch>
             </sizepolicy>
            </property>
            <layout class="QHBoxLayout" name="horizontalLayout_2">
             <item>
              <widget class="QLabel" name="labelLogLevel">
               <property name="text">
                <string>ログレベル:</string>
               </property>
              </widget>
             </item>
             <item>
              <widget class="QComboBox" name="comboBoxLogLevel"/>
             </item>
             <item>
              <spacer name="HSpacerLogLevel">
               <property name="orientation">
                <enum>Qt::Orientation::Horizontal</enum>
               </property>
               <property name="sizeHint" stdset="0">
                <size>
                 <width>40</width>
                 <height>20</height>
                </size>
               </property>
              </spacer>
             </item>
            </layout>
           </widget>
          </item>
          <item>
           <widget class="FilePickerWidget" name="filePickerLogFile" native="true">
            <property name="sizePolicy">
             <sizepolicy hsizetype="Expanding" vsizetype="Preferred">
              <horstretch>0</horstretch>
              <verstretch>0</verstretch>
             </sizepolicy>
            </property>
           </widget>
          </item>
         </layout>
        </widget>
       </item>
       <item>
        <widget class="QWidget" name="SaveSettings" native="true">
         <layout class="QHBoxLayout" name="layoutButtons">
          <item>
           <spacer name="HSpacerSaveButtons">
            <property name="orientation">
             <enum>Qt::Orientation::Horizontal</enum>
            </property>
            <property name="sizeHint" stdset="0">
             <size>
              <width>40</width>
              <height>20</height>
             </size>
            </property>
           </spacer>
          </item>
          <item>
           <widget class="QPushButton" name="buttonSave">
            <property name="text">
             <string>保存</string>
            </property>
           </widget>
          </item>
          <item>
           <widget class="QPushButton" name="buttonSaveAs">
            <property name="text">
             <string>名前を付けて保存</string>
            </property>
           </widget>
          </item>
         </layout>
        </widget>
       </item>
      </layout>
     </widget>
    </widget>
   </item>
  </layout>
 </widget>
 <customwidgets>
  <customwidget>
   <class>DirectoryPickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">DirectoryPickerWidget</header>
   <container>1</container>
  </customwidget>
  <customwidget>
   <class>FilePickerWidget</class>
   <extends>QWidget</extends>
   <header location="global">FilePickerWidget</header>
   <container>1</container>
  </customwidget>
 </customwidgets>
 <resources/>
 <connections/>
 <slots>
  <slot>on_buttonSave_clicked()</slot>
  <slot>on_buttonSaveAs_clicked()</slot>
  <slot>on_lineEditOpenAiKey_editingFinished()</slot>
  <slot>on_lineEditGoogleVisionKey_editingFinished()</slot>
  <slot>on_lineEditAnthropicKey_editingFinished()</slot>
  <slot>on_lineEditHfUsername_editingFinished()</slot>
  <slot>on_lineEditHfRepoName_editingFinished()</slot>
  <slot>on_lineEditHfToken_editingFinished()</slot>
  <slot>on_comboBoxLogLevel_currentIndexChanged(int)</slot>
 </slots>
</ui>

```

### src\gui\designer\TagFilterWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>TagFilterWidget</class>
 <widget class="QWidget" name="TagFilterWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>269</width>
    <height>277</height>
   </rect>
  </property>
  <property name="windowTitle">
   <string>Form</string>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout">
   <item>
    <widget class="QGroupBox" name="filterGroupBox">
     <property name="sizePolicy">
      <sizepolicy hsizetype="Expanding" vsizetype="Expanding">
       <horstretch>0</horstretch>
       <verstretch>0</verstretch>
      </sizepolicy>
     </property>
     <property name="title">
      <string>Filter Criteria</string>
     </property>
     <property name="alignment">
      <set>Qt::AlignmentFlag::AlignCenter</set>
     </property>
     <layout class="QVBoxLayout">
      <item>
       <widget class="QWidget" name="filterTypeWidget" native="true">
        <layout class="QHBoxLayout" name="filterTypeLayout">
         <item>
          <widget class="QLabel" name="filterTypeLabel">
           <property name="text">
            <string>Filter Type:</string>
           </property>
          </widget>
         </item>
         <item>
          <widget class="QComboBox" name="filterTypeComboBox">
           <item>
            <property name="text">
             <string>Tags</string>
            </property>
           </item>
           <item>
            <property name="text">
             <string>Caption</string>
            </property>
           </item>
          </widget>
         </item>
         <item>
          <widget class="QRadioButton" name="andRadioButton">
           <property name="text">
            <string>AND検索</string>
           </property>
          </widget>
         </item>
        </layout>
       </widget>
      </item>
      <item>
       <widget class="QLineEdit" name="filterLineEdit">
        <property name="placeholderText">
         <string>Enter filter criteria</string>
        </property>
       </widget>
      </item>
      <item>
       <widget class="QWidget" name="taggingFilter" native="true">
        <layout class="QHBoxLayout" name="horizontalLayout_2">
         <item>
          <widget class="QCheckBox" name="noTagscheckBox">
           <property name="text">
            <string>タグの無い画像</string>
           </property>
          </widget>
         </item>
         <item>
          <widget class="QCheckBox" name="NSFWcheckBox">
           <property name="text">
            <string>NSFW</string>
           </property>
          </widget>
         </item>
        </layout>
       </widget>
      </item>
      <item>
       <widget class="QWidget" name="countRangeWidget" native="true">
        <property name="inputMethodHints">
         <set>Qt::InputMethodHint::ImhNone</set>
        </property>
        <layout class="QHBoxLayout" name="horizontalLayout">
         <item>
          <widget class="QLabel" name="tagUpdateatLabel">
           <property name="text">
            <string>タグ編集日</string>
           </property>
          </widget>
         </item>
         <item>
          <widget class="QWidget" name="countRangeSlide" native="true"/>
         </item>
        </layout>
       </widget>
      </item>
      <item>
       <widget class="QWidget" name="resolutionWidget" native="true">
        <layout class="QHBoxLayout" name="resolutionLayout">
         <item>
          <widget class="QLabel" name="resolutionLabel">
           <property name="text">
            <string>Resolution:</string>
           </property>
          </widget>
         </item>
         <item>
          <widget class="QComboBox" name="resolutionComboBox">
           <item>
            <property name="text">
             <string>None</string>
            </property>
           </item>
           <item>
            <property name="text">
             <string>512x512</string>
            </property>
           </item>
           <item>
            <property name="text">
             <string>768x768</string>
            </property>
           </item>
           <item>
            <property name="text">
             <string>1024x1024</string>
            </property>
           </item>
          </widget>
         </item>
        </layout>
       </widget>
      </item>
      <item>
       <widget class="QPushButton" name="applyFilterButton">
        <property name="text">
         <string>Apply Filters</string>
        </property>
       </widget>
      </item>
     </layout>
    </widget>
   </item>
  </layout>
 </widget>
 <resources/>
 <connections/>
</ui>

```

### src\gui\designer\ThumbnailSelectorWidget.ui

```
<?xml version="1.0" encoding="UTF-8"?>
<ui version="4.0">
 <class>ThumbnailSelectorWidget</class>
 <widget class="QWidget" name="ThumbnailSelectorWidget">
  <property name="geometry">
   <rect>
    <x>0</x>
    <y>0</y>
    <width>400</width>
    <height>300</height>
   </rect>
  </property>
  <layout class="QVBoxLayout" name="verticalLayout">
   <item>
    <widget class="QScrollArea" name="scrollAreaThumbnails">
     <property name="widgetResizable">
      <bool>true</bool>
     </property>
     <widget class="QWidget" name="widgetThumbnailsContent">
      <property name="geometry">
       <rect>
        <x>0</x>
        <y>0</y>
        <width>376</width>
        <height>276</height>
       </rect>
      </property>
      <property name="minimumSize">
       <size>
        <width>64</width>
        <height>64</height>
       </size>
      </property>
     </widget>
    </widget>
   </item>
  </layout>
 </widget>
 <resources/>
 <connections/>
</ui>

```

### src\gui\widgets\directory_picker.py

```
from PySide6.QtWidgets import QWidget, QFileDialog
from PySide6.QtCore import Qt
from gui_file.DirectoryPickerWidget_ui import Ui_DirectoryPickerWidget
from module.log import get_logger

class DirectoryPickerWidget(QWidget, Ui_DirectoryPickerWidget):
    def __init__(self, parent=None):
        self.logger = get_logger("DirectoryPickerWidget")
        super().__init__(parent)
        self.setupUi(self)
        self.set_label_text("フォルダを選択")

        self.DirectoryPicker.pushButtonPicker.clicked.connect(self.select_folder)
        self.DirectoryPicker.comboBoxHistory.currentIndexChanged.connect(self.on_history_item_selected)

    def select_folder(self):
        dir_path = QFileDialog.getExistingDirectory(self, "フォルダを選択")
        if dir_path:
            self.DirectoryPicker.lineEditPicker.setText(dir_path)
            self.DirectoryPicker.update_history(dir_path)  # 呼び出すメソッド名を修正
            self.logger.debug(f"フォルダが選択: {dir_path}")

    def on_history_item_selected(self, index):
        """履歴項目が選択されたときの処理"""
        selected_path = self.DirectoryPicker.comboBoxHistory.itemData(index, Qt.ToolTipRole)  # ツールチップデータ (フルパス) を取得
        self.DirectoryPicker.lineEditPicker.setText(selected_path)
        self.logger.debug(f"履歴からフォルダが選択: {selected_path}")

    def set_label_text(self, text):
        self.DirectoryPicker.set_label_text(text)

    def get_selected_path(self):
        return self.DirectoryPicker.lineEditPicker.text()

    def set_path(self, path):
        self.DirectoryPicker.lineEditPicker.setText(path)

    def on_path_changed(self, new_path):
        print(f"Selected directory changed: {new_path}")

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    from module.log import setup_logger
    logconf = {'level': 'DEBUG', 'file': 'DirectoryPickerWidget.log'}
    setup_logger(logconf)
    import sys

    app = QApplication(sys.argv)
    widget = DirectoryPickerWidget()
    widget.set_label_text("Select Folder")
    widget.show()
    sys.exit(app.exec())
```

### src\gui\widgets\file_picker.py

```
from PySide6.QtWidgets import QWidget, QFileDialog
from PySide6.QtCore import Qt

from gui_file.FilePickerWidget_ui import Ui_FilePickerWidget
from module.log import get_logger

class FilePickerWidget(QWidget, Ui_FilePickerWidget):
    def __init__(self, parent=None):
        self.logger = get_logger("FilePickerWidget")
        super().__init__(parent)
        self.setupUi(self)
        self.set_label_text("フォルダを選択")

        self.FilePicker.pushButtonPicker.clicked.connect(self.select_file)
        self.FilePicker.comboBoxHistory.currentIndexChanged.connect(self.on_history_item_selected)

    def select_file(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "ファイルを選択", "", "すべてのファイル (*)")
        if file_path:
            self.FilePicker.lineEditPicker.setText(file_path)
            self.FilePicker.update_history(file_path)
            self.logger.debug(f"ファイル選択: {file_path}")

    def on_history_item_selected(self, index):
        """履歴項目が選択されたときの処理"""
        selected_path = self.FilePicker.comboBoxHistory.itemData(index, Qt.ToolTipRole)  # ツールチップデータ (フルパス) を取得
        self.FilePicker.lineEditPicker.setText(selected_path)
        self.logger.debug(f"履歴からファイルを選択: {selected_path}")

    def set_label_text(self, text):
        self.FilePicker.set_label_text(text)

    def get_selected_path(self):
        return self.FilePicker.lineEditPicker.text()

    def set_path(self, path):
        self.FilePicker.lineEditPicker.setText(path)

    def on_path_changed(self, new_path):
        print(f"Selected file changed: {new_path}")

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    import sys

    app = QApplication(sys.argv)
    widget = FilePickerWidget()
    widget.set_label_text("Select Folder")
    widget.show()
    sys.exit(app.exec())
```

### src\gui\widgets\filter.py

```
import numpy as np

from PySide6.QtWidgets import QWidget, QLabel, QVBoxLayout, QHBoxLayout, QLabel
from PySide6.QtCore import Qt, Signal, Slot, QDateTime, QTimeZone, QDate, QTime
from superqt import QDoubleRangeSlider

from gui_file.TagFilterWidget_ui import Ui_TagFilterWidget

from module.log import get_logger

class CustomRangeSlider(QWidget):
    """日付または数値の範囲を選択するためのカスタムレンジスライダーウィジェット。

    このウィジェットは、日付または数値の範囲を選択するためのスライダーを提供します。
    現在の範囲の値をラベルとして表示します。

    属性:
        valueChanged (Signal): スライダーの値が変更されたときに発行されるシグナル。
            このシグナルは、選択された範囲の最小値と最大値を表す2つの整数値を発行します。

            日付範囲の場合、これらの整数値はローカルタイムゾーンでのUnixタイムスタンプ
            （エポックからの秒数）を表します。数値範囲の場合、実際に選択された値を表します。

            引数:
                min_value (int): 選択された範囲の最小値。
                max_value (int): 選択された範囲の最大値。

    """
    valueChanged = Signal(int, int)  # 最小値と最大値の変更を通知するシグナル

    def __init__(self, parent=None, min_value=0, max_value=100000):
        super().__init__(parent)
        self.min_value = min_value
        self.max_value = max_value
        self.is_date_mode = False
        self.setup_ui()

    def setup_ui(self):
        """CustomRangeSliderのユーザーインターフェースをセットアップします。

        このメソッドは、スライダーとラベルを初期化し、必要なシグナルを接続します。

        スライダーは0から100の範囲で設定され、後にユーザーが設定した実際の範囲
        （日付または数値）にマッピングされます。

        現在の範囲の最小値と最大値を表示するために2つのラベルが作成されます。
        これらのラベルは、スライダーの値が変更されるたびに更新されます。

        注意:
            このメソッドはクラスのコンストラクタ内部で呼び出されるため、
            ユーザーが直接呼び出す必要はありません。
        """
        layout = QVBoxLayout(self)

        self.slider = QDoubleRangeSlider(Qt.Orientation.Horizontal)
        self.slider.setRange(0, 100)
        self.slider.setValue((0, 100))

        self.min_label = QLabel(f"{self.min_value:,}")
        self.max_label = QLabel(f"{self.max_value:,}+")

        labels_layout = QHBoxLayout()
        labels_layout.addWidget(self.min_label)
        labels_layout.addStretch()
        labels_layout.addWidget(self.max_label)

        layout.addWidget(self.slider)
        layout.addLayout(labels_layout)

        self.slider.valueChanged.connect(self.update_labels)

    @Slot()
    def update_labels(self):
        min_val, max_val = self.slider.value()
        min_count = self.scale_to_value(min_val)
        max_count = self.scale_to_value(max_val)

        if self.is_date_mode:
            local_tz = QTimeZone.systemTimeZone()
            min_date = QDateTime.fromSecsSinceEpoch(min_count, local_tz)
            max_date = QDateTime.fromSecsSinceEpoch(max_count, local_tz)
            self.min_label.setText(min_date.toString("yyyy-MM-dd"))
            self.max_label.setText(max_date.toString("yyyy-MM-dd"))
        else:
            self.min_label.setText(f"{min_count:,}")
            self.max_label.setText(f"{max_count:,}")

        self.valueChanged.emit(min_count, max_count)

    def scale_to_value(self, value):
        if value == 0:
            return self.min_value
        if value == 100:
            return self.max_value
        log_min = np.log1p(self.min_value)
        log_max = np.log1p(self.max_value)
        log_value = log_min + (log_max - log_min) * (value / 100)
        return int(np.expm1(log_value))

    def get_range(self):
        min_val, max_val = self.slider.value()
        return (self.scale_to_value(min_val), self.scale_to_value(max_val))

    def set_range(self, min_value, max_value):
        self.min_value = min_value
        self.max_value = max_value
        self.update_labels()

    def set_date_range(self):
        # 開始日を2023年1月1日の0時に設定（UTC）
        start_date = QDateTime(QDate(2023, 1, 1), QTime(0, 0), QTimeZone.UTC)

        # 終了日を現在の日付の23:59:59に設定（UTC）
        end_date = QDateTime.currentDateTimeUtc()
        end_date.setTime(QTime(23, 59, 59))

        # 日付モードをオンにする
        self.is_date_mode = True

        # UTCタイムスタンプを取得（秒単位の整数）
        start_timestamp = int(start_date.toSecsSinceEpoch())
        end_timestamp = int(end_date.toSecsSinceEpoch())

        # 範囲を設定
        self.set_range(start_timestamp, end_timestamp)

        # ラベルを更新
        self.update_labels()

class TagFilterWidget(QWidget, Ui_TagFilterWidget):
    filterApplied = Signal(dict)
    """{
        filter_type: str,
        filter_text: str,
        resolution: int,
        use_and: bool,
        count_range: tuple,
        include_untagged: bool,
        include_nsfw
    }
    """

    def __init__(self, parent=None):
        self.logger = get_logger(__class__.__name__)
        super().__init__(parent)
        self.setupUi(self)
        self.setup_slider()

    def setup_slider(self):
        # CustomLRangeSliderをcountRangeSlideウィジェットとして追加
        self.count_range_slider = CustomRangeSlider(self, min_value=0, max_value=100000)
        layout = self.countRangeWidget.layout()
        # 既存のcountRangeSlideウィジェットを削除（存在する場合）
        if self.countRangeSlide is not None:
            layout.removeWidget(self.countRangeSlide)
            self.countRangeSlide.deleteLater()
        # 新しいCustomLRangeSliderを追加
        layout.addWidget(self.count_range_slider)

    @Slot()
    def on_applyFilterButton_clicked(self):
        """フィルター条件を取得して、filterAppliedシグナルを発行"""
        resolution = self.resolutionComboBox.currentText()
        if resolution != 'None': #currentText
            split_resolution = resolution.split('x')
        else:
            split_resolution = 0
        filter_conditions = {
            'filter_type': self.filterTypeComboBox.currentText().lower() if self.filterTypeComboBox.isVisible() else None,
            'filter_text': self.filterLineEdit.text(),
            'resolution': int(split_resolution[0]) if split_resolution else 0,
            'use_and': self.andRadioButton.isChecked() if self.andRadioButton.isVisible() else False,
            'count_range': self.count_range_slider.get_range() if self.count_range_slider.isVisible() else None,
            'include_untagged': self.noTagscheckBox.isChecked(),  # タグ情報がない画像を含めるかどうか
            'include_nsfw': self.NSFWcheckBox.isChecked()  # NSFWコンテンツを含めるかどうか（デフォルトは除外）
        }
        self.logger.debug(f"Filter conditions: {filter_conditions}")
        self.filterApplied.emit(filter_conditions)

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    from module.config import get_config
    from module.log import setup_logger
    import sys

    app = QApplication(sys.argv)
    config = get_config()
    logconf = {'level': 'DEBUG', 'file': 'TagFilterWidget.log'}
    setup_logger(logconf)

    widget = TagFilterWidget()
    widget.show()
    sys.exit(app.exec())
```

### src\gui\widgets\image_preview.py

```
from pathlib import Path

from PySide6.QtWidgets import QWidget, QGraphicsScene, QSizePolicy
from PySide6.QtGui import QPixmap, QPainter
from PySide6.QtCore import Qt, QTimer, Slot
from gui_file.ImagePreviewWidget_ui import Ui_ImagePreviewWidget

from module.log import get_logger

class ImagePreviewWidget(QWidget, Ui_ImagePreviewWidget):
    def __init__(self, parent=None):
        self.logger = get_logger("ImagePreviewWidget")
        super().__init__(parent)
        self.setupUi(self)

        # QGraphicsScene を作成
        self.graphics_scene = QGraphicsScene()
        self.previewGraphicsView.setScene(self.graphics_scene)

        # スムーススケーリングを有効にする
        self.previewGraphicsView.setRenderHints(QPainter.RenderHint.Antialiasing 
                                               | QPainter.RenderHint.SmoothPixmapTransform)
        self.pixmap_item = None

    @Slot(Path)
    def load_image(self, image_path: Path):
        # 既存の表示をクリア
        self.graphics_scene.clear()

        # 画像を読み込み
        pixmap = QPixmap(str(image_path))

        # 画像をシーンに追加
        self.graphics_scene.addPixmap(pixmap)

        # シーンの矩形を画像のサイズに設定
        self.graphics_scene.setSceneRect(pixmap.rect())

        # サイズ調整処理を遅延
        QTimer.singleShot(0, self._adjust_view_size)
        self.logger.debug(f"{image_path.name} を プレビュー領域に表示")

    def _adjust_view_size(self):
        # graphicsView のサイズポリシーを一時的に Ignored に設定
        self.previewGraphicsView.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)

        # graphicsView のサイズを表示領域のサイズに設定
        view_size = self.previewGraphicsView.viewport().size()
        self.previewGraphicsView.resize(view_size)

        # fitInView を呼び出して画像をフィット
        self.previewGraphicsView.fitInView(self.graphics_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)

    # resizeEvent をオーバーライドしてウィンドウサイズ変更時にサイズ調整
    def resizeEvent(self, event):
        super().resizeEvent(event)
        self._adjust_view_size()

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    app = QApplication([])
    widget = ImagePreviewWidget()
    widget.load_image(Path(r"testimg\1_img\file01.png"))  # 画像パスを指定
    widget.show()
    app.exec()
```

### src\gui\widgets\picker.py

```
from pathlib import Path

from PySide6.QtWidgets import QWidget, QFileDialog
from PySide6.QtCore import Qt

from gui_file.PickerWidget_ui import Ui_PickerWidget

from module.log import get_logger


class PickerWidget(QWidget, Ui_PickerWidget):
    def __init__(self, parent=None):
        self.logger = get_logger("PickerWidget")
        super().__init__(parent)
        self.setupUi(self)
        self.history = []  # 履歴を保存するリスト

        self.comboBoxHistory.currentIndexChanged.connect(self.on_history_item_selected)

    def configure(self, label_text="Select File"):
        self.set_label_text(label_text)

    def set_label_text(self, text):
        self.labelPicker.setText(text)

    def set_button_text(self, text):
        self.pushButtonPicker.setText(text)

    def select_file(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select File", "", "All Files (*);;Text Files (*.txt)")
        if file_path:
            self.lineEditPicker.setText(file_path)
            self.history.append(file_path)

    def select_folder(self):
        dir_path = QFileDialog.getExistingDirectory(self, "Select Directory")
        if dir_path:
            self.lineEditPicker.setText(dir_path)
            self.history.append(dir_path)

    def update_history(self, path):
        if path and path not in self.history:
            self.history.append(path)
            self.lineEditPicker.setText(path)
            # コンボボックスにdir名だけを追加
            dir_name = Path(path).name
            self.comboBoxHistory.blockSignals(True) # シグナルを無効にしないとon_history_item_selectedが呼び出されてバグる
            self.comboBoxHistory.addItem(dir_name)
            # マウスオーバーでフルパスを表示
            self.comboBoxHistory.setItemData(self.comboBoxHistory.count() - 1, path, Qt.ToolTipRole)
            self.comboBoxHistory.blockSignals(False) # シグナルを有効に戻す
            if len(self.history) > 10:
                self.history.pop(0)
                self.comboBoxHistory.removeItem(0)

    def on_history_item_selected(self, index):
        """履歴項目が選択されたときの処理"""
        selected_path = self.comboBoxHistory.itemData(index, Qt.ToolTipRole) # フルパスを取得
        self.lineEditPicker.setText(selected_path)
        self.logger.debug(f"on_history_item_selected \n 履歴からファイルを選択: {selected_path}")



if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    import sys
    app = QApplication(sys.argv)
    widget = PickerWidget()
    widget.show()
    sys.exit(app.exec())
```

### src\gui\widgets\thumbnail.py

```
from pathlib import Path

from PySide6.QtWidgets import (QWidget, QGraphicsObject, QGraphicsScene, QGraphicsView, QGraphicsPixmapItem,
                               QVBoxLayout, QApplication, QGraphicsItem)
from PySide6.QtGui import QPixmap, QColor, QPen
from PySide6.QtCore import Qt, QSize, Signal, Slot, QRectF, QTimer

from module.log import get_logger

from gui_file.ThumbnailSelectorWidget_ui import Ui_ThumbnailSelectorWidget

class ThumbnailItem(QGraphicsObject):
    """
    サムネイル画像を表すクラス。
    選択されたときに枠を表示します。
    """
    def __init__(self, pixmap: QPixmap, image_path: Path, parent: 'ThumbnailSelectorWidget'):
        super().__init__()
        self.pixmap = pixmap
        self.image_path = image_path
        self.parent_widget = parent
        self.setAcceptHoverEvents(True)
        self.setFlag(QGraphicsItem.GraphicsItemFlag.ItemIsSelectable, True)
        self._is_selected = False

    def isSelected(self) -> bool:
        return self._is_selected

    def setSelected(self, selected: bool):
        if self._is_selected != selected:
            self._is_selected = selected
            self.update()  # 再描画をトリガー

    def boundingRect(self) -> QRectF:
        return QRectF(self.pixmap.rect())

    def paint(self, painter, option, widget):
        painter.drawPixmap(self.boundingRect().toRect(), self.pixmap)
        if self.isSelected():
            pen = QPen(QColor(0, 120, 215), 3)
            painter.setPen(pen)
            painter.drawRect(self.boundingRect().adjusted(1, 1, -1, -1))

class CustomGraphicsView(QGraphicsView):
    """
    アイテムのクリックを処理し、信号を発行するカスタムQGraphicsView。
    """
    itemClicked = Signal(QGraphicsPixmapItem, Qt.KeyboardModifier)

    def mousePressEvent(self, event):
        """
        アイテムがクリックされたときに信号を発行します。
        Args:
            event (QMouseEvent): マウスイベント
        """
        item = self.itemAt(event.position().toPoint())
        if isinstance(item, ThumbnailItem):
            self.itemClicked.emit(item, event.modifiers())
        super().mousePressEvent(event)

class ThumbnailSelectorWidget(QWidget, Ui_ThumbnailSelectorWidget):
    """
    サムネイル画像を表示し、選択操作を管理するウィジェット。
    """
    imageSelected = Signal(Path)
    multipleImagesSelected = Signal(list)
    deselected = Signal()

    def __init__(self, parent=None):
        """
        コンストラクタ
        Args:
            parent (QWidget, optional): 親ウィジェット. Defaults to None.
        """
        self.logger = get_logger("ThumbnailSelectorWidget")
        super().__init__(parent)
        self.setupUi(self)
        self.thumbnail_size = QSize(128, 128)
        self.scene = QGraphicsScene(self)
        self.graphics_view = CustomGraphicsView(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignLeft | Qt.AlignmentFlag.AlignTop)
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.graphics_view.setDragMode(QGraphicsView.DragMode.RubberBandDrag)
        self.graphics_view.itemClicked.connect(self.handle_item_selection)
        layout = QVBoxLayout(self.widgetThumbnailsContent)
        layout.addWidget(self.graphics_view)
        self.widgetThumbnailsContent.setLayout(layout)
        self.image_paths = []
        self.thumbnail_items = []
        self.last_selected_item = None

        # リサイズ用のタイマーを初期化
        self.resize_timer = QTimer(self)
        self.resize_timer.setSingleShot(True)
        self.resize_timer.timeout.connect(self.update_thumbnail_layout)

    def resizeEvent(self, event):
        """
        ウィジェットがリサイズされたときにタイマーをリセットします。
        Args:
            event (QResizeEvent): リサイズイベント
        """
        super().resizeEvent(event)
        # タイマーをリセットし、250ミリ秒後にupdate_thumbnail_layoutを呼び出す
        self.resize_timer.start(250)

    @Slot(list)
    def load_images(self, image_paths: list[Path]):
        """
        画像のリストをウィジェットにロードし、サムネイルとして表示します。
        Args:
            image_paths (list[Path]): 画像のパスのリスト
        """
        self.image_paths = image_paths
        self.update_thumbnail_layout()

    def update_thumbnail_layout(self):
        """
        シーン内のサムネイルをグリッドレイアウトで配置します。
        """
        self.scene.clear()
        self.thumbnail_items.clear()
        button_width = self.thumbnail_size.width()
        grid_width = self.scrollAreaThumbnails.viewport().width()
        column_count = max(grid_width // button_width, 1)
        for i, file_path in enumerate(self.image_paths):
            self.add_thumbnail_item(file_path, i, column_count)
        row_count = (len(self.image_paths) + column_count - 1) // column_count
        scene_height = row_count * self.thumbnail_size.height()
        self.scene.setSceneRect(0, 0, grid_width, scene_height)

    def add_thumbnail_item(self, image_path: Path, index: int, column_count: int):
        """
        指定されたグリッド位置にサムネイルアイテムをシーンに追加します。
        Args:
            image_path (Path): 画像のファイルパス
            index (int): アイテムのインデックス #TODO: 何に対してのインデックスか俺もわかってない
            column_count (int): グリッドの列数
        """

        pixmap = QPixmap(str(image_path)).scaled(
            self.thumbnail_size, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation
        )
        item = ThumbnailItem(pixmap, image_path, self)
        self.scene.addItem(item)
        self.thumbnail_items.append(item)
        row = index // column_count
        col = index % column_count
        x = col * self.thumbnail_size.width()
        y = row * self.thumbnail_size.height()
        item.setPos(x, y)

    def handle_item_selection(self, item: ThumbnailItem, modifiers: Qt.KeyboardModifier):
        """
        アイテムの選択を処理し、単一選択、コントロール選択、シフト選択をサポートします。
        Args:
            item (ThumbnailItem): 選択されたサムネイルアイテム
            modifiers (Qt.KeyboardModifier): キーボード修飾キー
        """
        if modifiers & Qt.KeyboardModifier.ControlModifier:
            item.setSelected(not item.isSelected())
            self.logger.debug(f"画像がCtrl+クリックで{'選択' if item.isSelected() else '選択解除'}: \n item.image_path: {item.image_path}")
        elif modifiers & Qt.KeyboardModifier.ShiftModifier and self.last_selected_item:
            self.select_range(self.last_selected_item, item)
            self.logger.debug(f"画像がShift+クリックで範囲選択")
        else:
            for other_item in self.thumbnail_items:
                if other_item != item:
                    other_item.setSelected(False)
            item.setSelected(True)
            self.logger.debug(f"画像が選択: \n item.image_path: {item.image_path}")
        self.last_selected_item = item
        self.update_selection()

    def select_range(self, start_item, end_item):
        """
        開始アイテムと終了アイテムの間の範囲を選択します。
        Args:
            start_item (ThumbnailItem): 範囲選択の開始アイテム
            end_item (ThumbnailItem): 範囲選択の終了アイテム
        """
        if start_item is None or end_item is None:
            return
        start_index = self.thumbnail_items.index(start_item)
        end_index = self.thumbnail_items.index(end_item)
        start_index, end_index = min(start_index, end_index), max(start_index, end_index)
        for i, item in enumerate(self.thumbnail_items):
            item.setSelected(start_index <= i <= end_index)
        self.update_selection()

    def update_selection(self):
        """
        現在選択されている画像のリストを取得し、対応するシグナルを発行します。
        """
        selected_images = self.get_selected_images()
        if len(selected_images) > 1:
            self.multipleImagesSelected.emit(selected_images)
        elif len(selected_images) == 1:
            self.imageSelected.emit(selected_images[0])
        else:
            self.deselected.emit()

    def get_selected_images(self) -> list[Path]:
        """
        現在選択されている画像のパスのリストを返します。
        Returns:
            list[Path]: 選択された画像のパスのリスト
        """
        selected_images = [item.image_path for item in self.thumbnail_items if item.isSelected()]
        self.logger.debug(f"選択された画像のリスト: \n selected_images: {selected_images}")
        return selected_images

    def select_first_image(self):
        """
        リスト内の最初の画像を選択します（存在する場合）。
        ディレクトリ選択時最初の画像をプレビューに表示するため｡
        """
        if self.thumbnail_items:
            first_item = self.thumbnail_items[0]
            self.scene.clearSelection()
            first_item.setSelected(True)
            self.last_selected_item = first_item
            self.update_selection()

if __name__ == "__main__":
    import sys
    from module.log import setup_logger
    from PySide6.QtWidgets import QApplication


    logconf = {'level': 'DEBUG', 'file': 'ThumbnailSelectorWidget.log'}
    setup_logger(logconf)
    app = QApplication(sys.argv)
    widget = ThumbnailSelectorWidget()
    image_paths = [
        Path(r"testimg/1_img/file01.png"),
        Path(r"testimg/1_img/file02.png"),
        Path(r"testimg/1_img/file03.png"),
        Path(r"testimg/1_img/file04.png"),
        Path(r"testimg/1_img/file05.png"),
        Path(r"testimg/1_img/file06.png"),
        Path(r"testimg/1_img/file07.png"),
        Path(r"testimg/1_img/file08.png"),
        Path(r"testimg/1_img/file09.png"),
    ]
    widget.load_images(image_paths)
    widget.setMinimumSize(400, 300)  # ウィジェットの最小サイズを設定
    widget.show()
    sys.exit(app.exec())
```

### src\gui\window\edit.py

```
from pathlib import Path

from PySide6.QtWidgets import QWidget, QTableWidgetItem, QHeaderView, QMessageBox
from PySide6.QtCore import Qt, Slot
from PySide6.QtGui import QPixmap

from gui_file.ImageEditWidget_ui import Ui_ImageEditWidget

from module.log import get_logger
from module.file_sys import FileSystemManager
from module.db import ImageDatabaseManager
from caption_tags import ImageAnalyzer
from ImageEditor import ImageProcessingManager

class ImageEditWidget(QWidget, Ui_ImageEditWidget):
    THUMBNAIL_SIZE = 64
    def __init__(self, parent=None):
        super().__init__(parent)
        self.logger = get_logger("ImageEditWidget")
        self.setupUi(self)
        self.main_window = None
        self.cm = None
        self.idm = None
        self.fsm = None
        self.ipm = None
        self.target_resolution = 0
        self.preferred_resolutions = []
        self.upscaler = None
        self.directory_images = None

    def initialize(self, config_manager: 'ConfigManager', file_system_manager: FileSystemManager,
                         image_database_manager: ImageDatabaseManager, main_window=None):
        """ウィジェットの初期化を行う

        Args:
            config_manager (ConfigManager): 設定管理クラス
            file_system_manager (FileSystemManager): ファイルシステム管理クラス
            image_database_manager (ImageDatabaseManager): 画像データベース管理クラス
            main_window (Optional): メインウィンドウインスタンス
        """
        self.cm = config_manager
        self.fsm = file_system_manager
        self.idm = image_database_manager
        self.main_window = main_window
        self.target_resolution = self.cm.config['image_processing']['target_resolution']
        self.preferred_resolutions = self.cm.config['preferred_resolutions']
        self.upscaler = None
        self.comboBoxResizeOption.currentText()
        upscalers = [upscaler['name'] for upscaler in self.cm.upscaler_models.values()]
        self.comboBoxUpscaler.addItems(upscalers)

        header = self.tableWidgetImageList.horizontalHeader()
        header.setSectionResizeMode(QHeaderView.ResizeMode.Stretch)
        header.setStretchLastSection(False)

    def initialize_processing(self):
        """画像処理に必要なクラスの初期化"""
        self.fsm.initialize(Path(self.cm.config['directories']['output']), self.target_resolution)
        self.ipm = ImageProcessingManager(self.fsm, self.target_resolution,
                                          self.preferred_resolutions)

    def showEvent(self, event):
        """ウィジェットが表示される際にメインウィンドウで選択された画像を表示する"""
        super().showEvent(event)
        if self.cm.dataset_image_paths:
            self.load_images(self.cm.dataset_image_paths)

    def load_images(self, directory_images: list):
        self.directory_images = directory_images
        self.tableWidgetImageList.setRowCount(0)
        self.ImagePreview.load_image(Path(directory_images[0]))
        for image_path in directory_images:
            self._add_image_to_table(image_path)

    def _add_image_to_table(self, file_path: Path):
        str_filename = str(file_path.name)
        str_file_path = str(file_path)
        row_position = self.tableWidgetImageList.rowCount()
        self.tableWidgetImageList.insertRow(row_position)

        # サムネイル
        thumbnail = QPixmap(str(file_path)).scaled(
            self.THUMBNAIL_SIZE, self.THUMBNAIL_SIZE,
            Qt.AspectRatioMode.KeepAspectRatio
        )
        thumbnail_item = QTableWidgetItem()
        thumbnail_item.setData(Qt.ItemDataRole.DecorationRole, thumbnail)
        self.tableWidgetImageList.setItem(row_position, 0, thumbnail_item)

        # ファイル名
        self.tableWidgetImageList.setItem(row_position, 1, QTableWidgetItem(str_filename))
        # パス
        self.tableWidgetImageList.setItem(row_position, 2, QTableWidgetItem(str_file_path))

        # 高と幅
        pixmap = QPixmap(str_file_path)
        file_height = pixmap.height()
        file_width = pixmap.width()
        self.tableWidgetImageList.setItem(row_position, 3, QTableWidgetItem(f"{file_height} x {file_width}"))

        # サイズ
        file_size = file_path.stat().st_size
        self.tableWidgetImageList.setItem(row_position, 4, QTableWidgetItem(f"{file_size / 1024:.2f} KB"))

        # 既存アノテーション
        existing_annotations = ImageAnalyzer.get_existing_annotations(file_path)
        if existing_annotations:
            # タグをカンマ区切りの文字列に結合
            tags_str = ', '.join([tag_info['tag'] for tag_info in existing_annotations['tags']])
            self.tableWidgetImageList.setItem(row_position, 5, QTableWidgetItem(tags_str))

            # キャプションをカンマ区切りの文字列に結合
            captions_str = ', '.join([caption_info['caption'] for caption_info in existing_annotations['captions']])
            self.tableWidgetImageList.setItem(row_position, 6, QTableWidgetItem(captions_str))

    @Slot()
    def on_tableWidgetImageList_itemSelectionChanged(self):
        selected_items = self.tableWidgetImageList.selectedItems()
        if selected_items:
            row = self.tableWidgetImageList.currentRow()
            file_path = self.tableWidgetImageList.item(row, 2).text()
            self.ImagePreview.load_image(Path(file_path))

    @Slot()
    def on_comboBoxResizeOption_currentIndexChanged(self):
        """選択したリサイズオプションに応じて画像を_configのtarget_resolutionに設定する
        """
        # TODO: 解像度の選択肢はコンボボックスのアイテムとして設定してないほうが今後解像度の対応が増えた時にいいかもしれない
        selected_option = self.comboBoxResizeOption.currentText()
        resolution = int(selected_option.split('x')[0])
        self.target_resolution = resolution
        self.cm.config['image_processing']['target_resolution'] = resolution
        self.logger.debug(f"目標解像度の変更: {resolution}")

    @Slot()
    def on_comboBoxUpscaler_currentIndexChanged(self):
        """選択したアップスケーラに応じて_configのupscalerに設定する
        """
        selected_option = self.comboBoxUpscaler.currentText()
        self.upscaler = selected_option
        self.cm.config['image_processing']['upscaler'] = selected_option
        self.logger.debug(f"アップスケーラーの変更: {selected_option}")

    @Slot()
    def on_pushButtonStartProcess_clicked(self):
        try:
            self.initialize_processing()
            if __name__ == "__main__": #NOTE: この条件分岐はテスト用､スレッディング処理なしで実行するため
                self.process_all_images()
            else:
                self.main_window.some_long_process(self.process_all_images)
        except Exception as e:
            self.logger.error(f"画像処理中にエラーが発生しました: {str(e)}")
            QMessageBox.critical(self, "エラー", f"処理中にエラーが発生しました: {str(e)}")

    def process_all_images(self, progress_callback=None, status_callback=None, is_canceled=None):
        try:
            self.logger.debug("画像処理開始") # Add debug log
            total_images = len(self.directory_images)
            for index, image_path in enumerate(self.directory_images):
                self.logger.debug(f"画像処理: {index + 1}/{total_images}") # Add debug log
                if is_canceled and is_canceled():
                    break
                self.process_image(image_path)
                if progress_callback:
                    progress = int((index + 1) / total_images * 100)
                    progress_callback(progress)
                if status_callback:
                    status_callback(f"画像 {index + 1}/{total_images} を処理中")
        except Exception as e:
            self.logger.error(f"画像処理中にエラーが発生しました: {str(e)}")
            raise e

    def process_image(self, image_file: Path):
        image_id = self.idm.detect_duplicate_image(image_file)
        if not image_id:
            image_id, original_image_metadata = self.idm.register_original_image(image_file, self.fsm)
        else:
            original_image_metadata = self.idm.get_image_metadata(image_id)

        existing_annotations = ImageAnalyzer.get_existing_annotations(image_file)
        if existing_annotations:
            for tag_dict in existing_annotations['tags']:
                tag = tag_dict['tag'].strip()
                word_count = len(tag_dict['tag'].split())
                if word_count > 5:
                    self.logger.info(f"5単語を超えた {tag} は作品名でないか検索します。")
                    tag_id = self.idm.get_tag_id_in_tag_database(tag)
                    if not tag_id:
                        self.logger.info("作品名が見つかりませんでした。キャプションとして処理します。")
                        existing_annotations['tags'].remove(tag_dict)
                        existing_annotations['captions'].append({'caption': tag, 'model_id': None})
                    else:
                        self.logger.info(f"作品名が見つかりました: {tag}")
            self.idm.save_annotations(image_id, existing_annotations)
        else:
            self.idm.save_annotations(image_id, {'tags': [], 'captions': []})

        existing_processed_image = self.idm.check_processed_image_exists(image_id, self.target_resolution)
        if existing_processed_image:
            return

        processed_image = self.ipm.process_image(
            image_file,
            original_image_metadata['has_alpha'],
            original_image_metadata['mode'],
            upscaler=self.upscaler
        )
        if processed_image:
            self.handle_processing_result(processed_image, image_file, image_id)
        else:
            self.logger.warning(f"画像処理スキップ: {image_file}")

    def handle_processing_result(self, processed_image, image_file, image_id):
        processed_path = self.fsm.save_processed_image(processed_image, image_file)
        processed_metadata = self.fsm.get_image_info(processed_path)
        self.idm.register_processed_image(image_id, processed_path, processed_metadata)
        self.logger.info(f"画像処理完了: {image_file} -> {processed_path}")

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication, QWidget
    from gui import MainWindow, ConfigManager
    from module.config import get_config
    import sys

    app = QApplication(sys.argv)
    config = get_config()
    fsm = FileSystemManager()
    idm = ImageDatabaseManager(Path("Image_database"))
    m_window = MainWindow()
    m_window.init_managers()
    cm = ConfigManager()
    image_paths = fsm.get_image_files(Path(r"TEST\testimg\1_img")) # 画像ファイルのディレクトリを指定
    widget = ImageEditWidget()
    widget.initialize(cm, fsm, idm)
    widget.load_images(image_paths)
    widget.show()
    sys.exit(app.exec())
```

### src\gui\window\export.py

```
import sys
from pathlib import Path

from PySide6.QtWidgets import QWidget, QMessageBox
from PySide6.QtCore import Qt, QDateTime, QTimeZone, QTime, Slot
from gui_file.DatasetExportWidget_ui import Ui_DatasetExportWidget

from module.file_sys import FileSystemManager
from module.db import ImageDatabaseManager
from module.log import get_logger

class DatasetExportWidget(QWidget, Ui_DatasetExportWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setupUi(self)
        self.logger = get_logger("DatasetExportWidget")
        self.fsm = None
        self.idm = None
        self.filtered_image_metadata = {}
        self.image_path_id_map = {}

    def init_ui(self):
        self.exportDirectoryPicker.set_label_text("Export Directory:")
        self.exportDirectoryPicker.set_path(self.cm.config['directories']['edited_output'])
        self.exportProgressBar.setVisible(False)
        self.dbSearchWidget.filterApplied.connect(self.on_filter_applied)

    def initialize(self, cm, fsm: FileSystemManager, idm: ImageDatabaseManager):
        self.cm = cm
        self.fsm = fsm
        self.idm = idm
        self.init_date_range()
        self.init_ui()

    def init_date_range(self):
        self.dbSearchWidget.count_range_slider.set_date_range()

    def on_filter_applied(self, filter_conditions: dict):
        filter_type = filter_conditions['filter_type']
        filter_text = filter_conditions['filter_text']
        resolution = filter_conditions['resolution']
        use_and = filter_conditions['use_and']
        start_date, end_date = filter_conditions.get('date_range', (None, None))
        include_untagged = filter_conditions['include_untagged']
        # 日付範囲の処理
        if start_date is not None and end_date is not None:
            # UTCタイムスタンプをQDateTimeに変換し、ローカルタイムゾーンに設定
            start_date_qt = QDateTime.fromSecsSinceEpoch(start_date).toLocalTime()
            end_date_qt = QDateTime.fromSecsSinceEpoch(end_date).toLocalTime()

            # ローカルタイムゾーンを使用してISO 8601形式の文字列に変換
            start_date = start_date_qt.toString(Qt.ISODate)
            end_date = end_date_qt.toString(Qt.ISODate)

        tags = []
        caption = ""
        if filter_type == "tags":
            # タグはカンマ区切りで複数指定されるため、リストに変換
            tags = [tag.strip() for tag in filter_text.split(',')]
        elif filter_type == "caption":
            caption = filter_text

        filtered_image_metadata, list_count = self.idm.get_images_by_filter(
            tags=tags,
            caption=caption,
            resolution=resolution,
            use_and=use_and,
            start_date=start_date,
            end_date=end_date,
            include_untagged=include_untagged
        )
        if not filtered_image_metadata:
            self.logger.info(f"{filter_type} に {filter_text} を含む検索結果がありません")
            QMessageBox.critical(self,  "info", f"{filter_type} に {filter_text} を含む検索結果がありません")
            return

        # idとpathの対応だけを取り出す
        self.image_path_id_map = {Path(item['stored_image_path']): item['image_id'] for item in filtered_image_metadata}

        # サムネイルセレクターを更新
        self.update_thumbnail_selector(list(self.image_path_id_map.keys()), list_count)

    @Slot()
    def on_exportButton_clicked(self):
        export_directory = self.exportDirectoryPicker.get_selected_path()
        if not export_directory:
            QMessageBox.warning(self, "Warning", "出力先ディレクトリを選択してください")
            return

        self.export_dataset(Path(export_directory))

    def export_dataset(self, export_dir: Path):
        self.exportButton.setEnabled(False)
        self.statusLabel.setText("Status: Exporting...")

        selected_images = self.thumbnailSelector.get_selected_images()
        if not selected_images:
            QMessageBox.warning(self, "Warning", "出力する画像を選択してください")
            self.exportButton.setEnabled(True)
            return

        total_images = len(selected_images)
        export_successful = True
        for i, image_path in enumerate(selected_images):
            try:
                image_id = self.image_path_id_map.get(image_path)
                if image_id is not None:
                    annotations = self.idm.get_image_annotations(image_id)
                    if self.latestcheckBox.isChecked():
                        # 最近のアノテーションのみをフィルタリング
                        annotations = self.idm.filter_recent_annotations(annotations)
                    image_data = {
                        'path': image_path,
                        'tags': annotations.get('tags', []),
                        'captions': annotations.get('captions', [])
                    }
                    if self.checkBoxTxtCap.isChecked():
                        self.fsm.export_dataset_to_txt(image_data, export_dir)
                    if self.checkBoxJson.isChecked():
                        self.fsm.export_dataset_to_json(image_data, export_dir)
                else:
                    self.logger.error(f"Image ID not found for {image_path}")
                    continue  # 次の画像へ

                progress = int((i + 1) / total_images * 100)
                self.exportProgressBar.setValue(progress)
                self.statusLabel.setText(f"Status: Exporting... {progress}%")

            except Exception as e:
                self.logger.error(f"エクスポート中にエラーが発生しました: {str(e)}")
                QMessageBox.critical(self, "Error", f"エクスポート中にエラーが発生しました: {str(e)}")
                export_successful = False
                break

        self.exportButton.setEnabled(True)
        if export_successful:
            QMessageBox.information(self, "Success", "Dataset export completed successfully.")

    @Slot(int)
    def update_export_progress(self, value: int):
        self.exportProgressBar.setValue(value)

    @Slot()
    def export_finished(self):
        self.exportButton.setEnabled(True)
        self.exportProgressBar.setVisible(False)
        self.statusLabel.setText("Status: Export completed")
        QMessageBox.information(self, "Success", "Dataset export completed successfully.")

    @Slot(str)
    def export_error(self, error_message: str):
        self.exportButton.setEnabled(True)
        self.exportProgressBar.setVisible(False)
        self.statusLabel.setText("Status: Export failed")
        QMessageBox.critical(self, "Error", f"An error occurred during export: {error_message}")

    def update_thumbnail_selector(self, image_paths: list[Path], list_count: int):
        # サムネイルセレクターに新しい画像リストをロード
        self.thumbnailSelector.load_images(image_paths)
        self.update_image_count_label(list_count)

    def update_image_count_label(self, count):
        total = self.idm.get_total_image_count()
        self.imageCountLabel.setText(f"Selected Images: {count} / Total Images: {total}")

    @Slot(Path)
    def on_thumbnailSelector_imageSelected(self, image_path: Path):
        self.imagePreview.load_image(image_path)

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    from gui import ConfigManager
    from module.config import get_config
    from module.log import setup_logger
    import sys

    app = QApplication(sys.argv)
    config = get_config()
    logconf = {'level': 'DEBUG', 'file': 'DatasetExportWidget.log'}
    setup_logger(logconf)

    cm = ConfigManager()
    fsm = FileSystemManager()
    idm = ImageDatabaseManager()

    widget = DatasetExportWidget()
    widget.initialize(cm, fsm, idm)
    widget.show()
    sys.exit(app.exec())

```

### src\gui\window\main_window.py

```
import sys
from pathlib import Path

from PySide6.QtWidgets import QApplication, QMainWindow, QStatusBar, QMessageBox

from gui_file.gui_ui import Ui_mainWindow
from ProgressWidget import ProgressWidget, Controller

from module.log import setup_logger, get_logger
from module.config import get_config
from module.db import ImageDatabaseManager
from module.file_sys import FileSystemManager

class ConfigManager:
    _instance = None
    config = None
    dataset_image_paths = None # REVIEW: ここで保持するのは適切か？なぜこうしたかw擦れた理由をコメントで書く

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ConfigManager, cls).__new__(cls)
            cls._instance.config = cls.load_config_from_file()
            cls._instance.dataset_image_paths = []
        return cls._instance

    @staticmethod
    def load_config_from_file():
        return get_config()

class MainWindow(QMainWindow, Ui_mainWindow):
    def __init__(self):
        self.cm = ConfigManager()
        log_conf = self.cm.config['log']
        setup_logger(log_conf)
        self.logger = get_logger("MainWindow")
        super().__init__()
        self.setupUi(self)

        self.init_managers()
        self.init_pages()

        # ここでサイドメニューのウィンドウ上での割合を決めないと表示が汚くなる
        self.mainWindowSplitter.setSizes([self.width() * 1 // 5, self.width() * 4 // 5])

        self.connect_signals()
        self.init_dataset_selector()
        self.init_statusbar()

    def init_managers(self):
        self.database_path = Path(self.cm.config['directories']['database'])
        self.idm = ImageDatabaseManager(self.database_path)

        self.fsm = FileSystemManager()
        self.progress_widget = ProgressWidget()
        self.progress_controller = Controller(self.progress_widget)
        vision_models, score_models, upscaler_models = self.idm.get_models()
        self.cm.vision_models = vision_models
        self.cm.score_models = score_models
        self.cm.upscaler_models = upscaler_models


    def init_pages(self):
        self.pageImageEdit.initialize(self.cm, self.fsm, self.idm, self)
        self.pageImageTagger.initialize(self.cm, self.idm)
        self.pageDatasetOverview.initialize(self.cm, self.idm)
        self.pageExport.initialize(self.cm, self.fsm, self.idm)
        self.pageSettings.initialize(self.cm)

    def connect_signals(self):
        self.sidebarList.currentRowChanged.connect(self.contentStackedWidget.setCurrentIndex)
        self.datasetSelector.DirectoryPicker.lineEditPicker.textChanged.connect(self.dataset_dir_changed)
        self.actionExit.triggered.connect(self.close)

    def init_dataset_selector(self):
        self.datasetSelector.set_label_text("データセット:")
        default_conf_path = self.cm.config['directories']['dataset']
        # default_conf_path が空文字列の場合は何もしない｡でないとカレントディクトリ内の画像全部対象とする
        if default_conf_path == "":
            return
        self.datasetSelector.set_path(default_conf_path)
        self.cm.dataset_image_paths = FileSystemManager.get_image_files(Path(default_conf_path))

    def init_statusbar(self):
        if not hasattr(self, 'statusbar') or self.statusbar is None:
            self.statusbar = QStatusBar(self)
            self.setStatusBar(self.statusbar)
        self.statusbar.showMessage("準備完了")

    def dataset_dir_changed(self, new_path):
        self.logger.info(f"データセットディレクトリが変更されました: {new_path}")
        self.cm.config['directories']['dataset'] = new_path
        self.cm.dataset_image_paths = FileSystemManager.get_image_files(Path(new_path))
        # path がない場合は何もしない
        if not self.cm.dataset_image_paths:
            return
        # 現在表示されているページを更新するため current_page の load_images メソッドを呼び出す
        current_page = self.contentStackedWidget.currentWidget()
        if hasattr(current_page, 'load_images'):
            self.some_long_process(current_page.load_images, self.cm.dataset_image_paths)

    def some_long_process(self, process_function, *args, **kwargs):
        self.progress_widget.show()
        try:
            self.progress_controller.start_process(process_function, *args, **kwargs)
        except Exception as e:
            self.logger.error(f"ProgressWidgetを使用した処理中にエラーが発生しました: {e}")

    def closeEvent(self, event):
        if hasattr(self, 'progress_controller') and self.progress_controller and \
        hasattr(self.progress_controller, 'thread') and \
        self.progress_controller.thread and \
        self.progress_controller.thread.isRunning():
            event.ignore()
            QMessageBox.warning(self, "Warning", "Process is still running.")
        else:
            event.accept()

if __name__ == "__main__":
    app = QApplication([])
    window = MainWindow()
    window.show()
    sys.exit(app.exec())
```

### src\gui\window\overview.py

```
from pathlib import Path

from PySide6.QtWidgets import QWidget, QMessageBox
from PySide6.QtCore import Qt, Signal, Slot, QDateTime

from gui_file.DatasetOverviewWidget_ui import Ui_DatasetOverviewWidget

from module.file_sys import FileSystemManager
from module.db import ImageDatabaseManager
from module.log import get_logger
from caption_tags import ImageAnalyzer

class DatasetOverviewWidget(QWidget, Ui_DatasetOverviewWidget):
    dataset_loaded = Signal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.logger = get_logger("DatasetOverviewWidget")
        self.setupUi(self)
        self.image_files = []

        # スプリッターの初期サイズを設定
        self.mainSplitter.setSizes([self.width()  // 3, self.width() * 2 // 3])
        self.infoSplitter.setSizes([self.height() * 1 // 5, self.height() * 2 // 5])

        # シグナル/スロット接続
        self.thumbnailSelector.imageSelected.connect(self.update_preview)
        self.dbSearchWidget.filterApplied.connect(self.on_filter_applied)

    def initialize(self, cm: 'ConfigManager', idm: 'ImageDatabaseManager'):
        self.cm = cm
        self.idm = idm

    def showEvent(self, event):
        """ウィジェットが表示される際に呼び出されるイベントハンドラ"""
        if self.cm.dataset_image_paths:
            self.load_images(self.cm.dataset_image_paths)

    def load_images(self, image_files: list):
        self.image_files = image_files
        self.thumbnailSelector.load_images(image_files)
        self.dataset_loaded.emit()

        # 初期画像の表示
        if self.image_files:
            self.update_preview(Path(self.image_files[0]))

    def on_filter_applied(self, filter_conditions: dict):
        filter_type = filter_conditions['filter_type']
        filter_text = filter_conditions['filter_text']
        resolution = filter_conditions['resolution']
        use_and = filter_conditions['use_and']
        start_date, end_date = filter_conditions.get('date_range', (None, None))
        include_untagged = filter_conditions['include_untagged']
        # 日付範囲の処理
        if start_date is not None and end_date is not None:
            # UTCタイムスタンプをQDateTimeに変換し、ローカルタイムゾーンに設定
            start_date_qt = QDateTime.fromSecsSinceEpoch(start_date).toLocalTime()
            end_date_qt = QDateTime.fromSecsSinceEpoch(end_date).toLocalTime()

            # ローカルタイムゾーンを使用してISO 8601形式の文字列に変換
            start_date = start_date_qt.toString(Qt.ISODate)
            end_date = end_date_qt.toString(Qt.ISODate)

        tags = []
        caption = ""
        if filter_type == "tags":
            # タグはカンマ区切りで複数指定されるため、リストに変換
            tags = [tag.strip() for tag in filter_text.split(',')]
        elif filter_type == "caption":
            caption = filter_text

        filtered_image_metadata, list_count = self.idm.get_images_by_filter(
            tags=tags,
            caption=caption,
            resolution=resolution,
            use_and=use_and,
            start_date=start_date,
            end_date=end_date,
            include_untagged=include_untagged
        )
        if not filtered_image_metadata:
            self.logger.info(f"検索条件に一致する画像がありませんでした: {filter_type}  {filter_text}")
            QMessageBox.critical(self, "info", f"検索条件に一致する画像がありませんでした: {filter_type}  {filter_text}")
            return

        # idとpathの対応だけを取り出す
        self.image_path_id_map = {item['image_id']: Path(item['stored_image_path']) for item in filtered_image_metadata}

        # サムネイルセレクターを更新
        self.update_thumbnail_selector(list(self.image_path_id_map.values()))

    @Slot(Path)
    def update_preview(self, image_path: Path):
        self.ImagePreview.load_image(image_path)
        self.update_metadata(image_path)

    def update_metadata(self, image_path: Path):
        if image_path:
            metadata = FileSystemManager.get_image_info(image_path)
            self.set_metadata_labels(metadata, image_path)
            self.update_annotations(image_path)

    def update_thumbnail_selector(self, image_paths: list[Path]):
        # サムネイルセレクターに新しい画像リストをロード
        self.thumbnailSelector.load_images(image_paths)

    def set_metadata_labels(self, metadata, image_path):
        self.fileNameValueLabel.setText(metadata['filename'])
        self.imagePathValueLabel.setText(str(image_path))
        self.formatValueLabel.setText(metadata['format'])
        self.modeValueLabel.setText(metadata['mode'])
        self.alphaChannelValueLabel.setText("あり" if metadata['has_alpha'] else "なし")
        self.resolutionValueLabel.setText(f"{metadata['width']} x {metadata['height']}")
        self.aspectRatioValueLabel.setText(self.calculate_aspect_ratio(metadata['width'], metadata['height']))
        self.extensionValueLabel.setText(metadata['extension'])

    def clear_metadata(self):
        labels = [
            self.fileNameValueLabel, self.imagePathValueLabel, self.formatValueLabel,
            self.modeValueLabel, self.alphaChannelValueLabel, self.resolutionValueLabel,
            self.extensionValueLabel, self.aspectRatioValueLabel,
        ]
        for label in labels:
            label.clear()
        self.tagsTextEdit.clear()
        self.captionTextEdit.clear()

    def update_annotations(self, image_path: Path):
        # この部分は実際のデータ取得方法に応じて実装する必要があります
        annotations = ImageAnalyzer.get_existing_annotations(image_path)
        if annotations:
            # タグを抽出して結合
            tags = [tag_info['tag'] for tag_info in annotations.get('tags', [])]
            tags_text = ", ".join(tags)
            self.tagsTextEdit.setPlainText(tags_text)

            # キャプションを抽出して結合
            captions = [caption_info['caption'] for caption_info in annotations.get('captions', [])]
            captions_text = " | ".join(captions)  # キャプションをパイプで区切って結合
            self.captionTextEdit.setPlainText(captions_text)

        elif annotations is None:
            # DBkからアノテーション情報を検索
            image_id = self.idm.detect_duplicate_image(image_path)
            image_data = self.idm.get_image_annotations(image_id)
            tags_text = ', '.join([tag_data.get('tag','') for tag_data in image_data['tags']])
            self.tagsTextEdit.setPlainText(tags_text)
            captions_text = ', '.join([caption_data.get('caption', '') for caption_data in image_data['captions']])
            self.captionTextEdit.setPlainText(captions_text)
        else:
            self.tagsTextEdit.clear()
            self.captionTextEdit.clear()

    @staticmethod
    def calculate_aspect_ratio(width, height): #TODO: アスペクト比の計算がなにかおかしい
        def gcd(a, b):
            while b:
                a, b = b, a % b
            return a
        ratio_gcd = gcd(width, height)
        return f"{width // ratio_gcd} : {height // ratio_gcd}"

if __name__ == "__main__":
    from PySide6.QtWidgets import QApplication
    from gui import ConfigManager
    from module.file_sys import FileSystemManager
    import sys
    from module.log import  setup_logger
    logconf = {'level': 'DEBUG', 'file': 'DatasetOverviewWidget.log'}
    setup_logger(logconf)
    cm = ConfigManager()
    fsm = FileSystemManager()
    idm = ImageDatabaseManager(cm.config['directories']['database'])
    directory = Path(r"testimg\10_shira")
    image_files: list[Path] = fsm.get_image_files(directory)
    app = QApplication(sys.argv)
    widget = DatasetOverviewWidget()
    widget.initialize(cm, idm)
    widget.load_images(image_files)
    widget.show()
    sys.exit(app.exec())
```

### src\gui\window\progress.py

```
import inspect

from PySide6.QtWidgets import QDialog
from PySide6.QtCore import Qt, Signal, Slot, QThread, QObject

from gui_file.ProgressWidget_ui import Ui_ProgressWidget

from module.log import get_logger

class ProgressWidget(QDialog, Ui_ProgressWidget):
    """
    処理の進捗状況を表示するダイアログウィジェット。

    Attributes:
        canceled (Signal): キャンセルボタンがクリックされたときに発行されるシグナル。
        logger (Logger): ロガーオブジェクト。

    Signals:
        canceled: キャンセルボタンクリック時に発行されるシグナル。

    Methods:
        update_status(status: str): ステータスラベルのテキストを更新する。
        update_progress(value: int): プログレスバーの値を更新する。
    """
    canceled = Signal()

    def __init__(self, parent=None):
        """ProgressWidgetの初期化"""
        super().__init__(parent, Qt.Dialog)  # 親ウィジェットとダイアログフラグを設定して初期化
        self.logger = get_logger("ProgressWidget")
        self.setupUi(self)
        self.setModal(True)  # モーダルに設定して他の操作を受け付けないようにする
        self.progressBar.setRange(0, 0)  # インジターミネートモードに設定
        self.logger.debug("ProgressWidget initialized")

    @Slot()
    def on_cancelButton_clicked(self):
        """キャンセルボタンがクリックされたときの処理"""
        self.logger.debug("Cancel button clicked")
        self.canceled.emit()  # canceledシグナルを発行

    @Slot(str)
    def update_status(self, status):
        """
        ステータスラベルのテキストを更新する。

        Args:
            status (str): 新しいステータステキスト。
        """
        self.statusLabel.setText(status)

    @Slot(int)
    def update_progress(self, value):
        """
        プログレスバーの値を更新する。

        Args:
            value (int): プログレスバーの新しい値（0から100の範囲）。
        """
        self.progressBar.setValue(value)

class Worker(QObject):
    """
    バックグラウンドで長時間実行されるタスクを処理するワーカークラス。

    Attributes:
        progress_updated (Signal): 進捗状況が更新されたときに発行されるシグナル。
        status_updated (Signal): ステータスが更新されたときに発行されるシグナル。
        finished (Signal): タスクが完了したときに発行されるシグナル。
        error_occurred (Signal): エラーが発生したときに発行されるシグナル。
        logger (Logger): ロガーオブジェクト。
        _is_canceled (bool): キャンセルリクエストを受けたかどうかを示すフラグ。
        function (callable): 実行する処理の関数。
        args (tuple): 関数に渡す位置引数。
        kwargs (dict): 関数に渡すキーワード引数。

    Signals:
        progress_updated(int): 進捗値が更新されたときに発行。
        status_updated(str): ステータスラベルが更新されたときに発行。
        finished: 処理が完了したときに発行。
        error_occurred(str): エラーが発生したときに発行。

    Methods:
        run(): ワーカースレッドで実行する処理。
        cancel(): ワーカースレッドのキャンセル処理。
    """
    progress_updated = Signal(int)
    status_updated = Signal(str)
    finished = Signal()
    error_occurred = Signal(str)

    def __init__(self, function, *args, **kwargs):
        """Workerの初期化

        Args:
            function (callable): 実行する関数。
            *args: 関数に渡す位置引数。
            **kwargs: 関数に渡すキーワード引数。
        """
        super().__init__()
        self.logger = get_logger(f"Worker: {function.__name__}")
        self._is_canceled = False  # キャンセルリクエストを受けたかどうかを示すフラグ
        self.function = function  # 実行する処理の関数
        self.args = args  # 関数に渡す位置引数
        self.kwargs = kwargs  # 関数に渡すキーワード引数
        self.logger.debug("Worker initialized")

    @Slot()
    def run(self):
        """
        ワーカースレッドで実行する処理。
        外部から渡された関数を実行します。
        """
        self.logger.info("Worker: 処理開始")
        try:
            if self._is_canceled:
                self.logger.info("Worker: キャンセルされました")
                return

            # 関数のシグネチャを取得
            sig = inspect.signature(self.function)
            params = sig.parameters

            # 渡すキーワード引数を準備
            kwargs = dict(self.kwargs)
            if 'progress_callback' in params:
                kwargs['progress_callback'] = self.progress_updated.emit
            if 'status_callback' in params:
                kwargs['status_callback'] = self.status_updated.emit
            if 'is_canceled' in params:
                kwargs['is_canceled'] = lambda: self._is_canceled

            # 関数を実行
            self.function(*self.args, **kwargs)

        except Exception as e:
            self.logger.error(f"Worker: エラーが発生しました: {e}")
            self.error_occurred.emit(str(e))
        finally:
            self.logger.info("Worker: 処理完了")
            self.finished.emit()  # 処理完了シグナルを発行

    @Slot()
    def cancel(self):
        """
        ワーカースレッドのキャンセル処理。
        _is_canceled フラグを True に設定して、処理を中断します。
        """
        self.logger.debug("Worker: キャンセルリクエストを受け付けました")
        self._is_canceled = True

class Controller(QObject):
    """
    ProgressWidgetとWorkerを管理し、タスクの実行を制御するコントローラクラス。

    Attributes:
        progress_widget (ProgressWidget): 進捗状況を表示する ProgressWidget。
        worker (Worker): バックグラウンド処理を実行する Worker。
        thread (QThread): ワーカースレッド。
        logger (Logger): ロガーオブジェクト。

    Methods:
        start_process(self, function, *args, **kwargs): 処理を開始する。
        cleanup(self): スレッドとワーカーのリソースを解放する。

    Signals:
        None
    """
    def __init__(self, progress_widget=None):
        """Controllerの初期化

        Args:
            progress_widget (ProgressWidget, optional): 既存のProgressWidgetを使用する場合に指定。
        """
        super().__init__()
        self.logger = get_logger("Controller")
        self.progress_widget = progress_widget if progress_widget else ProgressWidget()
        self.worker = None
        self.thread = None
        self.logger.debug("Controller initialized")

    def start_process(self, function, *args, **kwargs):
        """
        処理を開始する。

        Args:
            function (callable): 実行する関数。
            *args: 関数に渡す位置引数。
            **kwargs: 関数に渡すキーワード引数。
        """
        # 既存のスレッドとワーカーをクリーンアップ
        self.cleanup()

        # 新しいスレッドとワーカーを作成
        self.thread = QThread()
        self.worker = Worker(function, *args, **kwargs)
        self.worker.moveToThread(self.thread)

        # シグナルとスロットの接続
        self.thread.started.connect(self.worker.run)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)
        self.worker.progress_updated.connect(self.progress_widget.update_progress)
        self.worker.status_updated.connect(self.progress_widget.update_status)
        self.worker.error_occurred.connect(self.on_error)
        self.worker.finished.connect(self.on_worker_finished)
        self.progress_widget.canceled.connect(self.worker.cancel)

        # スレッドを開始
        self.thread.start()
        self.logger.debug("Controller: スレッドを開始しました")

    @Slot()
    def on_worker_finished(self):
        """
        Workerの処理が終了したときに呼び出されるスロット。
        ProgressWidgetを非表示にし、リソースを解放します。
        """
        self.logger.debug("Controller: Workerが完了しました")
        self.progress_widget.hide()
        self.cleanup()

    @Slot(str)
    def on_error(self, message):
        """
        Workerでエラーが発生したときに呼び出されるスロット。

        Args:
            message (str): エラーメッセージ。
        """
        self.logger.error(f"Controller: エラーが発生しました: {message}")
        # ここでエラーをユーザーに通知するための処理を追加できます
        # 例えば、QMessageBoxを表示するなど
        self.progress_widget.hide()
        self.cleanup()

    def cleanup(self):
        """
        スレッドとワーカーのリソースを解放する。
        """
        if self.thread and self.thread.isRunning():
            self.logger.debug("Controller: スレッドとワーカーをクリーンアップします")
            self.worker.cancel()
            self.thread.quit()
            self.thread.wait()
        self.thread = None
        self.worker = None

```

### src\gui\window\settings.py

```
from PySide6.QtWidgets import QWidget, QFileDialog, QMessageBox
from PySide6.QtCore import Slot

from gui_file.SettingsWidget_ui import Ui_SettingsWidget

from module.file_sys import FileSystemManager

class SettingsWidget(QWidget, Ui_SettingsWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setupUi(self)

    def initialize(self, cm: 'ConfigManager'):
        self.cm = cm
        self.initialize_ui()
        self.connect_custom_widgets()

    def initialize_ui(self):
        self.initialize_directory_pickers()
        self.initialize_api_settings()
        self.initialize_huggingface_settings()
        self.initialize_log_settings()

    def initialize_directory_pickers(self):
        directories = {
            'output': self.dirPickerOutput,
            'response_file': self.dirPickerResponse,
            'edited_output': self.dirPickerEditedOutput
        }
        for key, picker in directories.items():
            picker.set_label_text(f"{key.capitalize()} Directory")
            picker.set_path(self.cm.config.get('directories', {}).get(key, ""))

    def initialize_api_settings(self):
        api_settings = {
            'openai_key': self.lineEditOpenAiKey,
            'google_key': self.lineEditGoogleVisionKey,
            'claude_key': self.lineEditAnthropicKey
        }
        for key, widget in api_settings.items():
            widget.setText(self.cm.config.get('api', {}).get(key, ""))

    def initialize_huggingface_settings(self):
        hf_settings = {
            'hf_username': self.lineEditHfUsername,
            'repo_name': self.lineEditHfRepoName,
            'token': self.lineEditHfToken
        }
        for key, widget in hf_settings.items():
            widget.setText(self.cm.config.get('huggingface', {}).get(key, ""))

    def initialize_log_settings(self):
        self.comboBoxLogLevel.addItems(['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'])
        self.comboBoxLogLevel.setCurrentText(self.cm.config['log']['level'])
        self.filePickerLogFile.set_label_text("Log File")
        self.filePickerLogFile.set_path(self.cm.config['log']['file'])

    def _save_config(self, filename: str) -> bool:
        try:
            FileSystemManager.save_toml_config(self.cm.config, filename)
            return True
        except IOError as e:
            QMessageBox.critical(self, "保存エラー", str(e))
            return False

    @Slot()
    def on_buttonSave_clicked(self):
        if self._save_config("processing.toml"):
            QMessageBox.information(self, "保存成功", "設定を保存しました。")

    @Slot()
    def on_buttonSaveAs_clicked(self):
        filename, _ = QFileDialog.getSaveFileName(self, "名前を付けて保存", "", "TOML Files (*.toml)")
        if filename and self._save_config(filename):
            QMessageBox.information(self, "保存成功", f"設定を {filename} に保存しました。")

    @Slot()
    def on_lineEditOpenAiKey_editingFinished(self):
        self.cm.config['api']['openai_key'] = self.lineEditOpenAiKey.text()

    @Slot()
    def on_lineEditGoogleVisionKey_editingFinished(self):
        self.cm.config['api']['google_key'] = self.lineEditGoogleVisionKey.text()

    @Slot()
    def on_lineEditAnthropicKey_editingFinished(self):
        self.cm.config['api']['claude_key'] = self.lineEditAnthropicKey.text()

    @Slot()
    def on_lineEditHfUsername_editingFinished(self):
        self.cm.config['huggingface']['hf_username'] = self.lineEditHfUsername.text()

    @Slot()
    def on_lineEditHfRepoName_editingFinished(self):
        self.cm.config['huggingface']['repo_name'] = self.lineEditHfRepoName.text()

    @Slot()
    def on_lineEditHfToken_editingFinished(self):
        self.cm.config['huggingface']['token'] = self.lineEditHfToken.text()

    def on_comboBoxLogLevel_currentIndexChanged(self, index):
        self.cm.config['log']['level'] = self.comboBoxLogLevel.itemText(index)

    @Slot()
    def connect_custom_widgets(self):
        self.dirPickerOutput.DirectoryPicker.lineEditPicker.textChanged.connect(self.on_dirPickerOutput_changed)
        self.dirPickerResponse.DirectoryPicker.lineEditPicker.textChanged.connect(self.on_dirPickerResponse_changed)
        self.dirPickerEditedOutput.DirectoryPicker.lineEditPicker.textChanged.connect(self.on_dirPickerEditedOutput_changed)
        self.filePickerLogFile.FilePicker.lineEditPicker.textChanged.connect(self.on_filePickerLogFile_changed)

    @Slot()
    def on_dirPickerOutput_changed(self, new_path):
        self.cm.config['directories']['output'] = new_path

    @Slot()
    def on_dirPickerResponse_changed(self, new_path):
        self.cm.config['directories']['response_file'] = new_path

    @Slot()
    def on_dirPickerEditedOutput_changed(self, new_path):
        self.cm.config['directories']['edited_output'] = new_path

    @Slot()
    def on_filePickerLogFile_changed(self, new_path):
        self.cm.config['log']['file'] = new_path

if __name__ == "__main__":
    import sys
    from PySide6.QtWidgets import QApplication
    from gui import ConfigManager
    app = QApplication(sys.argv)
    cm = ConfigManager()
    settings_page = SettingsWidget()
    settings_page.initialize(cm)
    settings_page.show()
    sys.exit(app.exec())
```

### src\gui\window\tagger.py

```
from pathlib import Path

from PySide6.QtWidgets import QWidget, QFileDialog, QMessageBox
from PySide6.QtCore import Slot

from gui_file.ImageTaggerWidget_ui import Ui_ImageTaggerWidget

from module.file_sys import FileSystemManager
from caption_tags import ImageAnalyzer
from module.api_utils import APIClientFactory
from module.log import get_logger
from module.db import ImageDatabaseManager


class ImageTaggerWidget(QWidget, Ui_ImageTaggerWidget):
    def __init__(self, parent=None):
        self.logger = get_logger("ImageTaggerWidget")
        super().__init__(parent)
        self.setupUi(self)

        self.splitterMain.setSizes([self.splitterMain.width() // 3, self.splitterMain.width() * 2 // 3])

        self.all_webp_files = []
        self.selected_webp = []
        self.main_prompt = ""
        self.add_prompt = ""
        self.imggen_prompt = ""
        self.model_name = ""
        self.model = ""
        self.check_low_res = False
        self.image_path_id_map = {}

        # タグとキャプションの生成結果を保持するリスト {path: risult_dict}
        self.all_results = {}

    def initialize(self, cm: 'ConfigManager', idm: ImageDatabaseManager):
        self.cm = cm
        self.idm = idm
        self.vision_providers = list(set(model['provider'] for model in self.cm.vision_models.values()))
        self.format_name = ["danbooru", "e621", "derpibooru"] #TODO:そのうちDatabase参照に変更する

        self.init_ui()

    def init_ui(self):
        self.comboBoxAPI.addItems(self.vision_providers)
        self.comboBoxTagFormat.addItems(self.format_name)
        self.main_prompt = self.cm.config['prompts']['main']
        self.add_prompt = self.cm.config['prompts']['additional']
        self.textEditMainPrompt.setPlainText(self.main_prompt)
        self.textEditAddPrompt.setPlainText(self.add_prompt)
        self.DirectoryPickerSave.set_label_text("保存先:")
        self.DirectoryPickerSave.set_path(self.cm.config['directories']['edited_output'])

        self.dbSearchWidget.filterGroupBox.setTitle("Search Tag")
        self.dbSearchWidget.filterTypeWidget.hide()
        self.dbSearchWidget.countRangeWidget.hide()
        self.dbSearchWidget.resolutionWidget.hide()

        self.ThumbnailSelector.imageSelected.connect(self.single_image_selection)
        self.ThumbnailSelector.multipleImagesSelected.connect(self.multiple_image_selection)

    @Slot(int)
    def on_comboBoxAPI_currentIndexChanged(self, index: int):
        """
        comboBoxAPIのインデックスが変更されたときに呼び出されるスロット。
        """
        api = self.comboBoxAPI.itemText(index)
        self.comboBoxModel.clear()
        model_list = [model['name'] for model in self.cm.vision_models.values() if model['provider'] == api]
        self.comboBoxModel.addItems(model_list)
        self.model_name = self.comboBoxModel.currentText()

    @Slot()
    def on_comboBoxModel_currentTextChanged(self):
        model_name = self.comboBoxModel.currentText()
        for model_id, model_info in self.cm.vision_models.items():
            if model_info['name'] == model_name:
                self.model_id = model_id
                break

    @Slot()
    def on_comboBoxTagFormat_currentTextChanged(self):
        self.format_name = self.comboBoxTagFormat.currentText()

    def showEvent(self, event):
        """ウィジェットが表示される際に呼び出されるイベントハンドラ"""
        super().showEvent(event)
        if self.cm.dataset_image_paths:
            self.load_images(self.cm.dataset_image_paths)

    def load_images(self, image_files: list):
        """
        画像のリストをウィジェットにロードし、サムネイルとして表示します。
        トークン数節約のため.webpファイルに限定されます。
        # IDEA: トークン数節約ならあえて低解像度に落とした画像を送り込んでもいいかも
        Args:
            image_files (list[Path]): 画像のパスのリスト
        """
        self.all_webp_files = [file for file in image_files if file.suffix == '.webp']
        self.ThumbnailSelector.load_images(self.all_webp_files)
        if self.all_webp_files:
            self.ThumbnailSelector.select_first_image()

    @Slot(dict)
    def on_dbSearchWidget_filterApplied(self, filter_conditions: dict):
        self.logger.debug(f"on_dbSearchWidget_filterApplied: {filter_conditions}")
        filter_text = filter_conditions['filter_text']
        include_untagged = filter_conditions['include_untagged']
        include_nsfw = filter_conditions['include_nsfw']

        tags = []
        tags = [tag.strip() for tag in filter_text.split(',')]

        filtered_images, list_count = self.idm.get_images_by_filter(tags=tags, include_untagged=include_untagged, include_nsfw=include_nsfw)

        if not filtered_images:
            self.logger.info(f"Tag に {filter_text} を含む検索結果がありません")
            QMessageBox.critical(self,  "info", f"Tag に {filter_text} を含む検索結果がありません")

        # 重複を除いた画像のリストを作成
        unique_images = {}
        for metadata in filtered_images:
            image_id = metadata['image_id']
            if image_id not in unique_images:
                unique_images[image_id] = Path(metadata['stored_image_path'])
        image_list = list(unique_images.values())

        self.ThumbnailSelector.load_images(image_list)
        if image_list:
            self.ThumbnailSelector.select_first_image()

    @Slot(Path)
    def single_image_selection(self, image_path: Path):
        self.logger.debug(f"single_image_selection: {image_path}")
        self.selected_webp = [image_path]
        self.ImagePreview.load_image(image_path)

    @Slot(list)
    def multiple_image_selection(self, image_list: list[Path]):
        self.logger.debug(f"multiple_image_selection: {image_list}")
        self.selected_webp = image_list
        self.ImagePreview.load_image(image_list[0])

    @Slot()
    def on_textEditMainPrompt_textChanged(self):
        self.main_prompt = self.textEditMainPrompt.toPlainText()
        self.cm.config['prompts']['main_prompt'] = self.main_prompt

    @Slot()
    def on_textEditAddPrompt_textChanged(self):
        self.add_prompt = self.textEditAddPrompt.toPlainText()
        self.cm.config['prompts']['additional'] = self.add_prompt

    @Slot()
    def on_textEditGenaiPrompt_textChanged(self):
        self.imggen_prompt = self.textEditAddPrompt.toPlainText()
        self.cm.config['prompts']['imggen_prompt'] = self.imggen_prompt.strip()

    @Slot()
    def on_pushButtonGenerate_clicked(self):
        self.logger.info("タグとキャプションの生成を開始")
        self.ia = ImageAnalyzer()
        self.acf = APIClientFactory(self.cm.config['api'])
        self.acf.initialize(self.cm.config['prompts']['main'], self.cm.config['prompts']['additional'])
        self.ia.initialize(self.acf, (self.cm.vision_models, self.cm.score_models))

        try:
            for i, image_path in enumerate(self.selected_webp):
                self.logger.info(f"{image_path.stem}の処理中")

                api_image_path = image_path
                if self.lowRescheckBox.isChecked():
                    image_id = self.idm.detect_duplicate_image(image_path)
                    if image_id is not None: #NOTE: image_pathを上書きするとselected_webp不整合が起こる
                        api_image_path = Path(self.idm.get_low_res_image(image_id))

                result = self.ia.analyze_image(api_image_path, self.model_id, self.format_name)
                self.all_results[image_path] = result
                self.logger.info(f"画像 {image_path.name} のタグとキャプションの生成が完了しました")
                i += 1
                if i == len(self.selected_webp):
                    #HACK: kここから表示処理メソッド分ける？
                    tags_data = result.get("tags", [])
                    caps_data = result.get("captions", [])
                    score = result.get('score', {}).get('score', 0)
                    self.scoreSlider.setValue(int(score * 100))
                    self.scoreSlider.setToolTip(f"{score:.2f}")

                    tags_list = [tag_dict['tag'] for tag_dict in tags_data if 'tag' in tag_dict]
                    combined_tags = ", ".join(tags_list)
                    self.textEditTags.setPlainText(combined_tags)

                    if caps_data:
                        for cap_dict in caps_data:
                            if 'caption' in cap_dict:
                                caption_list = [cap_dict['caption'] for cap_dict in caps_data if 'caption' in cap_dict]
                                combined_captions = ", ".join(caption_list)
                                self.textEditCaption.setPlainText(combined_captions)
                    else:
                        self.textEditCaption.setPlainText("No caption available")
        except Exception as e:
            self.logger.error(f"タグとキャプションの生成中にエラーが発生しました: {e}")
            self.textEditTags.setPlainText("Error generating tags")
            self.textEditCaption.setPlainText("Error generating caption")

    @Slot()
    def on_pushButtonSave_clicked(self):
        save_txt_on =self.checkBoxText.isChecked()
        save_json_on = self.checkBoxJson.isChecked()
        register_db_on = self.checkBoxDB.isChecked()

        if not save_txt_on and not save_json_on and not register_db_on:
            QMessageBox.warning(self, "info", "保存方法が選択されていません。")
            return

        if not self.selected_webp:
            QMessageBox.warning(self, "info", "画像が選択されていません。")
            return

        if save_txt_on or save_json_on:
            export_dir = Path(QFileDialog.getExistingDirectory(self, "保存先フォルダを選択"))
            self.DirectoryPickerSave.set_path(str(export_dir))
            if not export_dir:
                return  # キャンセルされた場合

        try:
            for image_path, result in self.all_results.items():
                if not result["tags"] and not result["captions"]:
                    QMessageBox.warning(self, "info", "タグまたはキャプションが生成されていません。")
                    return

                if image_path in self.selected_webp:
                    image_data = {
                        'path': image_path,
                        'tags': result.get('tags', []),
                        'captions': result.get('captions', [])
                    }
                    if save_txt_on:
                        FileSystemManager.export_dataset_to_txt(image_data, export_dir)
                    if save_json_on:
                        FileSystemManager.export_dataset_to_json(image_data, export_dir)
                    if register_db_on:
                        self.save_to_db()

        except Exception as e:
            QMessageBox.critical(self, "エラー", f"アノテーション保存中にエラーが発生しました: {e}")

    def save_to_db(self):
        fsm = FileSystemManager() # TODO: 暫定後で設計から見直す
        fsm.initialize(Path(self.cm.config['directories']['output']), self.cm.config['image_processing']['target_resolution'])
        for image_path, result in self.all_results.items():
            image_id = self.idm.detect_duplicate_image(image_path)
            if image_id is None:
                image_id, original_metadata = self.idm.register_original_image(image_path, fsm)
                self.logger.info(f"ImageTaggerWidget.save_to_db {image_path.name}")

            if self.imggen_prompt:
                tag_list = [tag.strip() for tag in self.imggen_prompt.split(',') if tag.strip()]
                self.idm.register_prompt_tags(image_id, tag_list) # NOTE: 手入力 imggen_prompt とモデルIDが違うので別に登録
            self.idm.save_annotations(image_id, result)


if __name__ == "__main__":
    import sys
    from PySide6.QtWidgets import QApplication
    from gui import ConfigManager, MainWindow

    app = QApplication(sys.argv)
    cm = ConfigManager()
    m_window = MainWindow()
    fsm = FileSystemManager()
    idm = ImageDatabaseManager(cm.config['directories']['database'])
    image_dir = fsm.get_image_files(Path(r"TEST\testimg\1_img")) # 画像ファイルのディレクトリを指定
    widget = ImageTaggerWidget()
    widget.initialize(cm, idm)
    widget.load_images(image_dir)
    widget.show()
    sys.exit(app.exec())

```

### src\lorairo.egg-info\PKG-INFO

```
Metadata-Version: 2.1
Name: lorairo
Version: 0.0.5
Summary: AIタグ付��によるLoRA画像データセット準備ツール
Author: NEXTAltair
License: MIT
Project-URL: Homepage, https://github.com/NEXTAltair/lorairo
Project-URL: Bug Tracker, https://github.com/NEXTAltair/lorairo/issues
Keywords: lora,dataset,ai,image-processing
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: GPU :: NVIDIA CUDA
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Multimedia :: Graphics
Classifier: Operating System :: Microsoft :: Windows
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: Pillow
Requires-Dist: opencv-python
Requires-Dist: numpy
Requires-Dist: ImageHash
Requires-Dist: google-generativeai>=0.8.3
Requires-Dist: anthropic>=0.36.2
Requires-Dist: openai>=0.10.0
Requires-Dist: toml>=0.10.2
Requires-Dist: PySide6>=6.8.0
Requires-Dist: superqt>=0.6.7
Requires-Dist: torch==2.5.1+cu124
Requires-Dist: pytorch-lightning==2.4.0
Requires-Dist: joblib==1.4.2
Requires-Dist: genai-tag-db-tools@ git+https://github.com/NEXTAltair/genai-tag-db-tools.git
Provides-Extra: dev
Requires-Dist: black; extra == "dev"
Requires-Dist: pylint; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: pytest-qt; extra == "dev"

# LoRA用画像をいろいろするスクリプト

## 概要

本プロジェクトは、LoRA（Low-Rank Adaptation）学習用の画像データセット作成を自動化するPythonスクリプト集です。画像のリサイズ、タグ付け、キャプション生成、データベース管理などの機能を提供し、効率的なデータセット作成をサポートします。

### 主な機能

- **画像処理**: 画像のリサイズ、フォーマット変換、自動クロップなどを行います。
- **メタデータ管理**: 画像のメタデータをSQLiteデータベースで管理します。
- **タグ・キャプション生成**: GPT-4などのAIモデルを使用して、画像のタグとキャプションを自動生成します。
- **バッチ処理**: 大量の画像を効率的に処理するためのバッチ処理機能を提供します。
- **ファイルシステム管理**: 処理された画像や生成されたデータの保存を体系的に管理します。

### 主要コンポーネント

- **ImageEditor.py**: 画像処理を担当。リサイズ、クロップ、フォーマット変換などを行います。
- **caption_tags.py**: 画像分析とタグ・キャプション生成を行います。
- **api_utils.py**: APIとの通信を管理。バッチ処理のサポートも含みます。
- **db.py**: SQLiteデータベースの操作を担当します。
- **file_sys.py**: ファイルシステムの操作を管理します。
- **config.py**: 設定ファイルの読み込みと管理を行います。
- **log.py**: ログ機能を提供します。
- **cleanup_txt.py**: テキストデータのクリーンアップを行います。

## セットアップ

### 必要条件

- Python 3.11以上

### インストール手順

1. リポジトリをクローンします：
   ```bash
   git clone https://github.com/NEXTAltair/Lorayougazouwoiroirosurusukuriputo.git
   ```

2. 必要なパッケージをインストールします：
   ```bash
   pip install -r requirements.txt
   ```

3. `processing.toml` ファイルを設定します。

## 使用方法

1. `processing.toml` ファイルで必要な設定を行います。
2. メイン処理を実行します：
   ```bash
   stert.bat
   ```

## 設定

`processing.toml` ファイルで以下の設定が可能です：

- データセットディレクトリ
- 出力ディレクトリ
- 画像処理パラメータ
- API設定
- ログ設定
- その他の処理オプション

## 開発者向け情報

- 各モジュールは独立して動作し、`main.py` で統合されています。
- 新機能の追加時は、既存のクラスとメソッドの拡張を検討してください。
- ユニットテストの追加を推奨します。

## 今後の展望

- GUIインターフェースの追加
- 他のAI画像分析APIのサポート
- パフォーマンス最適化
- より高度なタグ管理システムの実装

## ライセンス

MIT

### 参考

- [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts) タグのクリーンナップ
- [DominikDoom/a1111-sd-webui-tagcomplete](https://github.com/DominikDoom/a1111-sd-webui-tagcomplete) tags.dbの基になったCSV tag data
- [applemango](https://github.com/DominikDoom/a1111-sd-webui-tagcomplete/discussions/265) CSV tag data の日本語翻訳
- としあき製 CSV tag data の日本語翻訳
- [AngelBottomless/danbooru-2023-sqlite-fixed-7110548](https://huggingface.co/datasets/KBlueLeaf/danbooru2023-sqlite) danbooru タグのデータベース
- [hearmeneigh/e621-rising-v3-preliminary-data](https://huggingface.co/datasets/hearmeneigh/e621-rising-v3-preliminary-data) e621 rule34 タグのデータベース
- [sd-webui-bayesian-merger](https://github.com/s1dlx/sd-webui-bayesian-merger) スコアリング実装
- [stable-diffusion-webui-dataset-tag-editor](https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor) スコアリング実装

```

### src\lorairo.egg-info\requires.txt

```
Pillow
opencv-python
numpy
ImageHash
google-generativeai>=0.8.3
anthropic>=0.36.2
openai>=0.10.0
toml>=0.10.2
PySide6>=6.8.0
superqt>=0.6.7
torch==2.5.1+cu124
pytorch-lightning==2.4.0
joblib==1.4.2
genai-tag-db-tools@ git+https://github.com/NEXTAltair/genai-tag-db-tools.git

[dev]
black
pylint
pytest
pytest-cov
pytest-qt

```

### src\lorairo.egg-info\SOURCES.txt

```
LICENSE
README.md
pyproject.toml
src/lorairo.egg-info/PKG-INFO
src/lorairo.egg-info/SOURCES.txt
src/lorairo.egg-info/dependency_links.txt
src/lorairo.egg-info/requires.txt
src/lorairo.egg-info/top_level.txt
```

### src\main.py

```
from PySide6.QtWidgets import QApplication
from lorairo import MainWindow
import sys


def main() -> None:
    app = QApplication([])
    window = MainWindow()
    window.show()
    sys.exit(app.exec())


if __name__ == "__main__":
    main()

```

### src\score_module\clip_aethetic_score.py

```

import torch
import pytorch_lightning
import os
import clip
import numpy as np

from PIL import Image
from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize
try:
    from torchvision.transforms import InterpolationMode
    BICUBIC = InterpolationMode.BICUBIC
except ImportError:
    BICUBIC = Image.BICUBIC
def _convert_image_to_rgb(image):
    return image.convert("RGB")
def _transform(n_px):
    return Compose([
        Resize(n_px, interpolation=BICUBIC),
        CenterCrop(n_px),
        _convert_image_to_rgb,
        ToTensor(),
        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),
    ])
def get_image_preprocess(preprocess_size, scale=1):
    return _transform(preprocess_size*scale)

def normalized(a, axis=-1, order=2):
    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))
    l2[l2 == 0] = 1
    return a / np.expand_dims(l2, axis)

def get_property(version, model_name):
    if version == 0:
        scale_size = 1
        image_size = 1
        output = model_name
        npy_dot = ".npy"
        add_word = ""
    elif version == 1:
        scale_size = 2
        image_size = 1 + (scale_size * scale_size)
        output = model_name + "_x4"
        npy_dot = "_x4.npy"
        add_word = "x4"
    elif version == 2:
        scale_size = 3
        image_size = 1 + (scale_size * scale_size)
        output = model_name + "_x9"
        npy_dot = "_x9.npy"
        add_word = "x9"
    return scale_size, image_size, output, npy_dot, add_word

class MLP(pytorch_lightning.LightningModule):
    def __init__(self, input_size, xcol='emb', ycol='avg_rating', base_size=768):
        super().__init__()
        if input_size == base_size:
            self.append_flag = False
            self.base_size = input_size
            self.append_size = input_size
        else:
            self.append_flag = True
            self.base_size = base_size
            self.append_size = input_size - base_size
        self.input_size = input_size
        self.hidden_size = max(self.input_size//2, 1024)
        self.xcol = xcol
        self.ycol = ycol
        
        self.persona_0 = torch.nn.Sequential(
            torch.nn.Linear(self.base_size, self.hidden_size),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size, self.hidden_size//16),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size//16, self.hidden_size//64),
            torch.nn.Linear(self.hidden_size//64, 1)
        )
        self.persona_1 = torch.nn.Sequential(
            torch.nn.Linear(self.append_size, self.hidden_size),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size, self.hidden_size//16),
            torch.nn.ReLU(),
            torch.nn.Linear(self.hidden_size//16, 1)
        )
        self.persona_2 = torch.nn.Sequential(
            torch.nn.Linear(self.input_size, self.hidden_size),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size, self.hidden_size//8),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size//8, self.hidden_size//16),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.1),
            torch.nn.Linear(self.hidden_size//16, self.hidden_size//32),
            torch.nn.Linear(self.hidden_size//32, 1)
        )
        self.output = torch.nn.Linear(3, 1)
    def forward(self, x):
        if self.append_flag:
            h0 = self.persona_0(x[:,:self.base_size])
            h1 = self.persona_1(x[:,self.base_size:])
        else:
            h0 = self.persona_0(x)
            h1 = self.persona_1(x)
        h2 = self.persona_2(x)
        return self.output(torch.concat([h0,h1,h2], dim=1))

class Score_Manager():
    def __init__(self, model_path, device, score_max, args=None) -> None:
        score_args = {}
        if args is not None:
            for net_arg in args:
                key, value = net_arg.split("=")
                if key == "version":
                    version = int(value)
        if args.version == 0:
            self.scale_size = 1
            self.image_size = 1
            self.npy_dot = ".npy"
        elif args.version == 1:
            self.scale_size = 2
            self.image_size = 1 + (self.scale_size * self.scale_size)
            #args.output = args.output + "_x4"
            self.npy_dot = "_x4.npy"
        elif args.version == 2:
            self.scale_size = 3
            self.image_size = 1 + (self.scale_size * self.scale_size)
            #args.output = args.output + "_x9"
            self.npy_dot = "_x9.npy"
        
        self.image_preprocess = None
        self.clip_model, self.clip_preprocess = clip.load("ViT-L/14", device="cpu")  #RN50x64
        self.preprocess_size = self.clip_model.visual.input_resolution
        if version >= 1:
            self.image_preprocess = get_image_preprocess(self.preprocess_size, self.scale_size)
        self.tokenizer = clip.tokenize
        self.mlp = MLP(768*self.image_size)
        self.device = device
        if score_max is not None:
            self.score_max = score_max
        else:
            self.score_max = 1.
        if os.path.splitext(model_path)[-1]!=".pth":
            model_path = f"{model_path}.pth"
        s = torch.load(model_path)
        
        self.mlp.load_state_dict(s)

    def to_gpu(self):
        self.mlp.to(self.device)
        self.mlp.requires_grad_(False)
        self.mlp.eval()
        self.clip_model.to(self.device)
        self.clip_model.eval()
    def to_cpu(self):
        self.mlp.to("cpu")
        self.clip_model.to("cpu")
    
    def get_score(self, raw_image, prompt):
        with torch.no_grad():
            #txt_id = self.tokenizer(prompt, truncate=True).to(self.device)
            #if txt_id.size(1) > 77:
            #    print(f"too long token({txt_id.size()}): {prompt}")
            image = self.clip_preprocess(raw_image).unsqueeze(0).to(self.device)
            image_features = self.clip_model.encode_image(image)
            if self.image_size > 1:
                image = self.image_preprocess(raw_image).unsqueeze(0).to(self.device)
                for i in range(self.scale_size):
                    for j in range(self.scale_size):
                        image_features = torch.concat([image_features,self.clip_model.encode_image(image[:,:,i*self.preprocess_size:(i+1)*self.preprocess_size,j*self.preprocess_size:(j+1)*self.preprocess_size])], dim=1)
                
            #txt_features = self.clip_model.encode_text(txt_id)
        
        return self.mlp(image_features).data.cpu()[0][0]/self.score_max

```

### src\score_module\musiq_module.py

```

# 参考コード
# https://github.com/anse3832/MUSIQ

import os
import clip
import numpy as np
import math
import glob
import tqdm
import cv2
import joblib
import random
import hashlib
try:
    import h5py
except:
    print("大規模データセットを取り扱うためのライブラリ(h5py)がインストールされていません")
from einops import repeat
from PIL import Image

import torch
from torch.utils.data import Dataset
import pytorch_lightning

from torchvision.transforms import Compose, Normalize, transforms
try:
    from torchvision.transforms import InterpolationMode
    BICUBIC = InterpolationMode.BICUBIC
except ImportError:
    BICUBIC = Image.BICUBIC
def _transform():
    return Compose([
        transforms.ToTensor(),
        Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])
def get_image_preprocess():
    return _transform()

def collate_fn(examples):
  return examples[0]

CONST_STR_KUGIRILINE_LEN = 24
def get_property(data_path: str=None, batch_size: int=1, max_patches: int=None, eval_per: float=0.0,
                 reso_size: int = None,
                 hdf5: bool=True, hdf5_resume: bool=True, hdf5_add_load: bool=True, hdf5_path: str=None,
                 mode: str="musiq", version: int=0, resnet_dir: str="./score_module", model_name:str=None, dataset_resume: list[str]=None, dataset_save_name: str=None):
    model_params = {
        "n_layer": 14,
        "h_dim":  384, # clip 768 def 384
        "n_head": 6,
        "d_head": 384,
        "d_ff": 1152,
        "grid_size": 10,
        "dropout": 0.1,
        "layer_norm_epsilon": 1e-12,
        "score_model_dir": resnet_dir,
    }
    dataset_params = {
        "data_path": data_path,
        "reso_size": reso_size if reso_size is not None else 832,
        "divisible": 32,
        "patche_size": 32,
        "patche_stride": 32,
        "grid_size": model_params["grid_size"],
        "scale_list": [384, 224],
        "max_patches": max_patches if max_patches is not None else None,
        "batch_size": batch_size,
        "save_name": f"{dataset_save_name}.hdf5" if dataset_save_name is not None else None,
        "eval_per": eval_per,
        "hdf5": hdf5,
        "hdf5_resume": hdf5_resume,
        "hdf5_add_load": hdf5_add_load,
        "hdf5_path": f"{hdf5_path}.hdf5" if hdf5_path is not None else None,
        "resume": dataset_resume,
    }
    reso_size = dataset_params["reso_size"]
    train_params = {
        "model_name": f"{model_name}_{version}_{reso_size}.pth" if model_name is not None else f"musiq_score_{version}_{reso_size}.pth",
        "save_last_name": f"{model_name}_{version}_{reso_size}_last.pth" if model_name is not None else f"musiq_score_{version}_{reso_size}_last.pth",
    }
    # fix model params
    if mode == "musiq_score":
        model_params["output_scale"] = 1
    elif mode == "musiq_clip":
        model_params["h_dim"] = 384
        model_params["output_scale"] = 2
    # fix dataset params
    if dataset_resume is not None:
        if os.path.isfile(dataset_params["resume"]):
            dataset_params["hdf5_resume"] = True
    return model_params, dataset_params, train_params
def print_dict(data: dict, name: str=None):
    if name is not None:
        print("=" * CONST_STR_KUGIRILINE_LEN)
        print(f"dict {name} data")
        print("-" * CONST_STR_KUGIRILINE_LEN)
    for key, value in data.items():
        print(f"{key}: {value}")
    if name is not None:
        print("=" * CONST_STR_KUGIRILINE_LEN)
        print("")

def create_pos_idx(grid_size, count_w, count_h, scale_id):
    """
    return:
        tensor(1, 1, h, w)
    """
    grid_emb_w = torch.arange(0, grid_size, dtype=torch.float32).view(1, 1, 1, -1)
    grid_emb_w = torch.nn.functional.interpolate(grid_emb_w, size=(1, count_w), mode='nearest')
    grid_emb_w = grid_emb_w.repeat(1, 1, count_h, 1)
    grid_emb_h = torch.arange(0, grid_size, dtype=torch.float32).view(1, 1, -1, 1)
    grid_emb_h = torch.nn.functional.interpolate(grid_emb_h, size=(count_h, 1), mode='nearest')
    grid_emb_h = grid_emb_h.repeat(1, 1, 1, count_w)
    grid_emb = grid_emb_h * grid_size + grid_emb_w
    scale_emb = torch.full_like(grid_emb, scale_id)
    cls_mask = torch.ones_like(grid_emb)
    return  torch.concat([grid_emb, scale_emb, cls_mask], dim=1)

def calculate_pad_size(image_size, patch_size, patch_stride):
  num_patches = (image_size - patch_size) // patch_stride + 1
  remainder = image_size - (num_patches - 1) * patch_stride - patch_size
  if image_size == patch_stride:
    return image_size % patch_size
  elif remainder != 0:
    return patch_size - remainder
  else:
    return 0

def extract_patches(image, patch_size, patch_stride, padding='same', output_mode='tf', transform=None):
    """
    Extract patches from an input image using PyTorch.

    Args:
        image (torch.Tensor): Input image (shape: [batch_size, channels, height, width]).
        patch_size (int): Size of the patches (assumed to be square).
        patch_stride (int): Stride for patch extraction.
        padding (str): Padding mode ('same' or 'valid').
        output_mode: 'tf' or 'else' tfの場合tf.image.extract_patchesと同じ出力形式になる(b,patch_count, patch_size*patch_size*3) -> patches.view(b,pc,h,w,c)

    Returns:
        torch.Tensor: Extracted patches (tf shape: [batch_size, num_patches, channels * patch_size * patch_size]), (torch: [batch_size, num_pathes, pathe_size_h, pathe_size_w, channel]), other shape: [bs, channel, x, y, w, h]
        Int: count_w
        Int: count_h
    """
    height, width, channels = image.shape

    if padding == 'same':
        pad_w = calculate_pad_size(width, patch_size, patch_stride)
        pad_h = calculate_pad_size(height, patch_size, patch_stride)
    else:
        pad_w = 0
        pad_h = 0

    if transform is not None:
        image = transform(image)
    else:
        image = torch.from_numpy(image)
        image = image.permute(2, 0, 1)

    patches = torch.nn.functional.pad(image.unsqueeze(0), (0, pad_h, 0, pad_w))
    patches = patches.unfold(2, patch_size, patch_stride).unfold(3, patch_size, patch_stride)
    count_h = patches.size(2)
    count_w = patches.size(3)
    if output_mode=="tf":
        patches = patches.permute(0, 2, 3, 5, 4, 1).contiguous()
        patches = patches.view(*patches.size()[:3], -1)
    elif output_mode == "torch":
        patches = patches.permute(0, 2, 3, 4, 5, 1).contiguous()

    return patches, count_w, count_h

def round_to_steps(x, reso_steps):
    x = int(x + 0.5)
    return x - x % reso_steps
def resize_img_resos(image, max_resos, reso_steps) -> list[int, int]:
    height, width, channels = image.shape
    image_resos = height * width
    image_aspec = width / height

    if image_resos > max_resos:
        resize_w = math.sqrt(max_resos * image_aspec)
        resize_h = max_resos / resize_w
        # よりアス比が近いものを選ぶ
        round_ww = round_to_steps(resize_w, reso_steps)
        round_wh = round_to_steps(round_ww / image_aspec, reso_steps)
        w_aspec = round_ww / round_wh
        
        round_hh = round_to_steps(resize_h, reso_steps)
        round_hw = round_to_steps(round_hh * image_aspec, reso_steps)
        h_aspec = round_hw / round_hh

        if abs(w_aspec-image_aspec) < abs(h_aspec-image_aspec):
            resized_size = (round_ww, int(round_ww / image_aspec + 0.5))
        else:
            resized_size = (int(round_hh * image_aspec + 0.5), round_hh)
    else:
        resized_size = (width, height)
    return resized_size
def resize_image(image, resize):
    return cv2.resize(image, resize, interpolation=cv2.INTER_AREA)       # INTER_AREAでやりたいのでcv2でリサイズ
def load_img(img_path):
    image = Image.open(img_path)
    if not image.mode == "RGB":
        image = image.convert("RGB")
    return np.array(image)
def get_resize_latents(resnet, device, image, resos, division=32):
    transform = get_image_preprocess()
    height, width, channels = image.shape
    image_resos = height * width
    area = resos**2
    resize = resize_img_resos(image, area, division)
    if image_resos > area:
        _img = resize_image(image, resize)
    else:
        _img = image
    _img = Image.fromarray(_img)
    _img = transform(_img)
    _latents = resnet(_img.unsqueeze(0).to(device)).to("cpu")
    _latents = _latents.permute(0, 3, 2, 1).contiguous()
    _, s_cw, s_ch, _ = _latents.size()
    return _latents, s_cw, s_ch
def check_hash(file_path, model="md5"):
    with open(file_path, 'rb') as f:
        hash_data = hashlib.md5(f.read()).hexdigest()
    return hash_data

class MUSIQ_Score_Dataset(Dataset):
    def __init__(self, data_path: str, reso_size: int, divisible: int,
                 patche_size: int, patche_stride: int, grid_size: int, scale_list: list[int],
                 max_patches: int=None,
                 batch_size: int=1, eval_per: float=0.0,
                 hdf5: bool=False, hdf5_resume: bool=True, hdf5_add_load: bool=True, hdf5_path: str=None,
                 resume: list[str]=None, save_name:str=None,
                 use_cashe: bool=True, device: str = "auto") -> None:
        super().__init__()
        self.reso_size = reso_size
        self.max_area = reso_size * reso_size
        self.divisible = divisible
        self.patche_size = patche_size
        self.patche_stride = patche_stride
        self.grid_size = grid_size
        self.scale_list = scale_list
        self.use_cashe = use_cashe
        self.max_patches = max_patches
        self.resume_list = resume
        self.save_name = save_name
        self.hdf5 = hdf5
        self.hdf5_path = None
        self.hdf5_resume = hdf5_resume
        self.hdf5_add_load = hdf5_add_load
        # HDF5が使えるかチェック
        if self.hdf5:
            try:
                __ = h5py.__version__
                self.hdf5_path = data_path + f"/dataset_{reso_size}.hdf5" if hdf5_path is None else hdf5_path
            except:
                self.hdf5 = False

        self.batch_size = batch_size
        self.eval_per = eval_per
        self.eval = False

        # dataset management
        self.score_count = {}
        self.eval_score_count = {}
        self.keys = []
        self.key_data_count = {}
        self.total_datalen = 0
        self.train_datalen = 0
        self.return_datalen = 0
        self.eval_keys = []
        self.eval_data_count = {}
        self.eval_datalen = 0
        self.eval_return_len = 0

        self.key_id_list = []
        self.data_id_list = {}
        self.eval_key_id_list = []
        self.eval_id_list = {}
        # transformers
        self.transformer = get_image_preprocess()
        # resnet
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu") if device =="auto" else device

        self.data_list = {}
        self.eval_list = {}
        # self.load_dataset(resume)

        self.files_path = self.get_data_list(data_path)
        # culc eval len
        if self.eval_per > 0.0:
            self.train_datalen = int(self.total_datalen * (1.0 - self.eval_per))
            self.eval_datalen = int(self.total_datalen - self.train_datalen)
            for _ in range(self.eval_datalen):
                while True:
                    score_id = random.randrange(0, len(self.files_path))
                    if random.random() > (len(self.files_path[score_id]["paths"])/(self.total_datalen)):
                        continue
                    if len(self.files_path[score_id]["paths"]) <= 0: continue
                    target_id = random.randrange(0, len(self.files_path[score_id]["paths"]))
                    if score_id in self.eval_id_list:
                        if target_id in self.eval_id_list[score_id]: continue
                    else:
                        self.eval_id_list[score_id] = []
                    self.eval_id_list[score_id].append(target_id)
                    break
        else:
            self.train_datalen = self.total_datalen
            self.eval_datalen = 0

    def load_dataset(self, resume):
        if not self.hdf5:
            if resume is not None:
                if os.path.isfile(resume):
                    [self.data_list, self.eval_list] = joblib.load(resume)
    def save_dataset(self, save_name=None):
        if not self.hdf5:
            if save_name is not None:
                joblib.dump([self.data_list, self.eval_list], save_name, compress=3)
    def merge_hdf5(self):
        pass
    def get_data_list(self,base_dir) -> dict[float,list]:
        if base_dir is None:
            files_path = []
        else:
            dir_list = glob.glob(base_dir+"/*")
            files_path = []
            for dir in dir_list:
                if os.path.isdir(dir):
                    files_path.append({"score": float(os.path.split(dir)[-1]), "paths": glob.glob(dir+"/*.png") + glob.glob(dir+"/*.jpg") + glob.glob(dir+"/*.jpeg") + glob.glob(dir+"/*.webp")})
                    self.total_datalen += len(files_path[-1]["paths"])
        return files_path
    def _load_img(self, img_path):
        image = Image.open(img_path)
        if not image.mode == "RGB":
            # print(img_path)
            image = image.convert("RGB")
        return np.array(image)
    def _get_resize(self, image, max_area):
        height, width, channels = image.shape
        image_resos = height * width
        resize = resize_img_resos(image, max_area, self.divisible)
        if image_resos > max_area:
            return resize_image(image, resize)
        return image
    def _to_latents(self, image, resnet):
        # image = [c, h, w] -> [bs, c, h, w]
        latents = resnet(image.unsqueeze(0).to(self.device)).to("cpu")
        # [bs, h, w, bs]
        return latents.permute(0, 3, 2, 1).contiguous()
    def __to_latents(self, patches, resnet):
        # img_pathes = [bs, x, y, h, w, channel]
        bs, x, y, h, w, ch = patches.size()
        patches = patches.view(bs*x*y, h, w, ch).permute(0, 3, 1, 2).contiguous()
        # img_pathes = [bs * x * y, channel, h, w]
        if self.max_patches is None:
            self.max_patches = patches.size(0)
        repeat_count = bs//self.max_patches + (bs%self.max_patches)
        latents = None
        for i in range(repeat_count):
            s_pos = i * self.max_patches
            e_pos = (i+1) * self.max_patches
            if e_pos > bs: e_pos = patches.size(0)
            if latents is None:
                latents = resnet(patches[s_pos:e_pos].to(self.device)).to("cpu")
            else:
                torch.concat([latents, resnet(patches[s_pos:e_pos].to(self.device)).to("cpu")], dim=0)
        return latents.view(bs, x, y, -1).contiguous()

    def _create_resize_img(self, image, area, scale_id, resnet=None):
        _img = self._get_resize(image, area)
        _img = Image.fromarray(_img)
        _img = self.transformer(_img)
        latents = self._to_latents(_img, resnet).squeeze(0)
        s_cw, s_ch, _ = latents.size()
        ppi = create_pos_idx(self.grid_size, s_cw, s_ch, scale_id).permute(0, 2, 3, 1).contiguous()
        return None, ppi, s_cw, s_ch, latents
    def __create_resize_img(self, image, area, scale_id, resnet=None):
        _img = self._get_resize(image, area)
        patches, s_cw, s_ch = extract_patches(_img, self.patche_size, self.patche_stride, output_mode="torch", transform=get_image_preprocess())
        if resnet is not None:
            latents = self._to_latents(patches, resnet).squeeze(0)
            patches = None
        else:
            latents = None
        ppi = create_pos_idx(self.grid_size, s_cw, s_ch, scale_id).permute(0, 2, 3, 1).contiguous()
        return patches, ppi, s_cw, s_ch, latents
    
    def _create_data_id_list(self, target_key=None, eval=False):
        if eval:
            self.eval_id_list[target_key] = [i for i in range(self.eval_data_count[target_key])]
            self._shuffle_data_id_list(target_key, eval)
        else:
            self.data_id_list[target_key] = [i for i in range(self.key_data_count[target_key])]
            self._shuffle_data_id_list(target_key)
    def _shuffle_data_id_list(self, target_key=None, eval=False):
        if eval:
            random.shuffle(self.eval_id_list[target_key])
        else:
            random.shuffle(self.data_id_list[target_key])
    def _create_key_id_list(self, eval=False):
        if eval:
            for i, key in enumerate(self.eval_keys):
                count = self.eval_data_count[key] // self.batch_size + (self.eval_data_count[key]%self.batch_size > 0)
                self.eval_key_id_list += [i] * count
            random.shuffle(self.eval_key_id_list)
        else:
            for i, key in enumerate(self.keys):
                count = self.key_data_count[key] // self.batch_size + (self.key_data_count[key]%self.batch_size > 0)
                self.key_id_list += [i] * count
            random.shuffle(self.key_id_list)
    
    def create_datalist(self, resnet=None):
        print("=" * CONST_STR_KUGIRILINE_LEN)
        print("create dataset")
        if resnet is not None:
            resnet.to(self.device)
            resnet.eval()
            resnet.requires_grad_(False)
        if self.hdf5:
            mode = "a" if self.hdf5_resume else "w"
            with h5py.File(self.hdf5_path, mode) as h5:
                if not "train" in h5:
                    h5_train_data = h5.create_group("train")
                    self.hdf5_add_load = True
                else:
                    h5_train_data = h5["train"]
                    for key in h5_train_data.keys():
                        data_list = h5_train_data[key]
                        self.key_data_count[key] = len(data_list)
                if not "eval" in h5:
                    h5_eval_data = h5.create_group("eval")
                    self.hdf5_add_load = True
                else:
                    h5_eval_data = h5["eval"]
                    for key in h5_eval_data.keys():
                        data_list = h5_eval_data[key]
                        self.eval_data_count[key] = len(data_list)
                if not "data_info" in h5:
                    h5_data_info = h5.create_group("data_info")
                    h5_data_info_data = h5_data_info.create_group("train")
                    h5_data_info_data = h5_data_info.create_group("eval")
                    #h5_data_info_hash = h5_data_info.create_group("hash")
                else:
                    h5_data_info = h5["data_info"]
                    h5_data_info_data = h5_data_info["train"]
                    for key in h5_data_info_data.keys():
                        self.score_count[key] = h5_data_info_data[key][0]
                        self.train_datalen += h5_data_info_data[key][0]
                    h5_data_info_data = h5_data_info["eval"]
                    for key in h5_data_info_data.keys():
                        self.eval_score_count[key] = h5_data_info_data[key][0]
                        self.eval_datalen += h5_data_info_data[key][0]
                    #h5_data_info_hash = h5_data_info["hash"]
                # データセット構築
                for target_score, img_path_dic in enumerate(self.files_path):
                    if not self.hdf5_add_load: break
                    score = img_path_dic["score"]
                    for target_id, img_path in enumerate(tqdm.tqdm(img_path_dic["paths"], desc=f"[score: {score}]")):
                        image = self._load_img(img_path)
                        # scales
                        scale_patches = []
                        scale_pos_idx = []
                        scale_latents = []
                        scale_count = []
                        for i, scale in enumerate(self.scale_list):
                            scale_count.append([0,0])
                            s_patches, s_pos_idx, scale_count[i][0], scale_count[i][1], latents = self._create_resize_img(image, scale*scale, i+1, resnet)
                            scale_patches.append(s_patches)
                            scale_pos_idx.append(s_pos_idx)
                            scale_latents.append(latents)

                        # img_pathes = [bs, x, y, h, w, channel] if resnet==None else None
                        # latents[bs, x, y, h_dim * w * h] if resnet is not None else None
                        # patche_pos_idx = [bs, x, y, pos_id + scale + cls]
                        img_patches, patche_pos_idx, count_w, count_h, latents = self._create_resize_img(image, self.max_area, 0, resnet)
                        res_str = f"{count_w}_{count_h}"
                        for sc in scale_count:
                            res_str = f"{res_str},{sc[0]}_{sc[1]}"
                        
                        eval_flag = False
                        if target_score in self.eval_id_list:
                            if target_id in self.eval_id_list[target_score]:
                                eval_flag = True

                        if eval_flag:
                            if not res_str in h5_eval_data:
                                self.eval_data_count[res_str] = 0
                                h5_eval_list = h5_eval_data.create_group(res_str)
                                eval_h5_data_list = h5_eval_list.create_group(str(self.eval_data_count[res_str]))
                            else:
                                h5_eval_list = h5_eval_data[res_str]
                                eval_h5_data_list = h5_eval_list.create_group(str(self.eval_data_count[res_str]))

                            eval_h5_data = eval_h5_data_list.create_dataset("score",data=[score])
                            eval_h5_latents = eval_h5_data_list.create_dataset("latents",data=latents.numpy(), shape=latents.size(),compression='gzip')
                            eval_h5_scale_1_latents = eval_h5_data_list.create_dataset("scale_1",data=scale_latents[0].numpy(), shape=scale_latents[0].size(),compression='gzip')
                            eval_h5_scale_2_latents = eval_h5_data_list.create_dataset("scale_2",data=scale_latents[1].numpy(), shape=scale_latents[1].size(),compression='gzip')
                            self.eval_data_count[res_str] += 1
                            if str(score) in self.eval_score_count:
                                self.eval_score_count[str(score)] +=1
                            else:
                                self.eval_score_count[str(score)] = 1
                        else:
                            if not res_str in h5_train_data:
                                self.key_data_count[res_str] = 0
                                data_list = h5_train_data.create_group(res_str)
                                h5_data_list = data_list.create_group(str(self.key_data_count[res_str]))
                            else:
                                data_list = h5_train_data[res_str]
                                h5_data_list = data_list.create_group(str(self.key_data_count[res_str]))

                            h5_data = h5_data_list.create_dataset("score",data=[score])
                            h5_latents = h5_data_list.create_dataset("latents",data=latents.numpy(), shape=latents.size(),compression='gzip')
                            h5_scale_1_latents = h5_data_list.create_dataset("scale_1",data=scale_latents[0].numpy(), shape=scale_latents[0].size(),compression='gzip')
                            h5_scale_2_latents = h5_data_list.create_dataset("scale_2",data=scale_latents[1].numpy(), shape=scale_latents[1].size(),compression='gzip')
                            self.key_data_count[res_str] += 1
                            if str(score) in self.score_count:
                                self.score_count[str(score)] += 1
                            else:
                                self.score_count[str(score)] = 1
                # score count情報書き込み
                if self.hdf5_add_load:
                    h5_data_info_data = h5_data_info["train"]
                    for key, value in self.score_count.items():
                        if key in h5_data_info_data:
                            h5_data_info_data_count = h5_data_info_data[key]
                            h5_data_info_data_count[0] = value
                        else:
                            h5_data_info_data_count = h5_data_info_data.create_dataset(key, data=[value])
                    h5_data_info_data = h5_data_info["eval"]
                    for key, value in self.eval_score_count.items():
                        if key in h5_data_info_data:
                            h5_data_info_data_count = h5_data_info_data[key]
                            h5_data_info_data_count[0] = value
                        else:
                            h5_data_info_data_count = h5_data_info_data.create_dataset(key, data=[value])
        else:
            for target_score, img_path_dic in enumerate(self.files_path):
                score = img_path_dic["score"]
                for target_id, img_path in enumerate(tqdm.tqdm(img_path_dic["paths"])):
                    image = self._load_img(img_path)
                    # scales
                    scale_patches = []
                    scale_pos_idx = []
                    scale_latents = []
                    scale_count = []
                    for i, scale in enumerate(self.scale_list):
                        scale_count.append([0,0])
                        s_patches, s_pos_idx, scale_count[i][0], scale_count[i][1], latents = self._create_resize_img(image, scale*scale, i+1, resnet)
                        scale_patches.append(s_patches)
                        scale_pos_idx.append(s_pos_idx)
                        scale_latents.append(latents)

                    # img_pathes = [bs, x, y, h, w, channel] if resnet==None else None
                    # latents[bs, x, y, h_dim * w * h] if resnet is not None else None
                    # patche_pos_idx = [bs, x, y, pos_id + scale + cls]
                    img_patches, patche_pos_idx, count_w, count_h, latents = self._create_resize_img(image, self.max_area, 0, resnet)
                    res_str = f"{count_w}_{count_h}"
                    for sc in scale_count:
                        res_str = f"{res_str},{sc[0]}_{sc[1]}"
                    eval_flag = False
                    if target_score in self.eval_id_list:
                        if target_id in self.eval_id_list[target_score]:
                            eval_flag = True

                    if eval_flag:
                        if res_str in self.eval_list:
                            self.eval_data_count[res_str] = 1
                            self.eval_list[res_str].append({"score": score, "patches": img_patches, "latents": latents, "scale_patches": scale_patches, "scale_1_latents": scale_latents[0], "scale_2_latents": scale_latents[1]})
                        else:
                            self.eval_data_count[res_str] += 1
                            self.eval_list[res_str] = [{"score": score, "patches": img_patches, "latents": latents, "scale_patches": scale_patches, "scale_1_latents": scale_latents[0], "scale_2_latents": scale_latents[1]}]
                        if str(score) in self.eval_score_count:
                            self.eval_score_count[str(score)] += 1
                        else:
                            self.eval_score_count[str(score)] = 1
                    else:
                        if res_str in self.data_list:
                            self.key_data_count[res_str] = 1
                            self.data_list[res_str].append({"score": score, "patches": img_patches, "latents": latents, "scale_patches": scale_patches, "scale_1_latents": scale_latents[0], "scale_2_latents": scale_latents[1]})
                        else:
                            self.key_data_count[res_str] += 1
                            self.data_list[res_str] = [{"score": score, "patches": img_patches, "latents": latents, "scale_patches": scale_patches, "scale_1_latents": scale_latents[0], "scale_2_latents": scale_latents[1]}]
                        if str(score) in self.score_count:
                            self.score_count[str(score)] += 1
                        else:
                            self.score_count[str(score)] = 1
        
        if resnet is not None:
            resnet.to("cpu")
        
        # counting datalist
        self.keys = list(self.key_data_count.keys())
        self.keys.sort()
        for key in self.keys:
            self._create_data_id_list(key)
        # eval
        self.eval_keys = list(self.eval_data_count.keys())
        self.eval_keys.sort()
        for key in self.eval_keys:
            self._create_data_id_list(key, eval=True)

        # create id list
        self._create_key_id_list()
        self.return_datalen = len(self.key_id_list)
        # eval
        self._create_key_id_list(eval=True)
        self.eval_return_len = len(self.eval_key_id_list)

        # save datalist
        # if (not self.hdf5) and (self.save_name is not None):
        #    self.save_dataset(self.save_name)
        
    def print_datacount(self):
        print("=" * CONST_STR_KUGIRILINE_LEN)
        print(":::データセット情報(サイズ毎のデータ数):::")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        print(f"data count list / data count: {self.train_datalen}")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        for key in self.keys:
            print(f"{key}: {self.key_data_count[key]}")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        print(f"eval count list / data count: {self.eval_datalen}")
        for key in self.eval_keys:
            print(f"{key}: {self.eval_data_count[key]}")
        print("=" * CONST_STR_KUGIRILINE_LEN)
    def print_datacount_score(self):
        print("=" * CONST_STR_KUGIRILINE_LEN)
        print(":::データセット情報(スコア毎のデータ数):::")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        print(f"data count list / data count: {self.train_datalen}")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        for key, value in self.score_count.items():
            print(f"{key}: {value}({(value/self.train_datalen*100):02.03f}%)")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        print(f"eval count list / data: {self.eval_datalen}")
        print("-" * CONST_STR_KUGIRILINE_LEN)
        for key, value in self.eval_score_count.items():
            print(f"{key}: {value}({(value/self.eval_datalen*100):02.03f}%)")
        print("=" * CONST_STR_KUGIRILINE_LEN)
    def __total_datalen__(self):
        return self.total_datalen
    def __len__(self):
        if self.eval:
            return self.eval_return_len
        return self.return_datalen
    def __getitem__(self, index):
        # ターゲットとなるkeyを取り出す
        if self.eval:
            if len(self.eval_key_id_list) <= 0:
                self._create_key_id_list(eval=True)
            target_key = self.eval_keys[self.eval_key_id_list.pop(0)]
            if len(self.eval_id_list[target_key]) <= 0:
                self._create_data_id_list(target_key, eval=True)
        else:
            if len(self.key_id_list) <= 0:
                self._create_key_id_list()
            target_key = self.keys[self.key_id_list.pop(0)]
            if len(self.data_id_list[target_key]) <=0:
                self._create_data_id_list(target_key)
        # batch size分のデータを取り出す
        scores = []
        latents = []
        scale_1_latents = []
        scale_2_latents = []
        if self.hdf5:
            with h5py.File(self.hdf5_path, "r") as h5:
                if self.eval:
                    h5_target_base = h5["eval"]
                    h5_target_key_base = h5_target_base[target_key]
                    for i in range(self.batch_size):
                        if len(self.eval_id_list[target_key]) <=0: break
                        target_id = str(self.eval_id_list[target_key].pop(0))
                        h5_target_data = h5_target_key_base[target_id]
                        scores.append(h5_target_data["score"][0])
                        latents.append(torch.from_numpy(h5_target_data["latents"][...]).clone())
                        scale_1_latents.append(torch.from_numpy(h5_target_data["scale_1"][...]).clone())
                        scale_2_latents.append(torch.from_numpy(h5_target_data["scale_2"][...]).clone())
                else:
                    h5_target_base = h5["train"]
                    h5_target_key_base = h5_target_base[target_key]
                    for i in range(self.batch_size):
                        if len(self.data_id_list[target_key]) <=0: break
                        target_id = str(self.data_id_list[target_key].pop(0))
                        h5_target_data = h5_target_key_base[target_id]
                        scores.append(h5_target_data["score"][0])
                        latents.append(torch.from_numpy(h5_target_data["latents"][...]).clone())
                        scale_1_latents.append(torch.from_numpy(h5_target_data["scale_1"][...]).clone())
                        scale_2_latents.append(torch.from_numpy(h5_target_data["scale_2"][...]).clone())
        else:
            if self.eval:
                for i in range(self.batch_size):
                    if len(self.eval_id_list[target_key]) <=0: break
                    target_id = self.eval_id_list[target_key].pop(0)
                    scores.append(self.eval_list[target_key][target_id]["score"])
                    latents.append(self.eval_list[target_key][target_id]["latents"])
                    scale_1_latents.append(self.eval_list[target_key][target_id]["scale_1_latents"])
                    scale_2_latents.append(self.eval_list[target_key][target_id]["scale_2_latents"])
            else:
                for i in range(self.batch_size):
                    if len(self.data_id_list[target_key]) <=0: break
                    target_id = self.data_id_list[target_key].pop(0)
                    scores.append(self.data_list[target_key][target_id]["score"])
                    latents.append(self.data_list[target_key][target_id]["latents"])
                    scale_1_latents.append(self.data_list[target_key][target_id]["scale_1_latents"])
                    scale_2_latents.append(self.data_list[target_key][target_id]["scale_2_latents"])
        scores = torch.Tensor(np.stack(scores)).unsqueeze(1)
        latents = torch.stack(latents)
        scale_1_latents = torch.stack(scale_1_latents)
        scale_2_latents = torch.stack(scale_2_latents)
        data = {"score": scores, "latent": latents, "s1_latent": scale_1_latents, "s2_latent": scale_2_latents}
        return data

class Bottleneck(torch.nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None, output_relu=True):
        super(Bottleneck, self).__init__()
        self.conv1 = torch.nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = torch.nn.BatchNorm2d(planes)
        self.conv2 = torch.nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
                               padding=1, bias=False)
        self.bn2 = torch.nn.BatchNorm2d(planes)
        self.conv3 = torch.nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)
        self.bn3 = torch.nn.BatchNorm2d(planes * 4)
        if output_relu:
            self.relu = torch.nn.ReLU(inplace=True)
        else:
            self.relu = torch.nn.SiLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out

class ResNetBackbone(torch.nn.Module):

    def __init__(self, block, layers):
        super(ResNetBackbone, self).__init__()
        self.inplanes = 64
        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = torch.nn.BatchNorm2d(64)
        self.relu = torch.nn.ReLU(inplace=True)
        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)


        for m in self.modules():
            if isinstance(m, torch.nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, torch.nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
        

    def _make_layer(self, block, planes, blocks, stride=1, output_relu=True):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = torch.nn.Sequential(
                torch.nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                torch.nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            if i+1 == blocks:
                layers.append(block(self.inplanes, planes, output_relu=output_relu))
            else:
                layers.append(block(self.inplanes, planes))

        return torch.nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        return x

def resnet50_backbone(score_model_dir=None):
    # Constructs a ResNet-50 model_hyper.
    torch_resnet50_url = "https://download.pytorch.org/models/resnet50-11ad3fa6.pth"
    model = ResNetBackbone(Bottleneck, [3, 4, 6, 3])
    
    # load pre-trained weights
    import torch.utils.model_zoo as model_zoo
    save_model = model_zoo.load_url(torch_resnet50_url, model_dir=score_model_dir)
    model_dict = model.state_dict()
    state_dict = {k: v for k, v in save_model.items() if k in model_dict.keys()}
    model_dict.update(state_dict)
    model.load_state_dict(model_dict)
    
    return model

class MultiHeadAttention(torch.nn.Module):
    def __init__(self, h_dim, n_head, d_head, dropout) -> None:
        super().__init__()
        self.n_head = n_head
        self.d_head = d_head
        self.dropout_p = dropout
        self.Q = torch.nn.Linear(h_dim, n_head * d_head)
        self.K = torch.nn.Linear(h_dim, n_head * d_head)
        self.V = torch.nn.Linear(h_dim, n_head * d_head)
        # SDPA
        self.sdpa = torch.nn.functional.scaled_dot_product_attention
        # Leniear
        self.linear = torch.nn.Linear(n_head * d_head, h_dim)
        self.dropout = torch.nn.Dropout(dropout)
        self.set_enable_math = True
    def enable_math(self, enable_math: bool=True):
        self.set_enable_math = enable_math
    def forward(self, Q, K, V, attn_mask=None):
        batch_size = Q.size(0)

        # latents = [bs, x * y + scale1 + scale2 + cls, h_dim] -> [bs, n_head, x*y+s1+s2+cls, d_head]
        q_s = self.Q(Q).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)
        k_s = self.K(K).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)
        v_s = self.V(V).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)

        if attn_mask is not None:
            # (bs, n_head, n_q_seq, n_k_seq)
            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_head, 1, 1)

        # [bs, n_head, x*y+s1+s2+cls, d_head]
        with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=self.set_enable_math, enable_mem_efficient=True):
            context = self.sdpa(q_s, k_s, v_s, dropout_p=self.dropout_p)
        # [bs, x*y+s1+s2+cls, n_head * d_head]
        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_head * self.d_head)
        # [bs, x*y+s1+s2+cls, h_dim]
        output = self.linear(context)
        output = self.dropout(output)
        # [bs, x*y+s1+s2+cls, h_dim]
        return output
    
class PoswiseFeedForwardNet(torch.nn.Module):
    def __init__(self, h_dim, d_ff, dropout) -> None:
        super().__init__()
        self.lin1 = torch.nn.Linear(h_dim, d_ff)
        self.lin2 = torch.nn.Linear(d_ff, h_dim)
        self.active = torch.nn.functional.gelu
        self.dropout = torch.nn.Dropout(dropout)
    def forward(self, input):
        # [bs, h_dim, x*y+s1+s2+cls]
        h = self.lin1(input)
        h = self.active(h)
        # [bs, d_ff, x*y+s1+s2+cls]
        h = self.lin2(h)
        # [bs, h_dim, x*y+s1+s2+cls]
        return self.dropout(h)

def get_sinusoid_encoding_table(n_seq, d_hidn):
    def cal_angle(position, i_hidn):
        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)
    def get_posi_angle_vec(position):
        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]

    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])
    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin 
    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos

    return sinusoid_table
def get_attn_pad_mask(seq_q, seq_k, i_pad):
    batch_size, len_q = seq_q.size()
    batch_size, len_k = seq_k.size()
    pad_attn_mask = seq_k.data.eq(i_pad)
    pad_attn_mask= pad_attn_mask.unsqueeze(1).expand(batch_size, len_q, len_k)
    return pad_attn_mask
class Encoder_Layer(torch.nn.Module):
    def __init__(self, h_dim, n_head, d_head, d_ff, dropout, layer_norm_epsilon) -> None:
        super().__init__()
        self.attn = MultiHeadAttention(h_dim, n_head, d_head, dropout)
        self.ln1 = torch.nn.LayerNorm(h_dim, eps=layer_norm_epsilon)
        self.pos_ffn = PoswiseFeedForwardNet(h_dim, d_ff, dropout)
        self.ln2 = torch.nn.LayerNorm(h_dim, eps=layer_norm_epsilon)
    def enable_math(self, enable_math: bool=True):
        self.attn.enable_math(enable_math)
    def forward(self, input, attn_mask):
        # latents = [bs, x * y + scale1 + scale2 + cls, h_dim]
        att_output = self.attn(input, input, input, attn_mask)
        # [bs, x*y+s1+s2+cls, h_dim]
        att_output = self.ln1(input + att_output)
        # [bs, x*y+s1+s2+cls, h_dim]
        ffn_output = self.pos_ffn(att_output)
        return self.ln2(att_output + ffn_output)

class MUSIQ_Encoder(torch.nn.Module):
    def __init__(self, n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout,layer_norm_epsilon) -> None:
        super().__init__()
        # scale Embedding
        self.sce_org_param = torch.nn.Parameter(torch.randn(1, h_dim, 1, 1))
        self.sce_1_param = torch.nn.Parameter(torch.randn(1, h_dim, 1, 1))
        self.sce_2_param = torch.nn.Parameter(torch.randn(1, h_dim, 1, 1))
        # Hash-based 2D Spatial Embedding
        self.grid_size = grid_size
        self.hse_param = torch.nn.Parameter(torch.randn(1, h_dim, grid_size, grid_size))
        # CLS token
        self.cls_param = torch.nn.Parameter(torch.zeros(1, h_dim, 1))
        self.dropout = torch.nn.Dropout(dropout)

        # Transformer Layer
        self.layers = torch.nn.ModuleList([Encoder_Layer(h_dim, n_head, d_head, d_ff, dropout, layer_norm_epsilon) for _ in range(n_layer)])
    def enable_math(self, enable_math: bool=True):
        for layer in self.layers:
            layer.enable_math(enable_math)
    def forward(self, org_emb, scale_1_emb, scale_2_emb, mask_input=None):
        # latents = [bs, h_dim, x, y]
        bs, h_dim, x, y = org_emb.size()
        __, __, x1, y1 = scale_1_emb.size()
        __, __, x2, y2 = scale_2_emb.size()

        # scale Embedding
        scale_emb_org = repeat(self.sce_org_param, "() h () () -> b h x y", b=bs, x=x, y=y)
        scale_emb_1 = repeat(self.sce_1_param, "() h () () -> b h x y", b=bs, x=x1, y=y1)
        scale_emb_2 = repeat(self.sce_2_param, "() h () () -> b h x y", b=bs, x=x2, y=y2)
        org_emb += scale_emb_org
        scale_1_emb += scale_emb_1
        scale_2_emb += scale_emb_2

        # pos emb
        spatial_org_embed = torch.zeros(1, h_dim, x, y).to(org_emb.device)
        for i in range(x):
            for j in range(y):
                t_i = int((i/x)*self.grid_size)
                t_j = int((j/y)*self.grid_size)
                spatial_org_embed[:, :, i, j] = self.hse_param[:, :, t_i, t_j]
        spatial_org_embed = repeat(spatial_org_embed, '() h x y -> b h x y', b=bs)

        spatial_1_embed = torch.zeros(1, h_dim, x1, y1).to(org_emb.device)
        for i in range(x1):
            for j in range(y1):
                t_i = int((i/x1)*self.grid_size)
                t_j = int((j/y1)*self.grid_size)
                spatial_1_embed[:, :, i, j] = self.hse_param[:, :, t_i, t_j]
        spatial_1_embed = repeat(spatial_1_embed, '() h x y -> b h x y', b=bs)

        spatial_2_embed = torch.zeros(1, h_dim, x2, y2).to(org_emb.device)
        for i in range(x2):
            for j in range(y2):
                t_i = int((i/x2)*self.grid_size)
                t_j = int((j/y2)*self.grid_size)
                spatial_2_embed[:, :, i, j] = self.hse_param[:, :, t_i, t_j]
        spatial_2_embed = repeat(spatial_2_embed, '() h x y -> b h x y', b=bs)

        org_emb += spatial_org_embed
        scale_1_emb += spatial_1_embed
        scale_2_emb += spatial_2_embed

        # latents = [bs, h_dim, x, y] -> [bs, h_dim, x * y]
        org_emb = org_emb.view(bs, h_dim, -1)
        scale_1_emb = scale_1_emb.view(bs, h_dim, -1)
        scale_2_emb = scale_2_emb.view(bs, h_dim, -1)

        # latents = [bs, h_dim, x, y] -> [bs, h_dim, x * y + scale1 + scale2]
        input_emb = torch.concat([org_emb, scale_1_emb, scale_2_emb], dim=2)

        # latents = [bs, h_dim, x * y + scale1 + scale2] -> [bs, h_dim, x * y + scale1 + scale2 + cls]
        cls_emb = repeat(self.cls_param, '() h l -> b h l', b=bs)
        input_emb = torch.cat((cls_emb, input_emb), dim=2)
        # latents = [bs, h_dim, x * y + scale1 + scale2 + cls] -> [bs, x * y + scale1 + scale2 + cls, h_dim]
        output = self.dropout(input_emb).permute(0, 2, 1).contiguous()

        # (bs, n_enc_seq+1, n_enc_seq+1)
        attn_mask = None # get_attn_pad_mask(mask_input, mask_input, self.config.i_pad)

        for layer in self.layers:
            output = layer(output, attn_mask)
        return output

class MUSIQ(torch.nn.Module):
    def __init__(self, n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon) -> None:
        super().__init__()
        self.pre_encoder_dim = 2048

        self.h_dim = h_dim
        self.in_conv = torch.nn.Conv2d(self.pre_encoder_dim, self.h_dim, kernel_size=1, bias=False)
        self.in_conv_1 = torch.nn.Conv2d(self.pre_encoder_dim, self.h_dim, kernel_size=1, bias=False)
        self.in_conv_2 = torch.nn.Conv2d(self.pre_encoder_dim, self.h_dim, kernel_size=1, bias=False)

        self.mhattn = MUSIQ_Encoder(n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon)

    def enable_math(self, enable_math: bool=True):
        self.mhattn.enable_math(enable_math)
    def forward(self, latents, scale_1_latents, scale_2_latents):
        # latents[bs, x, y, resnet_dim * w * h]
        # scale_latents = [ latents_scale1,  latents_scale2, ...]
        bs, x, y, __ = latents.size()
        __, s0_x, s0_y, __ = scale_1_latents.size()
        __, s1_x, s1_y, __ = scale_2_latents.size()

        # latents[bs, x, y, resnet_dim] -> [bs, resnet_dim, x, y]
        latents = latents.permute(0, 3, 1, 2).contiguous()
        s0_latents = scale_1_latents.permute(0, 3, 1, 2).contiguous()
        s1_latents = scale_2_latents.permute(0, 3, 1, 2).contiguous()

        # Pre Encode
        # latents[bs, resnet_dim, x, y] -> [bs, h_dim, x, y]
        h_org = self.in_conv(latents)
        h_s0 = self.in_conv_1(s0_latents)
        h_s1 = self.in_conv_2(s1_latents)
        # 
        output = self.mhattn(h_org, h_s0, h_s1)
        # latents[bs, x*y + s1x*s1y + s2x*s2y, h_dim, x, y]
        return output

class MLP(pytorch_lightning.LightningModule):
    def __init__(self, input_size=768, h_size=None):
        super().__init__()
        self.input_size = input_size
        self.h_size = h_size if h_size is not None else self.input_size//2
        self.hidden_size = max(self.h_size, 1024)
        
        self.model = torch.nn.Sequential(
            torch.nn.Linear(self.input_size, self.hidden_size),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size, self.hidden_size//8),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size//8, self.hidden_size//32),
            torch.nn.Linear(self.hidden_size//32, 1)
        )
    def forward(self, x):
        return self.model(x)

class MUSIQ_SCORE_Model(torch.nn.Module):
    def __init__(self, n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon, output_scale=1) -> None:
        super().__init__()
        self.musiq = MUSIQ(n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon)
        self.mlp = MLP(h_dim * output_scale)
        self.output_scale=output_scale
    def enable_math(self, enable_math: bool=True):
        self.musiq.enable_math(enable_math)
    def forward(self, latents, scale_1_latents, scale_2_latents):
        if self.output_scale == 1:
            h = self.musiq(latents, scale_1_latents, scale_2_latents)[:, 0]
        else:
            h = self.musiq(latents, scale_1_latents, scale_2_latents)[:, 0:self.output_scale].contiguous().view(latents.size(0), -1)
        return self.mlp(h)
# モデル作成用
def Create_MUSIQ_Model(n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon, score_model_dir=None):
    return resnet50_backbone(score_model_dir), MUSIQ(n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon)
def Create_MUSIQ_SCORE_Model(n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon, score_model_dir=None, output_scale=1):
    return resnet50_backbone(score_model_dir), MUSIQ_SCORE_Model(n_layer, h_dim, n_head, d_head, d_ff, grid_size, dropout, layer_norm_epsilon, output_scale)


class Score_Manager():
    def __init__(self, model_path, device, score_max, args=None) -> None:
        score_args = {}
        if args is not None:
            for net_arg in args:
                key, value = net_arg.split("=")
                if key == "version":
                    version = int(value)
        if args.version == 0:
            self.scale_size = 1
            self.image_size = 1
            self.npy_dot = ".npy"
        elif args.version == 1:
            self.scale_size = 2
            self.image_size = 1 + (self.scale_size * self.scale_size)
            #args.output = args.output + "_x4"
            self.npy_dot = "_x4.npy"
        elif args.version == 2:
            self.scale_size = 3
            self.image_size = 1 + (self.scale_size * self.scale_size)
            #args.output = args.output + "_x9"
            self.npy_dot = "_x9.npy"
        
        self.image_preprocess = None
        self.clip_model, self.clip_preprocess = clip.load("ViT-L/14", device="cpu")  #RN50x64
        self.preprocess_size = self.clip_model.visual.input_resolution
        if version >= 1:
            self.image_preprocess = get_image_preprocess(self.preprocess_size, self.scale_size)
        self.tokenizer = clip.tokenize
        self.mlp = None#MLP(768*self.image_size)
        self.device = device
        if score_max is not None:
            self.score_max = score_max
        else:
            self.score_max = 1.
        if os.path.splitext(model_path)[-1]!=".pth":
            model_path = f"{model_path}.pth"
        s = torch.load(model_path)
        
        self.mlp.load_state_dict(s)

    def to_gpu(self):
        self.mlp.to(self.device)
        self.mlp.requires_grad_(False)
        self.mlp.eval()
        self.clip_model.to(self.device)
        self.clip_model.eval()
    def to_cpu(self):
        self.mlp.to("cpu")
        self.clip_model.to("cpu")
    
    def get_score(self, raw_image, prompt):
        with torch.no_grad():
            #txt_id = self.tokenizer(prompt, truncate=True).to(self.device)
            #if txt_id.size(1) > 77:
            #    print(f"too long token({txt_id.size()}): {prompt}")
            image = self.clip_preprocess(raw_image).unsqueeze(0).to(self.device)
            image_features = self.clip_model.encode_image(image)
            if self.image_size > 1:
                image = self.image_preprocess(raw_image).unsqueeze(0).to(self.device)
                for i in range(self.scale_size):
                    for j in range(self.scale_size):
                        image_features = torch.concat([image_features,self.clip_model.encode_image(image[:,:,i*self.preprocess_size:(i+1)*self.preprocess_size,j*self.preprocess_size:(j+1)*self.preprocess_size])], dim=1)
                
            #txt_features = self.clip_model.encode_text(txt_id)
        
        return self.mlp(image_features).data.cpu()[0][0]/self.score_max

if __name__ == '__main__':
    score_module_dir = "./score_module"
    model_params, dataset_params, train_params = get_property("./test_dataset", batch_size=2, mode="musiq_clip", eval_per=0.1, hdf5_resume=False, hdf5_add_load=False)
    print_dict(model_params, "model params")
    print_dict(dataset_params, "dataset params")
    
    test = MUSIQ_Score_Dataset(**dataset_params)
    #musiq_model = MUSIQ(2, 332, 5, 5, 5, 10, 0.1, 1e-9, score_module_dir)
    pre_encoder, musiq_model = Create_MUSIQ_SCORE_Model(**model_params)
    #pre_encoder = resnet50_backbone(score_module_dir)
    test.create_datalist(pre_encoder)
    test.print_datacount()
    test.print_datacount_score()
    test.eval=True
    data = test.__getitem__(0)
    scores = data["score"]
    latents = data["latent"]
    scale_1_latents = data["s1_latent"]
    scale_2_latents = data["s2_latent"]
    print("eval---------")
    print(f"datalen: {len(test)}")
    print(f"score: {scores}{scores.size()}\nlatents: {latents.size()}")
    print(f"s1_latents: {scale_1_latents.size()}")
    print(f"s2_latents: {scale_2_latents.size()}")
    print(scale_2_latents)
    test.eval=False
    data = test.__getitem__(0)
    scores = data["score"]
    latents = data["latent"]
    scale_1_latents = data["s1_latent"]
    scale_2_latents = data["s2_latent"]
    print("train---------")
    print(f"datalen: {len(test)}")
    print(f"score: {scores}{scores.size()}\nlatents: {latents.size()}")
    print(f"s1_latents: {scale_1_latents.size()}")
    print(f"s2_latents: {scale_2_latents.size()}")
    print(scale_2_latents)

    print("to cuda")
    musiq_model.to("cuda")
    print("test run")
    output = musiq_model(latents.to("cuda"), scale_1_latents.to("cuda"), scale_2_latents.to("cuda")).to("cpu")
    print(output.size())

```

### src\score_module\rewardfunction_score.py

```

import torch
import pytorch_lightning
import os
import clip
import numpy as np

from PIL import Image
from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize
try:
    from torchvision.transforms import InterpolationMode
    BICUBIC = InterpolationMode.BICUBIC
except ImportError:
    BICUBIC = Image.BICUBIC
def _convert_image_to_rgb(image):
    return image.convert("RGB")
def _transform(n_px):
    return Compose([
        Resize(n_px, interpolation=BICUBIC),
        CenterCrop(n_px),
        _convert_image_to_rgb,
        ToTensor(),
        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),
    ])
def get_image_preprocess(preprocess_size, scale=1):
    return _transform(preprocess_size*scale)

class MLP(pytorch_lightning.LightningModule):
    def __init__(self, input_size, xcol='emb', ycol='avg_rating'):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = max(self.input_size//2, 1024)
        self.xcol = xcol
        self.ycol = ycol
        self.layers = torch.nn.Sequential(
            torch.nn.Linear(self.input_size, self.hidden_size),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(self.hidden_size, 1)
        )

    def forward(self, x):
        return self.layers(x)

class Score_Manager():
    def __init__(self, model_path, device, score_max, args=None) -> None:
        score_args = {}
        if args is not None:
            for net_arg in args:
                key, value = net_arg.split("=")
                if key == "version":
                    version = int(value)
        if version == 0:
            self.image_size = 1
            self.max_tokens = 77
        elif version == 1:
            self.image_size = 1
            self.max_tokens = 231
        elif version == 2:
            self.image_size = 5
            self.max_tokens = 77
        elif version == 3:
            self.image_size = 5
            self.max_tokens = 231
        
        self.token_chunk = 77
        self.token_split_num = self.max_tokens // self.token_chunk

        self.image_preprocess = None
        self.clip_model, self.clip_preprocess = clip.load("ViT-L/14", device="cpu")  #RN50x64
        self.preprocess_size = self.clip_model.visual.input_resolution
        if version >= 2:
            self.image_preprocess = get_image_preprocess(self.preprocess_size, 2)
        self.tokenizer = clip.tokenize
        self.mlp = MLP(768*(self.image_size+self.token_split_num))
        self.device = device
        if score_max is not None:
            self.score_max = score_max
        else:
            self.score_max = 1.
        if os.path.splitext(model_path)[-1]!=".pth":
            model_path = f"{model_path}.pth"
        s = torch.load(model_path)
        
        self.mlp.load_state_dict(s)

    def to_gpu(self):
        self.mlp.to(self.device)
        self.mlp.requires_grad_(False)
        self.mlp.eval()
        self.clip_model.to(self.device)
        self.clip_model.eval()
    def to_cpu(self):
        self.mlp.to("cpu")
        self.clip_model.to("cpu")
    
    def _get_txt_id(self, prompt):
        txt_id = self.tokenizer(prompt, context_length=self.max_tokens, truncate=True).to(self.device)
        if txt_id.size(1) > self.max_tokens:
            print(f"too long token({txt_id.size()}): {prompt}")
        txt_features_list = []
        for i in range(self.token_split_num):
            txt_features = self.clip_model.encode_text(txt_id[:,i*self.token_chunk:(i+1)*self.token_chunk])
            txt_features_list.append(txt_features)
        if self.token_split_num>1:
            txt_features = torch.concat(txt_features_list, dim=1)
        return txt_id, txt_features

    def get_score(self, raw_image, prompt):
        with torch.no_grad():
            #txt_id = self.tokenizer(prompt, truncate=True).to(self.device)
            #if txt_id.size(1) > 77:
            #    print(f"too long token({txt_id.size()}): {prompt}")
            txt_id, txt_features = self._get_txt_id(prompt)
            image = self.clip_preprocess(raw_image).unsqueeze(0).to(self.device)
            image_features = self.clip_model.encode_image(image)
            if self.image_size == 5:
                image = self.image_preprocess(raw_image).unsqueeze(0).to(self.device)
                for i in range(2):
                    for j in range(2):
                        image_features = torch.concat([image_features,self.clip_model.encode_image(image[:,:,i*self.preprocess_size:(i+1)*self.preprocess_size,j*self.preprocess_size:(j+1)*self.preprocess_size])], dim=1)
                
            #txt_features = self.clip_model.encode_text(txt_id)
            input_emb = torch.concat([image_features, txt_features], dim=1)
        
        return self.mlp(input_emb).data.cpu()[0][0]/self.score_max

```

### src\score_module\scorer.py

```
# score_module/scorer.py
import torch
import requests
import numpy as np
from pathlib import Path
from PIL import Image
from transformers import pipeline
import clip
from dataclasses import dataclass
from typing import Dict, List

# モデルのURL
LAION_MODEL_URL = "https://github.com/grexzen/SD-Chad/blob/main/sac+logos+ava1-l14-linearMSE.pth?raw=true"
CAFE_MODEL_URL = "https://huggingface.co/cafeai/cafe_aesthetic/resolve/main/model.safetensors?download=true"

def download_model(url: str, model_path: Path):
    """URLからモデルをダウンロードする
    スコアモデルが増えたとき用に関数化しておく
    Args:
        url (str): ダウンロードするモデルのURL
        model_path (Path): 保存先のパス
    """
    response = requests.get(url, stream=True)
    response.raise_for_status() # HTTPリクエストが失敗した場合、例外を発生させる
    with open(model_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192): # データをチャンクごとに読み込む
            f.write(chunk) # ファイルに書き込む
    print(f"保存完了 {model_path}")

# モデルの読み込み部分をクラスの初期化時に移動
@dataclass
class AestheticScorer:
    device: str = "cuda" if torch.cuda.is_available() else "cpu"

    def __post_init__(self):
        # LAIONモデルの読み込み
        self.laion_model, self.laion_processor = self._load_laion_model()
        # CAFEモデルの読み込み
        self.cafe_pipe = self._load_cafe_model()
        # CLIPモデルの読み込み
        self.clip_model, _ = clip.load("ViT-L/14", device=self.device)

    def _load_laion_model(self):
        model_path = Path("src/score_module/score_models/sac+logos+ava1-l14-linearMSE.pth")
        if not model_path.exists():
            print("LAION モデルダウンロード...")
            download_model(LAION_MODEL_URL, model_path)

        model = AestheticPredictor(768)  # 768はCLIPの出力次元数
        model.load_state_dict(torch.load(model_path, map_location=self.device))
        model.eval()
        model.to(self.device) # モデルを適切なデバイスに移動
        processor = clip.load("ViT-L/14", device=self.device)[1]
        return model, processor

    def _load_cafe_model(self):
        pipe_aesthetic = pipeline("image-classification", "cafeai/cafe_aesthetic", device=self.device)
        return pipe_aesthetic


    def score(self, image: Image.Image, model_type) -> float:
        if model_type == "laion":
            score = self._calculate_laion_score(image)
        elif model_type == "cafe":
            score = self._calculate_cafe_score(image)
        else:
            raise ValueError(f"model_type が不正: {model_type}")
        return score

    def _calculate_laion_score(self, image: Image.Image):
        """LAIONモデルを使って美的スコアを計算する
        Args:
            image (Image.Image): スコアを計算する画像
        Returns:
            float: 美的スコア
        """
        image_tensor = self.laion_processor(image).unsqueeze(0).to(self.device) # 画像をテンソルに変換し、デバイスに移動

        with torch.no_grad(): # 勾配計算を行わない
            image_features = self.clip_model.encode_image(image_tensor) # CLIPモデルで画像の特徴量を抽出
            # 特徴量を正規化し、型とデバイスを調整
            image_features = torch.from_numpy(normalized(image_features.cpu().detach().numpy())).to(self.device).float()

        prediction = self.laion_model(image_features) # LAIONモデルでスコアを予測

        score = prediction.data.cpu().item() # スコアをCPUに移動し、Pythonの数値に変換
        return score

    def _calculate_cafe_score(self, image: Image.Image):
        """CAFEモデルを使って美的スコアを計算する
        Args:
            image (Image.Image): スコアを計算する画像
        Returns:
            float: 美的スコア
        """
        data = self.cafe_pipe(image, top_k=1) # CAFEモデルでスコアを予測
        score = data[0]['score'] if data else 0.0 # スコアを取得
        return score

def normalized(a, axis=-1, order=2):
    """ベクトルを正規化する関数
    Args:
        a (np.array): 正規化するベクトル
        axis (int, optional): 正規化する軸. Defaults to -1.
        order (int, optional): ノルムの次数. Defaults to 2.
    Returns:
        np.array: 正規化されたベクトル
    """
    l2 = np.atleast_1d(np.linalg.norm(a, order, axis)) # ベクトルaのノルムを計算
    l2[l2 == 0] = 1 # ノルムが0の場合は1にする
    return a / np.expand_dims(l2, axis) # 正規化

@dataclass
class AestheticPredictor(torch.nn.Module):
    input_size: int

    def __post_init__(self):
        super().__init__()
        self.layers = torch.nn.Sequential(
            torch.nn.Linear(self.input_size, 1024),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(1024, 128),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(128, 64),
            torch.nn.Dropout(0.1),
            torch.nn.Linear(64, 16),
            torch.nn.Linear(16, 1),
        )

    def forward(self, x):
        return self.layers(x)
```

### src\storage\file_system.py

```
import os
from pathlib import Path
from typing import Any
from PIL import Image, ImageCms
Image.MAX_IMAGE_PIXELS = 1000000000 #クソデカファイルに対応､ローカルアプリななので攻撃の心配はない
from io import BytesIO
import math
import json
import toml
import shutil
from module.log import get_logger
from datetime import datetime

class FileSystemManager:
    logger = get_logger("FileSystemManager")
    image_extensions = ['.jpg', '.png', '.bmp', '.gif', '.tif', '.tiff', '.jpeg', '.webp']
    def __init__(self):
        self.logger = FileSystemManager.logger
        self.initialized = False
        self.image_extensions = FileSystemManager.image_extensions
        self.image_dataset_dir = None
        self.resolution_dir = None
        self.original_images_dir = None
        self.resized_images_dir = None
        self.batch_request_dir = None
        self.logger.debug("初期化")

    def __enter__(self):
        if not self.initialized:
            raise RuntimeError("FileSystemManagerが初期化されていません。")
        return self

    def __exit__(self, exc_type, exc_val, _):
        if exc_type is not None:
            # 例外が発生した場合のログ記録
            self.logger.error("FileSystemManager使用中にエラーが発生: %s",exc_val)
        return False  # 例外を伝播させる

    def initialize(self, output_dir: Path, target_resolution: int):
        """
        FileSystemManagerを初期化｡ 2つの引数はGUI操作で変更可能

        Args:
            output_dir (Path): 出力ディレクトリのパス
            target_resolution (int): 学習元モデルのベース解像度
        """
        # 画像出力ディレクトリをセットアップ
        self.image_dataset_dir = output_dir / 'image_dataset'
        original_dir = self.image_dataset_dir / 'original_images'
        self.resolution_dir = self.image_dataset_dir  / str(target_resolution)

        # 日付ベースのサブディレクトリ
        current_date = datetime.now().strftime("%Y/%m/%d")
        self.original_images_dir = original_dir / current_date
        self.resized_images_dir = self.resolution_dir / current_date

        # batch Request jsonl ファイルの保存先
        self.batch_request_dir = output_dir / 'batch_request_jsonl'


        # 必要なすべてのディレクトリを作成
        directories_to_create = [
            output_dir,
            self.image_dataset_dir, original_dir, self.resolution_dir,
            self.original_images_dir, self.resized_images_dir,self.batch_request_dir
        ]
        for dir_path in directories_to_create:
            self._create_directory(dir_path)

        self.initialized = True
        self.logger.debug ("FileSystemManagerが正常に初期化されました。")

    def _create_directory(self, path: str | Path ):
        """
        指定されたパスにディレクトリがなければ作成｡

        Args:
            path (str | Path ): 作成するディレクトリのパス
        """
        path = Path(path)
        try:
            path.mkdir(parents=True, exist_ok=True)
            self.logger.debug ("ディレクトリを作成: %s", path)
        except Exception as e:
            self.logger.error("ディレクトリの作成に失敗: %s. FileSystemManager._create_directory: %s", path, str(e))
            raise

    @staticmethod
    def get_image_files(input_dir: Path) -> list[Path]:
        """
        ディレクトリから画像ファイルのリストを取得｡

        Returns:
            list[Path]: 画像ファイルのパスのリスト
        """
        image_files = []
        for ext in FileSystemManager.image_extensions:
            for image_file in input_dir.rglob(f'*{ext}'):
                image_files.append(image_file)
        FileSystemManager.logger.debug(f"get_image_files \n image_file list:{image_files}")
        return image_files

    @staticmethod
    def get_image_info(image_path: Path) -> dict[str, Any]:
        """
        画像ファイルから基本的な情報を取得する 不足している情報は登録時に設定

        編集前 uuid, stored_image_path

        編集後 image_id, stored_image_path

        Args:
            image_path (Path): 画像ファイルのパス

        Returns:
            dict[str, Any]: 画像の基本情報（幅、高さ、フォーマット、モード、アルファチャンネル情報、ファイル名、ファイルの拡張子）
        """
        try:
            with Image.open(image_path) as img:
                width, height = img.size
                format_value = img.format.lower() if img.format else 'unknown'
                mode = img.mode
                # アルファチャンネル画像情報 BOOL
                has_alpha = img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info)

            # 色域情報の詳細な取得
            color_space = mode
            icc_profile = img.info.get('icc_profile')
            if icc_profile:
                profile = ImageCms.ImageCmsProfile(BytesIO(icc_profile))
                color_space = ImageCms.getProfileName(profile).strip()

            return {
                'width': width,
                'height': height,
                'format': format_value,
                'mode': mode,
                'has_alpha': has_alpha,
                'filename': image_path.name,
                'extension': image_path.suffix,
                'color_space': color_space,
                'icc_profile': 'Present' if icc_profile else 'Not present'
            }
        except Exception as e:
            message = f"画像情報の取得失敗: {image_path}. FileSystemManager.get_image_info: {str(e)}"
            FileSystemManager.logger.error(message)
            raise

    def _get_next_sequence_number(self, save_dir: str | Path ) -> int:
        """
        処理後画像のリネーム書利用連番

        指定されたディレクトリ内の次のシーケンス番号を取得します。

        Args:
            save_dir (str | Path ): シーケンス番号を取得するディレクトリのパス

        Returns:
            int: 次のシーケンス番号
        """
        try:
            files = list(Path(save_dir).glob(f'{Path(save_dir).name}_*.webp'))
            return len(files)
        except Exception as e:
            self.logger.error("シーケンス番号の取得に失敗: %s. FileSystemManager._get_next_sequence_number: %s", save_dir, str(e))
            raise

    def save_processed_image(self, image: Image.Image, original_path: Path) -> Path:
        """
        処理済みの画像を保存｡

        Args:
            image (Image.Image): 保存する画像オブジェクト
            original_filename (Path): 元のファイルpath

        Returns:
            Path: 保存された画像のパス
        """
        try:
            parent_name = original_path.parent.name
            parent_dir = self.resized_images_dir / parent_name # type: ignore
            self._create_directory(parent_dir)

            sequence = self._get_next_sequence_number(parent_dir)
            new_filename = f"{parent_name}_{sequence:05d}.webp"
            output_path = parent_dir /new_filename

            image.save(output_path)
            self.logger.info("処理済み画像を保存: %s", output_path)
            return output_path
        except Exception as e:
            self.logger.error("処理済み画像の保存に失敗: %s. FileSystemManager.save_original_image: %s", new_filename, str(e))
            raise

    @staticmethod
    def copy_file(src: Path, dst: Path, buffer_size: int = 64 * 1024 * 1024):  # デフォルト64MB
        """
        ファイルをコピーする独自の関数。
        異なるドライブ間でのコピーにも対応。

        Args:
            src (Path): コピー元のファイルパス
            dst (Path): コピー先のファイルパス
            buffer_size (int): バッファサイズ（バイト）。デフォルトは64MB。
        """
        with open(src, 'rb') as fsrc:
            with open(dst, 'wb') as fdst:
                while True:
                    buffer = fsrc.read(buffer_size)
                    if not buffer:
                        break
                    fdst.write(buffer)

        # ファイルの更新日時と作成日時を設定
        os.utime(dst, (os.path.getatime(src), os.path.getmtime(src)))
        shutil.copystat(src, dst)

    def save_original_image(self, image_file: Path) -> Path:
        """
        元の画像をデータベース用ディレクトリに保存します。

        Args:
            image_file (Path): 保存する元画像のパス

        Returns:
            Path: 保存された画像のパス
        """
        try:
            # 保存先のディレクトリパスを生成
            parent_name = image_file.parent.name
            save_dir = self.original_images_dir / parent_name # type: ignore
            self._create_directory(save_dir)
            # 新しいファイル名を生成（元のファイル名を保持）
            new_filename = image_file.name
            output_path = save_dir / new_filename
            # ファイル名の重複をチェックし、必要に応じて連番を付加
            counter = 1
            while output_path.exists():
                new_filename = f"{image_file.stem}_{counter}{image_file.suffix}"
                output_path = save_dir / new_filename
                counter += 1
            # 画像をコピー
            self.copy_file(image_file, output_path)

            self.logger.info("元画像を保存: %s", output_path)
            return output_path
        except Exception as e:
            self.logger.error("元画像の保存に失敗: %s. FileSystemManager.save_original_image: %s", image_file, str(e))
            raise

    def create_batch_request_file(self) -> Path:
        """新しいバッチリクエストJSONLファイルを作成します。

        Returns:
            Path: 作成されたJSONLファイルのパス
        """
        batch_request = self.batch_request_dir / 'batch_request.jsonl' # type: ignore
        return batch_request

    def save_batch_request(self, file_path: Path, data: dict[str, Any]):
        """バッチリクエストデータをJSONLファイルとして保存します。

        Args:
            file_path (Path): 追加先のJSONLファイルのパス
            data (dict[str, Any]): 追加するデータ
        """
        with open(file_path, 'a', encoding='utf-8') as f:
            json.dump(data, f)
            f.write('\n')

    def split_jsonl(self, jsonl_path: Path, jsonl_size: int, json_maxsize: int) -> None:
        """
        JSONLが96MB[OpenAIの制限]を超えないようにするために分割して保存する
        保存先はjsonl_pathのサブフォルダに保存される

        Args:
            jsonl_path (Path): 分割が必要なjsonlineファイルのpath
            jsonl_size (int): 分割が必要なjsonlineファイルのサイズ
            json_maxsize (int): OpenAI API が受け付ける最大サイズ
        """
        # jsonl_sizeに基づいてファイルを分割
        split_size = math.ceil(jsonl_size / json_maxsize)
        with open(jsonl_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        lines_per_file = math.ceil(len(lines) / split_size)  # 各ファイルに必要な行数
        split_dir = jsonl_path / "split"
        split_dir.mkdir(parents=True, exist_ok=True)
        for i in range(split_size):
            split_filename = f'instructions_{i}.jsonl'
            split_path = split_dir / split_filename
            with open(split_path, 'w', encoding='utf-8') as f:
                f.writelines(lines[i * lines_per_file:(i + 1) * lines_per_file])

    @staticmethod
    def export_dataset_to_txt(image_data: dict, save_dir: Path):
        """学習用データセットをテキスト形式で指定ディレクトリに出力する

        Args:
            image_data (dict]): 画像データ. 各辞書は 'path', 'tags', 'caption' をキーに持つ
            save_dir (Path): 保存先のディレクトリパス
        """
        image_path = image_data['path']
        file_name = image_path.stem

        with open(save_dir / f"{file_name}.txt", "w", encoding="utf-8") as f:
            tags = ', '.join([tag_data['tag'] for tag_data in image_data['tags']])
            f.write(tags)
        with open(save_dir / f"{file_name}.caption", "w", encoding="utf-8") as f:
            captions = ', '.join([caption_data['caption'] for caption_data in image_data['captions']])
            f.write(captions)
        FileSystemManager.copy_file(image_path, save_dir / image_path.name)

    @staticmethod
    def export_dataset_to_json(image_data: dict, save_dir: Path):
        """学習用データセットをJSON形式で指定ディレクトリに出力する

        Args:
            image_data (list[dict]): 画像データのリスト. 各辞書は 'path', 'tags', 'caption' をキーに持つ
            save_dir (Path): 保存先のディレクトリパス
        """
        json_data = {}
        image_path = image_data['path']
        save_image = save_dir / image_path.name
        FileSystemManager.copy_file(image_path, save_image)
        tags = ', '.join([tag_data['tag'] for tag_data in image_data['tags']])
        captions = ', '.join([caption_data['caption'] for caption_data in image_data['captions']])
        image_key = str(save_image)
        json_data[image_key] = {"tags": tags, "caption": captions}

        with open(save_dir / "meta_data.json", "a", encoding="utf-8") as f:
            json.dump(json_data, f, indent=4, ensure_ascii=False)
            f.write('\n')

    @staticmethod
    def save_toml_config(config: dict, filename: str) -> None:
        try:
            with open(filename, 'w') as f:
                toml.dump(config, f)
        except Exception as e:
            FileSystemManager.logger.error("保存エラー", str(e))
            raise IOError(f"設定の保存中にエラーが発生しました: {str(e)}")
```

### src\utils\config.py

```
import toml
from pathlib import Path
from typing import Any
from copy import deepcopy

# デフォルト設定
DEFAULT_CONFIG = {
    'directories': {
        'database': 'Image_database',
        'dataset': '',
        'output': 'output',
        'edited_output': 'edited_output',
        'response_file': 'response_file'
    },
    'image_processing': {
        'target_resolution': 1024,
        'realesrganer_upscale': False,
        'realesrgan_model': "RealESRGAN_x4plus_anime_6B.pth"
    },
    'generation': {
        'batch_jsonl': False,
        'start_batch': False,
        'single_image': True
    },
    'options': {
        'generate_meta_clean': False,
        'cleanup_existing_tags': False,
        'join_existing_txt': True
    },
    'prompts': {
        'main': "",
        'additional': ""
    },
    'text_extensions': ['.txt', '.caption'],
    'preferred_resolutions': [
        (512, 512), (768, 512), (512, 768),
        (1024, 1024), (1216, 832), (832, 1216)
    ],
    'image_database': 'image_database.db',
    'log': {
        'level': 'INFO',
        'file': 'app.log'
    }
}

def load_config(config_file: str = 'processing.toml') -> dict:
    try:
        # TOMLファイルの読み込み
        with open(config_file, 'r', encoding='utf-8') as f:
            load_parameters = toml.load(f)

        # 必須セクションのチェック
        for section in ['directories', 'image_processing']:
            if section not in load_parameters:
                raise KeyError(f"必須の設定セクション '{section}' が見つかりません。")

        # mainprompt.mdファイルの存在確認と読み込み
        prompt_file = Path('mainprompt.md')
        if prompt_file.exists():
            with open(prompt_file, 'r', encoding='utf-8') as f:
                load_parameters.setdefault('prompts', {})
                load_parameters['prompts']['main'] = f.read()
        else:
            load_parameters.setdefault('prompts', {})
            load_parameters['prompts']['main'] = ""  # デフォルト値として空文字列を設定

        return load_parameters
    except FileNotFoundError as exc:
        raise ValueError(f"設定ファイル '{config_file}' が見つかりません。") from exc
    except toml.TomlDecodeError as e:
        raise ValueError(f"設定ファイルの解析エラー: {str(e)}") from e

def deep_update(d: dict[str, Any], u: dict[str, Any]) -> dict[str, Any]:
    for k, v in u.items():
        if isinstance(v, dict):
            d[k] = deep_update(d.get(k, {}), v)
        elif v != "":
            d[k] = v
    return d

def get_config(config_file = 'processing.toml') -> dict:
    final_config = deepcopy(DEFAULT_CONFIG)
    loaded_config = load_config(config_file)
    final_config = deep_update(final_config, loaded_config)
    return final_config

def write_config_file(config_data: dict[str, Any], file_name: str = "processing.toml"):
    """設定をファイルに保存します。"""
    try:
        with open(file_name, "w", encoding="utf-8") as f:
            toml.dump(config_data, f)
    except Exception as e:
        print(f"設定ファイルの保存に失敗しました: {e}")

if __name__ == "__main__":
    try:
        config = get_config()
        print(config)
    except (FileNotFoundError, ValueError, KeyError) as e:
        print(f"設定エラー processing.tomlを確認: {e}")
```

### src\utils\log.py

```
import sys
import locale
import logging
import traceback
import io
from pathlib import Path
from logging.handlers import RotatingFileHandler
from typing import Dict

# システムのデフォルトエンコーディングをUTF-8に設定
if sys.platform.startswith('win'):
    # Windowsの場合
    import ctypes
    ctypes.windll.kernel32.SetConsoleCP(65001)
    ctypes.windll.kernel32.SetConsoleOutputCP(65001)
else:
    # Unix系の場合
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')

def setup_logger(config: Dict[str, str]) -> None:
    log_level = config['level'].upper()
    log_file = Path(config['file'])

    numeric_level = getattr(logging, log_level, None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {log_level}')

    # ルートロガーの設定
    root_logger = logging.getLogger()
    root_logger.setLevel(numeric_level)

    # 既存のハンドラを削除
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # ログのフォーマット設定
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # コンソールハンドラの設定
    console_handler = logging.StreamHandler(stream=sys.stderr)
    console_handler.setLevel(numeric_level)
    console_handler.setFormatter(formatter)
    console_handler.stream = io.TextIOWrapper(console_handler.stream.buffer, encoding='utf-8')
    root_logger.addHandler(console_handler)

    # ファイルハンドラの設定
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes = 10*1024*1024,
        backupCount = 5,
        encoding='utf-8'
    )
    file_handler.setLevel(numeric_level)
    file_handler.setFormatter(formatter)
    root_logger.addHandler(file_handler)

    # デバッグ情報の出力
    print(f"Debug: StreamHandler's stream: {console_handler.stream}", file=sys.stderr)

def get_logger(name: str) -> logging.Logger:
    return logging.getLogger(name)
```

### src\utils\tools.py

```
"""使い回せそうなスタティックメソッドを提供するモジュール"""
from pathlib import Path

class ToolsStatic:
    """ユーティリティクラス
    スタティックメソッドを提供
    """

    @staticmethod
    def join_txt_and_caption_files(dir_path: Path):
        """指定したディレクトリ内の.captionファイルを.txtファイルに追加する
        # TODO: 使用箇所なし src.ImageEditor.py src.DatasetExportWidget.py で使えるように実装
        """
        file_dict = {}
        for file in dir_path.iterdir():
            if file.is_file():
                basename = file.stem
                ext = file.suffix
                if basename not in file_dict:
                    file_dict[basename] = []
                file_dict[basename].append(ext)

        # .txtと.captionの両方が存在するファイルを処理
        for basename, extensions in file_dict.items():
            if '.txt' in extensions and '.caption' in extensions:
                txt_file = dir_path / f"{basename}.txt"
                caption_file = dir_path / f"{basename}.caption"

                # .captionファイルの内容を読み込む
                with open(caption_file, 'r', encoding='utf-8') as cf:
                    caption_content = cf.read()

                # .txtファイルに内容を追加
                with open(txt_file, 'a', encoding='utf-8') as tf:
                    tf.write('\n')  # 区切りのために改行を追加
                    tf.write(caption_content)

                print(f"{caption_file} を {txt_file} に追加しました。")
```

### tests\conftest.py

```
# conftest.py
from unittest.mock import Mock, MagicMock, patch
from pathlib import Path
import sys
import uuid
import shutil

try:

    from module.file_sys import FileSystemManager
except ImportError:
    from src.module.file_sys import FileSystemManager
from module.config import get_config
from module.log import setup_logger, get_logger
from ImageEditor import ImageProcessingManager


# QApplication のインスタンスを作成
@pytest.fixture(scope="session")
def app():
    return QApplication([])


# テスト用パス############################################################
@pytest.fixture(scope="session")
def tmp_path_factory(request):
    return request.config.rootpath / "TEST" / "pytest_temp"


@pytest.fixture(scope="session")
def tmp_path(tmp_path_factory):
    return tmp_path_factory


# テスト用データベース############################################################
@pytest.fixture(scope="session")
def test_db_paths(tmp_path):
    img_db = tmp_path / "db" / "test_image_database.db"
    tag_db = tmp_path / "db" / "test_tag_database.db"
    img_db.parent.mkdir(parents=True, exist_ok=True)
    tag_db.parent.mkdir(parents=True, exist_ok=True)
    return img_db, tag_db


@pytest.fixture(scope="module")
def sqlite_manager(test_db_paths):
    img_db, tag_db = test_db_paths
    manager = SQLiteManager(img_db, tag_db)
    manager.create_tables()
    manager.insert_models()
    yield manager
    manager.close()
    img_db.unlink(missing_ok=True)
    tag_db.unlink(missing_ok=True)


# 主要なクラスのモック############################################################
@pytest.fixture
def mock_image_database_manager(mocker):
    mock_idm = mocker.Mock(spec=ImageDatabaseManager)
    return mock_idm


@pytest.fixture
def mock_image_processing_manager(mocker):
    mock_ipm = mocker.Mock(spec=ImageProcessingManager)
    return mock_ipm


@pytest.fixture
def mock_file_system_manager(tmp_path):
    """
    FileSystemManager のモックを提供します。
    テスト用の一時ディレクトリを使用します。
    """
    mock_fs = MagicMock(spec=FileSystemManager)
    mock_fs.original_images_dir = tmp_path / "original_images"
    mock_fs.resized_images_dir = tmp_path / "resized_images"
    mock_fs.batch_request_dir = tmp_path / "batch_request_jsonl"
    mock_fs.original_images_dir.mkdir(parents=True, exist_ok=True)
    mock_fs.resized_images_dir.mkdir(parents=True, exist_ok=True)
    mock_fs.batch_request_dir.mkdir(parents=True, exist_ok=True)
    return mock_fs


@pytest.fixture(scope="session")
def preferred_resolutions():
    config = get_config()
    return config["preferred_resolutions"]


# サンプル画像とデータ############################################################
@pytest.fixture
def sample_images(tmp_path):
    """
    テスト用のサンプル画像を作成し、そのパスを提供します。
    """
    from PIL import Image

    # RGB512 画像
    rgb512_image = Image.new("RGB", (512, 512), color="red")
    rgb512_path = tmp_path / "rgb512_image.jpg"
    rgb512_image.save(rgb512_path)

    # RGB 画像
    rgb_image = Image.new("RGB", (800, 600), color="red")
    rgb_path = tmp_path / "rgb_image.jpg"
    rgb_image.save(rgb_path)

    # RGBA 画像
    rgba_image = Image.new("RGBA", (800, 600), color=(0, 255, 0, 128))
    rgba_path = tmp_path / "rgba_image.png"
    rgba_image.save(rgba_path)

    # CMYK 画像
    cmyk_image = Image.new("CMYK", (800, 600), color="blue")
    cmyk_path = tmp_path / "cmyk_image.tiff"
    cmyk_image.save(cmyk_path)

    # パレットモード画像
    p_image = Image.new("P", (800, 600))
    p_image.putpalette(
        [0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255] * 64  # 黒  # 赤  # 緑  # 青
    )  # パレットを256色分埋める
    p_image.paste(1, (0, 0, p_image.width, p_image.height))  # 画像全体を赤で塗りつぶす
    p_path = tmp_path / "p_image.png"
    p_image.save(p_path)

    return {"rgb": rgb_path, "rgb512": rgb512_path, "rgba": rgba_path, "cmyk": cmyk_path, "p": p_path}


@pytest.fixture
def sample_image_path_list(sample_images):
    path_list = list(sample_images.values())
    yield path_list


@pytest.fixture(scope="session")
def test_image_path(tmp_path):
    source_image = Path("testimg/1_img/file01.webp")  # プロジェクトルートからの相対パス
    temp_dir = tmp_path / "images"
    temp_dir.mkdir(exist_ok=True)
    dest_image = temp_dir / "test_image.webp"
    shutil.copy(source_image, dest_image)
    return dest_image


@pytest.fixture
def test_image_info(test_image_path):
    return {
        "uuid": str(uuid.uuid4()),
        "stored_image_path": str(test_image_path),
        "width": 512,
        "height": 512,
        "format": "WEBP",
        "mode": "RGB",
        "has_alpha": False,
        "filename": test_image_path.name,
        "extension": "webp",
        "color_space": "sRGB",
        "icc_profile": None,
    }


@pytest.fixture
def sample_image_info():
    return {
        "uuid": str(uuid.uuid4()),
        "stored_image_path": "testimg/1_img/file01.webp",
        "width": 512,
        "height": 512,
        "format": "WEBP",
        "mode": "RGB",
        "has_alpha": False,
        "filename": "file01.webp",
        "extension": "webp",
        "color_space": "sRGB",
        "icc_profile": None,
    }


# GUIのモック############################################################
from PySide6.QtWidgets import QApplication, QWidget
from PySide6.QtCore import Signal


@pytest.fixture(scope="session")
def app():
    return QApplication.instance() or QApplication(sys.argv)


# 一回だけ初期化しないとValueError: I/O operation on closed file
@pytest.fixture(scope="session")
def setup_logging_once():
    setup_logger({"level": "DEBUG", "file": "test.log"})


@pytest.fixture
def mock_main_window(setup_logging_once, mocker):
    class MockMainWindow:
        def __init__(self):
            self.logger = get_logger("MockMainWindow")  # 既にセットアップされたロガーを使用
            self.progress_controller = mocker.Mock()
            self.some_long_process = mocker.Mock()

    return MockMainWindow()


# ConfigManager のモックを作成
@pytest.fixture
def mock_config_manager():
    class MockConfigManager:
        def __init__(self):
            self.config = {
                "image_processing": {"target_resolution": 512, "upscaler": "Lanczos"},
                "preferred_resolutions": [512, 768, 1024],
                "directories": {"edited_output": "edited_output_directory"},
            }
            self.dataset_image_paths = []
            self.vision_models = {
                1: {"name": "gpt-4o", "provider": "OpenAI"},
                2: {"name": "gpt-4-turbo", "provider": "OpenAI"},
                5: {"name": "gpt-4o-mini", "provider": "OpenAI"},
                6: {"name": "gemini-1.5-pro-exp-0801", "provider": "Google"},
                7: {"name": "gemini-1.5-pro-preview-0409", "provider": "Google"},
            }
            self.score_models = {3: {"name": "laion", "provider": ""}, 4: {"name": "cafe", "provider": ""}}
            self.upscaler_models = {13: {"name": "RealESRGAN_x4plus", "provider": "xinntao"}}

    return MockConfigManager()


class MockThumbnailSelectorWidget(QWidget):
    imageSelected = Signal(Path)
    multipleImagesSelected = Signal(list)
    deselected = Signal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.image_paths = []
        self.thumbnail_items = []
        self.load_images = Mock()
        self.get_selected_images = Mock(return_value=[])
        self.select_first_image = Mock()
        self.update_thumbnail_layout = Mock()

    def setMinimumSize(self, width, height):
        pass  # サイズ設定をモック化


@pytest.fixture
def mock_thumbnail_selector_widget(mocker):
    return mocker.patch("src.ThumbnailSelectorWidget.ThumbnailSelectorWidget", MockThumbnailSelectorWidget)


class MockTagFilterWidget(QWidget):
    filterApplied = Signal(dict)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.filterTypeComboBox = Mock()
        self.filterLineEdit = Mock()
        self.resolutionComboBox = Mock()
        self.andRadioButton = Mock()
        self.count_range_slider = Mock()
        self.applyFilterButton = Mock()

    def setup_slider(self):
        pass

    def on_applyFilterButton_clicked(self):
        filter_conditions = {
            "filter_type": self.filterTypeComboBox.currentText().lower(),
            "filter_text": self.filterLineEdit.text(),
            "resolution": int(1024),  # デフォルト値
            "use_and": self.andRadioButton.isChecked(),
            "count_range": (0, 100000),  # デフォルト値
        }
        self.filterApplied.emit(filter_conditions)


@pytest.fixture
def mock_tag_filter_widget(mocker):
    mock_widget = MockTagFilterWidget()
    mocker.patch("src.TagFilterWidget.TagFilterWidget", return_value=mock_widget)
    return mock_widget


from DirectoryPickerWidget import DirectoryPickerWidget


@pytest.fixture
def mock_directory_picker_widget(mocker):
    mock_widget = mocker.Mock(spec=DirectoryPickerWidget)
    mock_widget.get_selected_path.return_value = "/path/to/export"
    return mock_widget

```

### tests\integration\test_DatasetExportWidget.py

```
import pytest
from pytestqt.qtbot import QtBot
from pathlib import Path
from PySide6.QtWidgets import QMessageBox
from PySide6.QtCore import Qt
from unittest.mock import MagicMock, patch
from DatasetExportWidget import DatasetExportWidget

def test_init_ui(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager):
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
    qtbot.addWidget(widget)

    widget.init_ui()
    widget.exportDirectoryPicker.set_label_text("Export Directory:")
    assert widget.exportDirectoryPicker.DirectoryPicker.labelPicker.text() == "Export Directory:"

def test_on_filter_applied(qtbot, mock_config_manager, mock_file_system_manager,
                           mock_image_database_manager, mocker):
    # テストケースを定義
    test_cases = [
        {
            'description': '検索結果がある場合',
            'filter_conditions': {
                'filter_type': 'tags',
                'filter_text': 'tag1, tag2',
                'resolution': 1024,
                'use_and': True,
                'include_untagged': False
            },
            'expected_tags': ['tag1', 'tag2'],
            'expected_caption': '',
            'expected_resolution': 1024,
            'expected_use_and': True,
            'expected_include_untagged': False,
            'filtered_image_metadata': [
                {
                    'id': 1,
                    'image_id': 1,
                    'stored_image_path': '/path/to/image1.jpg',
                    'width': 1024,
                    'height': 1024,
                    'mode': 'RGB',
                    'has_alpha': 0,
                    'filename': 'image1.jpg',
                    'color_space': 'RGB',
                    'icc_profile': 'Not present',
                    'created_at': '2024-09-26T20:21:08.451199',
                    'updated_at': '2024-09-26T20:21:08.451199'
                },
                {
                    'id': 2,
                    'image_id': 2,
                    'stored_image_path': '/path/to/image2.jpg',
                    'width': 1024,
                    'height': 1024,
                    'mode': 'RGB',
                    'has_alpha': 0,
                    'filename': 'image2.jpg',
                    'color_space': 'RGB',
                    'icc_profile': 'Not present',
                    'created_at': '2024-09-26T20:21:08.451199',
                    'updated_at': '2024-09-26T20:21:08.451199'
                }
            ],
            'list_count': 2,
            'expect_no_results': False
        },
        {
            'description': '検索結果がない場合',
            'filter_conditions': {
                'filter_type': 'tags',
                'filter_text': 'nonexistent_tag',
                'resolution': 1024,
                'use_and': True,
                'include_untagged': False
            },
            'expected_tags': ['nonexistent_tag'],
            'expected_caption': '',
            'expected_resolution': 1024,
            'expected_use_and': True,
            'filtered_image_metadata': [],
            'list_count': 0,
            'expect_no_results': True,
            'expected_include_untagged': False
        }
    ]

    for case in test_cases:
        # テストケースの説明を表示
        print(f"Testing case: {case['description']}")

        # ウィジェットのインスタンス化と初期化
        widget = DatasetExportWidget()
        widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
        qtbot.addWidget(widget)

        # get_images_by_filter の返り値を設定
        mock_image_database_manager.get_images_by_filter.return_value = (
            case['filtered_image_metadata'],
            case['list_count']
        )

        # update_thumbnail_selector をモック
        mock_update_thumbnail_selector = mocker.patch.object(widget, 'update_thumbnail_selector')

        # QMessageBox.critical をモック
        mock_critical = mocker.patch.object(QMessageBox, 'critical')

        # on_filter_applied を呼び出し
        widget.on_filter_applied(case['filter_conditions'])

        # get_images_by_filter が正しい引数で呼ばれたか確認
        mock_image_database_manager.get_images_by_filter.assert_called_with(
            tags=case['expected_tags'],
            caption=case['expected_caption'],
            resolution=case['expected_resolution'],
            use_and=case['expected_use_and'],
            start_date=None,
            end_date=None,
            include_untagged=case['expected_include_untagged']
        )

        if case['expect_no_results']:
            # 結果がない場合の検証
            assert widget.image_path_id_map == {}
            mock_update_thumbnail_selector.assert_not_called()
            mock_critical.assert_called_once_with(
                widget,
                "info",
                f"{case['filter_conditions']['filter_type']} に {case['filter_conditions']['filter_text']} を含む検索結果がありません"
            )
        else:
            # 結果がある場合の検証
            expected_image_path_id_map = {
                Path(item['stored_image_path']): item['id'] for item in case['filtered_image_metadata']
            }
            assert widget.image_path_id_map == expected_image_path_id_map

            # update_thumbnail_selector が正しく呼ばれたか確認
            mock_update_thumbnail_selector.assert_called_once_with(
                list(expected_image_path_id_map.keys()),
                case['list_count']
            )
            mock_critical.assert_not_called()

        # モックをリセット
        mock_image_database_manager.get_images_by_filter.reset_mock()
        mock_update_thumbnail_selector.reset_mock()
        mock_critical.reset_mock()

def test_on_exportButton_clicked_no_export_directory(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager, mocker):
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
    qtbot.addWidget(widget)

    # 出力ディレクトリを空に設定
    widget.exportDirectoryPicker.set_path("")

    with patch.object(QMessageBox, 'warning') as mock_warning:
        qtbot.mouseClick(widget.exportButton, Qt.LeftButton)
        mock_warning.assert_called_once()

def test_on_exportButton_clicked_no_export_formats(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager, mocker):
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
    qtbot.addWidget(widget)

    # 出力ディレクトリを設定
    widget.exportDirectoryPicker.set_path("/path/to/export")
    # 出力形式のチェックボックスをオフにする
    widget.checkBoxTxtCap.setChecked(False)
    widget.checkBoxJson.setChecked(False)

    with patch.object(QMessageBox, 'warning') as mock_warning:
        qtbot.mouseClick(widget.exportButton, Qt.LeftButton)
        mock_warning.assert_called_once()

@pytest.mark.parametrize(
    "selected_images, image_path_id_map, annotations_list, expect_warning, expect_critical, expect_information, expect_logger_warning",
    [
        # テストケース1: 正常なエクスポート
        (
            [Path('/path/to/image1.jpg'), Path('/path/to/image2.jpg')],
            {
                Path('/path/to/image1.jpg'): 1,
                Path('/path/to/image2.jpg'): 2
            },
            [
                {'tags': ['tag1', 'tag2'], 'captions': ['caption1']},
                {'tags': ['tag3', 'tag4'], 'captions': ['caption2']}
            ],
            False,  # expect_warning
            False,  # expect_critical
            True,   # expect_information
            False   # expect_logger_warning
        ),
        # テストケース2: image_path_id_map に存在しない画像パスがある
        (
            [Path('/path/to/image1.jpg'), Path('/path/to/image2.jpg')],
            {
                Path('/path/to/image1.jpg'): 1
                # image2.jpg のエントリーがない
            },
            [
                {'tags': ['tag1', 'tag2'], 'captions': ['caption1']}
                # annotations_list も1つだけ
            ],
            False,
            False,
            True,
            True  # image2.jpg のIDが見つからないので警告ログが出る
        ),
        # テストケース3: 選択された画像がない
        (
            [],
            {},
            [],
            True,   # expect_warning: 警告ダイアログが表示される
            False,
            False,
            False
        ),
        # テストケース4: エクスポート中に例外が発生
        (
            [Path('/path/to/image1.jpg')],
            {
                Path('/path/to/image1.jpg'): 1
            },
            Exception("Database error"),  # get_image_annotations が例外を投げる
            False,
            True,   # expect_critical: エラーダイアログが表示される
            False,
            False
        ),
    ]
)
def test_export_dataset(qtbot, mock_config_manager, mock_file_system_manager,
                        mock_image_database_manager, mocker,
                        selected_images, image_path_id_map, annotations_list,
                        expect_warning, expect_critical, expect_information, expect_logger_warning):
    # ウィジェットのインスタンス化と初期化
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
    qtbot.addWidget(widget)

    # GUI コンポーネントのモック設定
    widget.exportButton = mocker.Mock()
    widget.statusLabel = mocker.Mock()
    widget.exportProgressBar = mocker.Mock()
    widget.thumbnailSelector = mocker.Mock()

    # 選択された画像パスを設定
    widget.thumbnailSelector.get_selected_images.return_value = selected_images

    # image_path_id_map を設定
    widget.image_path_id_map = image_path_id_map

    # get_image_annotations の返り値を設定
    if isinstance(annotations_list, Exception):
        # 例外を発生させる
        mock_image_database_manager.get_image_annotations.side_effect = annotations_list
    else:
        mock_image_database_manager.get_image_annotations.side_effect = annotations_list

    # FileSystemManager のメソッドをモック
    mock_file_system_manager.export_dataset_to_txt = mocker.Mock()
    mock_file_system_manager.export_dataset_to_json = mocker.Mock()

    # QMessageBox のモック
    mock_warning = mocker.patch.object(QMessageBox, 'warning')
    mock_critical = mocker.patch.object(QMessageBox, 'critical')
    mock_information = mocker.patch.object(QMessageBox, 'information')

    # ロガーの警告をモック
    mock_logger_warning = mocker.patch.object(widget.logger, 'warning')

    # エクスポートディレクトリとフォーマットを設定
    export_dir = Path('/path/to/export')
    formats = ['txt_cap', 'json']

    # メソッドを実行
    widget.export_dataset(export_dir, formats)

    # 警告ダイアログの確認
    if expect_warning:
        mock_warning.assert_called_once_with(widget, "Warning", "出力する画像を選択してください")
    else:
        mock_warning.assert_not_called()

    # エラーダイアログの確認
    if expect_critical:
        mock_critical.assert_called_once()
    else:
        mock_critical.assert_not_called()

    # 情報ダイアログの確認
    if expect_information:
        mock_information.assert_called_once_with(widget, "Success", "Dataset export completed successfully.")
    else:
        mock_information.assert_not_called()

    # ロガーの警告の確認
    if expect_logger_warning:
        mock_logger_warning.assert_called()
    else:
        mock_logger_warning.assert_not_called()

    # エクスポートメソッドの呼び出し回数を確認
    if not expect_warning and not expect_critical:
        expected_call_count = len(image_path_id_map)
        assert mock_file_system_manager.export_dataset_to_txt.call_count == expected_call_count * (1 if 'txt_cap' in formats else 0)
        assert mock_file_system_manager.export_dataset_to_json.call_count == expected_call_count * (1 if 'json' in formats else 0)
    else:
        mock_file_system_manager.export_dataset_to_txt.assert_not_called()
        mock_file_system_manager.export_dataset_to_json.assert_not_called()

def test_on_exportButton_clicked_no_export_directory(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager, mocker):
    # ウィジェットのインスタンス化
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)

    # GUI コンポーネントのモック設定
    widget.exportDirectoryPicker = mocker.Mock()
    widget.exportDirectoryPicker.get_selected_path.return_value = ''

    # QMessageBox の警告をモック（コンテキストマネージャーを使用しない）
    mock_warning = mocker.patch.object(QMessageBox, 'warning')

    # エクスポートボタンのクリックをシミュレート
    widget.on_exportButton_clicked()

    # 警告ダイアログが表示されたか確認
    mock_warning.assert_called_once_with(widget, "Warning", "出力先ディレクトリを選択してください")

def test_update_thumbnail_selector(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager, mocker):
    # DatasetExportWidget のインスタンスを作成し、必要なマネージャーを初期化
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
    qtbot.addWidget(widget)

    # サムネイルセレクターとラベルをモック化
    widget.thumbnailSelector = mocker.Mock()
    widget.thumbnailSelector.load_images = mocker.Mock()
    widget.thumbnailSelector.get_selected_images.return_value = [Path("/path/to/image1.jpg"), Path("/path/to/image2.jpg")]
    widget.imageCountLabel = mocker.Mock()

    # get_total_image_count の戻り値を設定
    mock_image_database_manager.get_total_image_count.return_value = 100

    # テスト用の画像パスとリスト数を設定
    image_paths = [Path("/path/to/image1.jpg"), Path("/path/to/image2.jpg")]
    list_count = 2

    # update_thumbnail_selector メソッドを実行
    widget.update_thumbnail_selector(image_paths, list_count)

    # load_images メソッドが正しく呼び出されたか確認
    widget.thumbnailSelector.load_images.assert_called_once_with(image_paths)

    # サムネイルセレクターから選択された画像を取得し、正しい数か確認
    selected_images = widget.thumbnailSelector.get_selected_images()
    assert len(selected_images) == 2

    # 画像数のラベルが正しく更新されたか確認
    widget.imageCountLabel.setText.assert_called_once_with(f"Selected Images: {list_count} / Total Images: 100")

def test_update_image_count_label(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager):
    widget = DatasetExportWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager)
    qtbot.addWidget(widget)

    count = 10
    total = 100

    mock_image_database_manager.get_total_image_count.return_value = total

    widget.update_image_count_label(count)

    assert widget.imageCountLabel.text() == f"Selected Images: {count} / Total Images: {total}"

```

### tests\integration\test_db.py

```
import pytest
from pathlib import Path
from module.db import SQLiteManager, ImageRepository, ImageDatabaseManager
from unittest.mock import MagicMock, patch
from module.log import get_logger
import uuid
from datetime import datetime, timezone, timedelta
import time

@pytest.fixture
def test_db_paths(tmp_path):
    img_db = tmp_path / f"test_image_database_{uuid.uuid4()}.db"
    tag_db = Path("src/module/genai-tag-db-tools/tags_v3.db") #テストによる変更がないので実際のパスを使用
    return img_db, tag_db

@pytest.fixture
def sqlite_manager(test_db_paths):
    img_db, tag_db = test_db_paths
    sqlite_manager = SQLiteManager(img_db, tag_db)
    sqlite_manager.create_tables()
    sqlite_manager.insert_models()
    yield sqlite_manager
    sqlite_manager.close()
    img_db.unlink(missing_ok=True)

@pytest.fixture
def image_database_manager(sqlite_manager):
    # ハードコーディングされたパスをテスト用データベースに変更するためパッチ
    with patch.object(ImageDatabaseManager, '__init__', return_value=None):
        idm = ImageDatabaseManager()
        idm.logger = get_logger("ImageDatabaseManager")
        idm.db_manager = sqlite_manager
        idm.repository = ImageRepository(sqlite_manager)
        idm.logger.debug("初期化（テスト用パス使用）")
        yield idm

def test_sqlite_connect(sqlite_manager):
    """データベース接続とテーブル作成の確認"""
    conn = sqlite_manager.connect()
    assert conn is not None
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = {table['name'] for table in cursor.fetchall()}
    expected_tables = {'images', 'processed_images', 'models', 'tags', 'captions', 'scores'}
    assert expected_tables.issubset(tables)

def test_sqlite_fetch_one(sqlite_manager):
    """単一行のデータ取得の確認"""
    query = "SELECT * FROM models WHERE name = ?"
    params = ('gpt-4o',)
    result = sqlite_manager.fetch_one(query, params)
    # 確認するパラメーターはsrc.module.db.SQLiteManager.insert_modelsで追加されたもの
    assert result is not None
    assert result['name'] == 'gpt-4o'
    assert result['type'] == 'vision'
    assert result['provider'] == 'OpenAI'

def test_add_original_image(image_database_manager, sample_image_info):
    """オリジナル画像の追加とメタデータの取得"""
    image_id = image_database_manager.repository.add_original_image(sample_image_info)
    assert isinstance(image_id, int)

    metadata = image_database_manager.repository.get_image_metadata(image_id)
    assert metadata is not None
    for key, value in sample_image_info.items():
        assert metadata[key] == value

def test_duplicate_image(image_database_manager, sample_image_info):
    """重複画像の検出と同一IDの返却確認"""
    image_id1 = image_database_manager.repository.add_original_image(sample_image_info)
    image_id2 = image_database_manager.repository.add_original_image(sample_image_info)  # 重複画像を追加
    assert image_id1 == image_id2  # 同じIDが返される

@patch('module.db.calculate_phash', return_value='mocked_phash')
def test_register_original_image(mock_calculate_phash, image_database_manager, mock_file_system_manager, tmp_path):
    """オリジナル画像の登録処理"""
    manager = image_database_manager

    mock_file_system_manager.get_image_info.return_value = {
        'width': 800,
        'height': 600,
        'format': 'JPEG',
        'mode': 'RGB',
        'has_alpha': False,
        'filename': 'image.jpg',
        'extension': 'jpg',
        'color_space': 'sRGB',
        'icc_profile': None
    }
    mock_file_system_manager.save_original_image.return_value = tmp_path / "image.jpg"

    result = manager.register_original_image(Path("/fake/path/image.jpg"), mock_file_system_manager)
    assert result is not None
    image_id, metadata = result
    assert isinstance(image_id, int)
    assert metadata['width'] == 800
    assert metadata['height'] == 600

def test_register_processed_image(image_database_manager, sample_image_info, tmp_path):
    """処理済み画像の登録とメタデータの確認"""
    manager = image_database_manager

    image_id = manager.repository.add_original_image(sample_image_info)

    # processed_info に extension と phash は不要なため削除
    processed_info = {
        'width': 256,
        'height': 256,
        'format': 'WEBP',
        'mode': 'RGB',
        'has_alpha': False,
        'filename': 'processed.webp',
        'color_space': 'sRGB',
        'icc_profile': None
    }
    processed_path = tmp_path / "processed.webp"
    processed_path.touch()

    result = manager.register_processed_image(image_id, processed_path, processed_info)
    assert result is not None
    processed_image_id = result

    metadata = manager.repository.get_processed_image(image_id)
    assert metadata is not None
    assert len(metadata) > 0
    processed_metadata = metadata[0]
    assert processed_metadata['image_id'] == image_id
    assert processed_metadata['width'] == 256
    assert processed_metadata['height'] == 256

def assert_annotations(retrieved, expected, model_id, case_index, repository):
    if 'tags' in expected:
        assert len(retrieved['tags']) >= len(expected['tags']), f"Case {case_index}: タグの数が一致しません"
        for tag in expected['tags']:
            matching_tags = [t for t in retrieved['tags'] if t['tag'] == tag]
            assert matching_tags, f"Case {case_index}: タグ '{tag}' が見つかりません"
            matching_tag = next((t for t in matching_tags if t['model_id'] == model_id), None)
            assert matching_tag is not None, f"Case {case_index}: タグ '{tag}' に期待される model_id が見つかりません"
            assert matching_tag['model_id'] == model_id, f"Case {case_index}: タグ '{tag}' のmodel_idが一致しません"
            expected_tag_id = repository.find_tag_id(tag)
            assert matching_tags[0]['tag_id'] == expected_tag_id, f"Case {case_index}: タグ '{tag}' のtag_idが一致しません"
            if tag == 'spiked collar':
                assert expected_tag_id == 1, f"Case {case_index}: 'spiked collar' のtag_idが1ではありません"
            
            # 新しい検証: updated_at が現在時刻に近いことを確認
            assert (datetime.now(timezone.utc) - datetime.fromisoformat(matching_tags[0]['updated_at']).replace(tzinfo=timezone.utc)) < timedelta(seconds=100), \
                f"Case {case_index}: タグ '{tag}' のupdated_atが最新ではありません"

    if 'captions' in expected:
        assert len(retrieved['captions']) >= len(expected['captions']), f"Case {case_index}: キャプションの数が一致しません"
        for caption in expected['captions']:
            matching_captions = [c for c in retrieved['captions'] if c['caption'] == caption]
            assert matching_captions, f"Case {case_index}: キャプション '{caption}' が見つかりません"
            assert matching_captions[0]['model_id'] == model_id, f"Case {case_index}: キャプション '{caption}' のmodel_idが一致しません"

    if 'score' in expected:
        matching_scores = [s for s in retrieved['scores'] if s['score'] == expected['score']]
        assert matching_scores, f"Case {case_index}: スコア {expected['score']} が見つかりません"
        assert matching_scores[0]['model_id'] == model_id, f"Case {case_index}: スコア {expected['score']} のmodel_idが一致しません"

def test_save_annotations(image_database_manager, sample_image_info):
    """アノテーションの保存、取得、更新の確認、欠損値のテストを含む"""
    manager = image_database_manager
    image_id = manager.repository.add_original_image(sample_image_info)

    test_cases = [
        {
            'tags': ['spiked collar', 'tag1', 'tag2'],
            'captions': ['caption1', 'caption2'],
            'score': 0.95,
            'model_id': 1
        },
        {
            'tags': ['tag4', 'tag5'],
            'captions': ['caption3'],
            'model_id': 2
        },
        {
            'captions': ['caption4'],
            'score': 0.85,
            'model_id': 3
        },
        {
            'tags': ['tag6'],
            'score': 0.75,
            # 'model_id' がない場合
        },
        {
            'tags': ['spiked collar'], #tags_v3に存在するidを登録
        }
    ]

    for index, case in enumerate(test_cases, start=1):
        manager.repository.save_annotations(image_id, case)

        retrieved = manager.repository.get_image_annotations(image_id)

        current_model_id = case.get('model_id')

        assert_annotations(retrieved, case, current_model_id, index, manager.repository)

    # タグの再登録のテスト
    time.sleep(1)  # updated_at の変更を確実に検出するため
    reregister_case = {
        'tags': ['spiked collar', 'tag1'],
        'model_id': 4
    }
    manager.repository.save_annotations(image_id, reregister_case)
    retrieved = manager.repository.get_image_annotations(image_id)

    # 再登録されたタグの検証
    for tag in reregister_case['tags']:
        matching_tags = [t for t in retrieved['tags'] if t['tag'] == tag]
        assert len(matching_tags) > 1, f"再登録: タグ '{tag}' の追加が行われませんでした"

        # 新しく追加されたタグの検証
        new_matching_tag = next((t for t in matching_tags if t['model_id'] == 4), None)
        assert new_matching_tag is not None, f"再登録: タグ '{tag}' に新しい model_id が見つかりません"
        assert (datetime.now(timezone.utc) - datetime.fromisoformat(new_matching_tag['updated_at']).replace(tzinfo=timezone.utc)) < timedelta(seconds=100), \
            f"再登録: タグ '{tag}' の updated_at が更新されていません"

    # 他のタグが影響を受けていないことを確認
    other_tags = [t for t in retrieved['tags'] if t['tag'] not in reregister_case['tags']]
    for tag in other_tags:
        assert tag['model_id'] != 4, f"再登録: 他のタグ '{tag['tag']}' のmodel_idが誤って更新されています"

def test_find_tag_id(image_database_manager, sample_image_info):
    """
    アタッチしたsrc.module.genai-tag-db-toolsのタグデータベースから登録されたタグIDを取得する
    """
    manager = image_database_manager
    image_id = manager.repository.add_original_image(sample_image_info)
    manager.repository.save_annotations(image_id, {'tags': ['spiked collar'], 'model_id': None})

    tag_id = manager.repository.find_tag_id('spiked collar')
    assert tag_id == 1

def test_update_image_metadata(image_database_manager, sample_image_info):
    """画像メタデータの更新の確認"""
    manager = image_database_manager
    image_id = manager.repository.add_original_image(sample_image_info)

    updated_info = {'width': 1024, 'height': 768}
    manager.repository.update_image_metadata(image_id, updated_info)

    metadata = manager.repository.get_image_metadata(image_id)
    assert metadata['width'] == 1024
    assert metadata['height'] == 768
    assert metadata['updated_at'] is not None

def test_delete_image(image_database_manager, sample_image_info):
    """画像の削除と関連データの確認"""
    manager = image_database_manager
    image_id = manager.repository.add_original_image(sample_image_info)
    manager.repository.save_annotations(image_id, {
        'tags': ['test_tag1','test_tag2','test_tag3'],
        'captions': ['test_caption1','test_caption2','test_caption3'],
        'score': 0.95,
        'model_id': 1
    })

    # 削除前にアノテーションが存在することを確認
    annotations_before = manager.get_image_annotations(image_id)
    assert len(annotations_before['tags']) == 3
    assert len(annotations_before['captions']) == 3
    assert len(annotations_before['scores']) == 1

    manager.repository.delete_image(image_id)

    # 画像が削除されたことを確認
    metadata = manager.get_image_metadata(image_id)
    assert metadata is None

    # 削除後はアノテーションが空になることを確認
    annotations_after = manager.get_image_annotations(image_id)
    assert len(annotations_after['tags']) == 0
    assert len(annotations_after['captions']) == 0
    assert len(annotations_after['scores']) == 0

def test_get_total_image_count(image_database_manager, sample_image_info):
    """総画像数の取得の確認"""
    manager = image_database_manager
    initial_count = manager.repository.get_total_image_count()

    manager.repository.add_original_image(sample_image_info)
    new_count = manager.repository.get_total_image_count()
    assert new_count == initial_count + 1

def test_get_models(image_database_manager):
    """モデル情報の取得の確認"""
    manager = image_database_manager

    vision_models, score_models, upscaler_models = manager.get_models()
    assert isinstance(vision_models, dict)
    assert isinstance(score_models, dict)
    assert isinstance(upscaler_models, dict)
    assert len(vision_models) > 0

from datetime import datetime

@pytest.fixture
def setup_test_data(image_database_manager, sample_image_info, tmp_path):
    manager = image_database_manager

    # テスト用の画像データを作成
    image_data = [
        {"tags": ["cat", "cute"], "caption": "A cute cat playing"},
        {"tags": ["dog", "playful"], "caption": "A playful dog in the park"},
        {"tags": ["cat", "sleeping"], "caption": "A cat sleeping on a couch"},
        {"tags": ["bird", "flying"], "caption": "A bird flying in the sky"},
        {"tags": ["catfish", "swimming"], "caption": "A catfish swimming in a pond"}
    ]

    image_ids = []
    for idx, data in enumerate(image_data):
        # 直接SQLでオリジナル画像を追加（phashチェックを避けるため）
        query = """
        INSERT INTO images (uuid, stored_image_path, width, height, format, mode, has_alpha, filename,
                            extension, color_space, icc_profile, phash, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        created_at = datetime.now().isoformat()
        params = (
            str(uuid.uuid4()),  # uuid
            f"image_path_{idx}.jpg",  # stored_image_path
            256,  # width
            256,  # height
            "WEBP",  # format
            "RGB",  # mode
            False,  # has_alpha
            f'image_{idx}.jpg',  # filename
            'webp',  # extension
            'sRGB',  # color_space
            None,  # icc_profile
            f'unique_phash_{idx}',  # phash
            created_at,  # created_at
            created_at   # updated_at
        )
        cursor = manager.db_manager.execute(query, params)
        image_id = cursor.lastrowid
        image_ids.append(image_id)
        # 処理済み画像を登録
        processed_info = {
            'width': 256,
            'height': 256,
            'format': 'WEBP',
            'mode': 'RGB',
            'has_alpha': False,
            'filename': f'processed_{idx}.webp',
            'color_space': 'sRGB',
            'icc_profile': None
        }
        processed_path = tmp_path / f"processed_{idx}.webp"
        processed_path.touch()
        manager.register_processed_image(image_id, processed_path, processed_info)

        # アノテーションを保存
        manager.repository.save_annotations(image_id, {
            'tags': data['tags'],
            'captions': [data['caption']],
            'model_id': None
        })

    return manager, image_ids

test_cases = [
    # テストケース1: 完全一致タグ検索
    {
        "description": "完全一致タグ検索",
        "tags": ['"cat"'],
        "caption": None,
        "expected_count": 2,
        "expected_ids": lambda ids: {ids[0], ids[2]}
    },
    # テストケース1.1: 部分一致タグ検索
    {
        "description": "部分一致タグ検索",
        "tags": ['cat'],
        "caption": None,
        "expected_count": 3,
        "expected_ids": lambda ids: {ids[0], ids[2], ids[4]}
    },
    # テストケース2: ワイルドカードタグ検索
    {
        "description": "ワイルドカードタグ検索",
        "tags": ['cat*'],
        "caption": None,
        "expected_count": 3,
        "expected_ids": lambda ids: {ids[0], ids[2], ids[4]}
    },
    # テストケース3: AND検索
    {
        "description": "AND検索",
        "tags": ['cat', 'cute'],
        "caption": None,
        "use_and": True,
        "expected_count": 1,
        "expected_ids": lambda ids: {ids[0]}
    },
    # テストケース4: OR検索
    {
        "description": "OR検索",
        "tags": ['dog', 'bird'],
        "caption": None,
        "use_and": False,
        "expected_count": 2,
        "expected_ids": lambda ids: {ids[1], ids[3]}
    },
    # テストケース5: 部分一致キャプション検索
    {
        "description": "部分一致キャプション検索",
        "tags": None,
        "caption": 'sleeping',
        "expected_count": 1,
        "expected_ids": lambda ids: {ids[2]}
    },
    # テストケース6: ワイルドカードキャプション検索
    {
        "description": "ワイルドカードキャプション検索",
        "tags": None,
        "caption": '* in *',
        "expected_count": 3,
        "expected_ids": lambda ids: {ids[1], ids[3], ids[4]}
    },
    # テストケース7: タグとキャプションの組み合わせ検索
    {
        "description": "タグとキャプションの組み合わせ検索",
        "tags": ['cat*'],
        "caption": '*ing*',
        "expected_count": 3,
        "expected_ids": lambda ids: {ids[0], ids[2], ids[4]}
    },
    # テストケース8: 存在しないタグでの検索
    {
        "description": "存在しないタグでの検索",
        "tags": ['nonexistent'],
        "caption": None,
        "expected_count": 0,
        "expected_ids": lambda ids: set()
    },
    # テストケース9: 空のタグリストでの検索
    {
        "description": "空のタグリストでの検索",
        "tags": [],
        "caption": None,
        "expected_count": 0,
        "expected_ids": lambda ids: None
    },
    # テストケース10: 解像度フィルタ
    {
        "description": "解像度フィルタ",
        "tags": ['cat'],
        "caption": None,
        "resolution": 256,
        "expected_count": 3,
        "expected_ids": lambda ids: {ids[0], ids[2], ids[4]}
    },
    # エッジケース1: タグが存在しない
    {
        "description": "エッジケース - 存在しないタグ",
        "tags": ['nonexistent'],
        "caption": None,
        "expected_count": 0,
        "expected_ids": lambda ids: set()
    },
    # エッジケース2: タグと存在しないタグのAND検索
    {
        "description": "エッジケース - タグと存在しないタグのAND検索",
        "tags": ['cat', 'nonexistent'],
        "caption": None,
        "use_and": True,
        "expected_count": 0,
        "expected_ids": lambda ids: set()
    },
    # エッジケース3: 存在しないキャプション
    {
        "description": "エッジケース - 存在しないキャプション",
        "tags": None,
        "caption": 'nonexistent',
        "expected_count": 0,
        "expected_ids": lambda ids: set()
    },
    # エッジケース4: ワイルドカードタグ検索で全ての画像を取得
    {
        "description": "エッジケース - ワイルドカードタグ検索で全ての画像を取得",
        "tags": ['*'],
        "caption": None,
        "expected_count": 5,
        "expected_ids": lambda ids: set(ids)
    },
    # エッジケース5: ワイルドカードキャプション検索で全ての画像を取得
    {
        "description": "エッジケース - ワイルドカードキャプション検索で全ての画像を取得",
        "tags": None,
        "caption": '*',
        "expected_count": 5,
        "expected_ids": lambda ids: set(ids)
    },
]

@pytest.mark.parametrize("case", test_cases)
def test_get_images_by_filter_cases(setup_test_data, case):
    """フィルタリングのテストケース"""
    manager, image_ids = setup_test_data
    description = case.get("description")
    tags = case.get("tags")
    caption = case.get("caption")
    resolution = case.get("resolution", 0)
    use_and = case.get("use_and", True)
    expected_count = case.get("expected_count")
    expected_ids = case.get("expected_ids")(image_ids)

    filtered_images, count = manager.get_images_by_filter(
        tags=tags, caption=caption, resolution=resolution, use_and=use_and
    )

    assert count == expected_count, f"{description} - 期待される画像数と一致しません"
    # None が返ってくる場合に備える
    if filtered_images is None:
        assert expected_ids is None, f"{description} - 期待される画像IDと一致しません"
    else:
        actual_ids = set(img['image_id'] for img in filtered_images)
        assert actual_ids == expected_ids, f"{description} - 期待される画像IDと一致しません"

def test_get_images_by_filter(image_database_manager, sample_image_info, tmp_path):
    """フィルタによる画像検索の確認"""
    manager = image_database_manager

    # オリジナル画像を追加
    image_id = manager.repository.add_original_image(sample_image_info)

    # 処理済み画像を登録
    processed_info = {
        'width': 256,
        'height': 256,
        'format': 'WEBP',
        'mode': 'RGB',
        'has_alpha': False,
        'filename': 'processed.webp',
        'color_space': 'sRGB',
        'icc_profile': None
    }
    processed_path = tmp_path / "processed.webp"
    processed_path.touch()
    manager.register_processed_image(image_id, processed_path, processed_info)

    # アノテーションを保存（タグの updated_at が更新される）
    manager.repository.save_annotations(image_id, {'tags': ['filter_tag'], 'model_id': None})

    # タグの updated_at を確認する
    rows = manager.db_manager.fetch_all(
        "SELECT created_at, updated_at FROM tags WHERE image_id = ?", [image_id]
    )
    for row in rows:
        print(f"Tag created_at: {row['created_at']}, updated_at: {row['updated_at']}")

    # 現在の日時をUTCで取得
    current_datetime = datetime.now(timezone.utc)

    # 日付範囲を設定
    start_date = (current_datetime - timedelta(seconds=10)).strftime('%Y-%m-%d %H:%M:%S')  # 10秒前
    end_date = (current_datetime + timedelta(seconds=10)).strftime('%Y-%m-%d %H:%M:%S')    # 10秒後

    filtered_images, count = manager.get_images_by_filter(
        tags=['filter_tag'],
        start_date=start_date,
        end_date=end_date
    )

    assert count == 1, f"Expected 1 image, but got {count}"
    assert filtered_images[0]['image_id'] == image_id

    # 時間範囲外の画像を検索（マッチしないはず）
    past_start_date = (current_datetime - timedelta(days=1)).strftime('%Y-%m-%d %H:%M:%S')  # 1日前
    past_end_date = (current_datetime - timedelta(hours=23)).strftime('%Y-%m-%d %H:%M:%S')   # 1日前+1時間

    filtered_images, count = manager.get_images_by_filter(
        tags=['filter_tag'],
        start_date=past_start_date,
        end_date=past_end_date
    )

    assert count == 0, f"Expected 0 images, but got {count}"
    assert len(filtered_images) == 0

def test_create_tables(image_database_manager):
    """テーブル作成のテストとカラムの存在確認"""
    manager = image_database_manager
    manager.db_manager.create_tables()

    # テーブルとそのカラムの定義
    table_definitions = {
        'images': [
            'id', 'uuid', 'phash', 'stored_image_path', 'width', 'height', 'format',
            'mode', 'has_alpha', 'filename', 'extension', 'color_space',
            'icc_profile', 'created_at', 'updated_at'
        ],
        'processed_images': [
            'id', 'image_id', 'stored_image_path', 'width', 'height', 'mode',
            'has_alpha', 'filename', 'color_space', 'icc_profile',
            'created_at', 'updated_at'
        ],
        'models': [
            'id', 'name', 'type', 'provider', 'created_at', 'updated_at'
        ],
        'tags': [
            'id', 'tag_id', 'image_id', 'model_id', 'tag', 'existing',
            'created_at', 'updated_at'
        ],
        'captions': [
            'id', 'image_id', 'model_id', 'caption', 'existing',
            'created_at', 'updated_at'
        ],
        'scores': [
            'id', 'image_id', 'model_id', 'score',
            'created_at', 'updated_at'
        ]
    }

    for table, expected_columns in table_definitions.items():
        # テーブルの存在を確認
        query = f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table}';"
        result = manager.db_manager.fetch_one(query)
        assert result is not None, f"テーブル '{table}' が存在しません。"

        # テーブルのカラムを取得
        query = f"PRAGMA table_info({table});"
        columns_info = manager.db_manager.fetch_all(query)
        existing_columns = {col['name'] for col in columns_info}

        # 期待されるカラムがすべて存在するか確認
        for column in expected_columns:
            assert column in existing_columns, f"テーブル '{table}' にカラム '{column}' が存在しません。"

```

### tests\integration\test_ImageEditWidget.py

```
import pytest
from pytestqt.qtbot import QtBot
from PySide6.QtWidgets import QApplication
from PySide6.QtCore import Qt
from pathlib import Path

from src.ImageEditWidget import ImageEditWidget

@pytest.fixture
def widget(qtbot, mock_config_manager, mock_file_system_manager, mock_image_database_manager, mock_main_window):
    widget = ImageEditWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager, mock_main_window)
    qtbot.addWidget(widget)
    return widget

def test_initialization(app, mock_config_manager, mock_file_system_manager,
                         mock_image_database_manager, mock_main_window):
    widget = ImageEditWidget()
    widget.initialize(mock_config_manager, mock_file_system_manager, mock_image_database_manager, mock_main_window)

    assert widget.cm == mock_config_manager
    assert widget.idm == mock_image_database_manager
    assert widget.fsm == mock_file_system_manager
    assert widget.main_window == mock_main_window
    assert widget.target_resolution == 512
    assert widget.preferred_resolutions == [512, 768, 1024]
    assert widget.comboBoxUpscaler.count() == 4
    assert [widget.comboBoxUpscaler.itemText(i) for i in range(4)] == ['None', 'RealESRGAN_x4plus', 'Lanczos', 'Bicubic']

def test_load_images(widget, mocker, sample_image_path_list):
    mock_load_image = mocker.patch.object(widget.ImagePreview, 'load_image')
    mock_pixmap = mocker.patch('src.ImageEditWidget.QPixmap')
    mock_stat = mocker.patch('pathlib.Path.stat')

    mock_pixmap.return_value = mocker.Mock()
    mock_stat.return_value.st_size = 1024

    widget.load_images(sample_image_path_list)

    assert widget.directory_images == sample_image_path_list
    assert widget.tableWidgetImageList.rowCount() == len(sample_image_path_list)
    mock_load_image.assert_called_with(sample_image_path_list[0])

def test_process_all_images(widget, mocker):
    test_image_paths = [Path('test_image1.png'), Path('test_image2.png')]
    widget.directory_images = test_image_paths
    widget.upscaler = 'Lanczos'
    widget.target_resolution = 512

    mock_get_existing_annotations = mocker.patch('src.ImageEditWidget.ImageAnalyzer.get_existing_annotations', return_value={'tags': [], 'captions': []})
    widget.ipm = mocker.Mock()
    mock_process_image = mocker.patch.object(widget.ipm, 'process_image', return_value='processed_image_data')

    # idm のモックを明示的に設定
    widget.idm = mocker.Mock()
    widget.idm.get_image_id_by_name.return_value = None  # 画像IDが存在しないと仮定
    widget.idm.register_original_image.return_value = (1, {'has_alpha': False, 'mode': 'RGB'})

    progress_callback = mocker.Mock()
    status_callback = mocker.Mock()
    is_canceled = mocker.Mock(return_value=False)

    widget.process_all_images(progress_callback=progress_callback, status_callback=status_callback, is_canceled=is_canceled)

    assert widget.idm.register_original_image.call_count == len(test_image_paths)

def test_on_pushButtonStartProcess_clicked(widget, mocker):
    mock_initialize_processing = mocker.patch.object(widget, 'initialize_processing')
    mock_process_all_images = mocker.patch.object(widget, 'process_all_images')
    mock_some_long_process = mocker.patch.object(widget.main_window, 'some_long_process', side_effect=lambda func: func())

    widget.on_pushButtonStartProcess_clicked()

    mock_initialize_processing.assert_called_once()
    mock_process_all_images.assert_called_once()
    mock_some_long_process.assert_called_once()

def test_on_pushButtonStartProcess_clicked_error(widget, mocker):
    mocker.patch.object(widget, 'initialize_processing', side_effect=Exception("Test error"))
    mock_error_dialog = mocker.patch('PySide6.QtWidgets.QMessageBox.critical')

    widget.on_pushButtonStartProcess_clicked()

    mock_error_dialog.assert_called_once()
```

### tests\integration\test_ImageTaggerWidget.py

```
import pytest
from pathlib import Path
from ImageTaggerWidget import ImageTaggerWidget

def test_initialization(app, mock_config_manager, mock_image_database_manager, mocker):
    # ウィジェットのインスタンスを作成
    widget = ImageTaggerWidget()
    
    # 外部依存関係をモック化
    widget.DirectoryPickerSave = mocker.Mock()
    widget.ThumbnailSelector = mocker.Mock()
    widget.dbSearchWidget = mocker.Mock()
    
    # ウィジェットを初期化
    widget.initialize(mock_config_manager, mock_image_database_manager)
    
    # 属性が正しく設定されていることを確認
    assert widget.cm == mock_config_manager
    assert widget.idm == mock_image_database_manager

    # vision_providersが正しく設定されていることを確認
    expected_vision_providers = list(set(model['provider'] for model in mock_config_manager.vision_models.values()))
    assert widget.vision_providers == expected_vision_providers

    # comboBoxAPIに正しいアイテムが追加されていることを確認
    actual_api_items = [widget.comboBoxAPI.itemText(i) for i in range(widget.comboBoxAPI.count())]
    assert actual_api_items == expected_vision_providers

    # comboBoxTagFormatに正しいアイテムが追加されていることを確認
    expected_formats = ["danbooru", "e621", "derpibooru"]
    actual_formats = [widget.comboBoxTagFormat.itemText(i) for i in range(widget.comboBoxTagFormat.count())]
    assert actual_formats == expected_formats

    # プロンプトが正しく設定されていることを確認
    assert widget.textEditMainPrompt.toPlainText() == mock_config_manager.config['prompts']['main']
    assert widget.textEditAddPrompt.toPlainText() == mock_config_manager.config['prompts']['additional']

def test_load_images(app, mock_config_manager, mock_image_database_manager, mocker, tmp_path):
    # サンプルのwebp画像を作成
    image1 = tmp_path / 'image1.webp'
    image1.touch()
    image2 = tmp_path / 'image2.webp'
    image2.touch()
    image_files = [image1, image2]

    # ウィジェットのインスタンスを作成
    widget = ImageTaggerWidget()
    
    # 外部依存関係をモック化
    widget.DirectoryPickerSave = mocker.Mock()
    widget.ImagePreview = mocker.Mock()
    widget.ThumbnailSelector = mocker.Mock()
    widget.ThumbnailSelector.load_images = mocker.Mock()
    widget.ThumbnailSelector.select_first_image = mocker.Mock()
    widget.dbSearchWidget = mocker.Mock()
    
    # ウィジェットを初期化
    widget.initialize(mock_config_manager, mock_image_database_manager)
    
    # 画像をロード
    widget.load_images(image_files)
    
    # all_webp_filesが正しく設定されていることを確認
    assert widget.all_webp_files == image_files

    # ThumbnailSelectorのload_imagesが正しく呼び出されていることを確認
    widget.ThumbnailSelector.load_images.assert_called_with(image_files)

    # サムネイルの最初の画像が選択されていることを確認
    widget.ThumbnailSelector.select_first_image.assert_called_once()

def test_on_pushButtonGenerate_clicked(app, mock_config_manager, mock_image_database_manager, mocker, tmp_path):
    # サンプルのwebp画像を作成
    image = tmp_path / 'image.webp'
    image.touch()
    image_files = [image]

    # ウィジェットのインスタンスを作成
    widget = ImageTaggerWidget()
    
    # 外部依存関係をモック化
    widget.DirectoryPickerSave = mocker.Mock()
    widget.ImagePreview = mocker.Mock()
    widget.ThumbnailSelector = mocker.Mock()
    widget.ThumbnailSelector.load_images = mocker.Mock()
    widget.ThumbnailSelector.select_first_image = mocker.Mock()
    widget.dbSearchWidget = mocker.Mock()
    
    # ImageAnalyzerとAPIClientFactoryをモック化
    mock_image_analyzer = mocker.patch('ImageTaggerWidget.ImageAnalyzer')
    mock_api_client_factory = mocker.patch('ImageTaggerWidget.APIClientFactory')
    mock_image_analyzer_instance = mock_image_analyzer.return_value
    mock_image_analyzer_instance.analyze_image.return_value = {
        'image_path': str(image),
        'tags': [{'tag': 'sample_tag'}],
        'captions': [{'caption': 'sample_caption'}],
        'score': {'score': 0.85}
    }

    # ウィジェットを初期化
    widget.initialize(mock_config_manager, mock_image_database_manager)
    
    # 選択された画像を設定
    widget.selected_webp = image_files

    # ボタンクリックのメソッドを呼び出し
    widget.on_pushButtonGenerate_clicked()
    
    # タグとキャプションが正しく設定されていることを確認
    assert widget.all_tags == ['sample_tag']
    assert widget.all_captions == ['sample_caption']

    # テキストエディットに正しく表示されていることを確認
    assert widget.textEditTags.toPlainText() == 'sample_tag'
    assert widget.textEditCaption.toPlainText() == 'sample_caption'

def test_on_pushButtonSave_clicked(app, mock_config_manager, mock_image_database_manager, mocker, tmp_path):
    # サンプルのwebp画像を作成
    image = tmp_path / 'image.webp'
    image.touch()
    image_files = [image]

    # ウィジェットのインスタンスを作成
    widget = ImageTaggerWidget()
    
    # 外部依存関係をモック化
    widget.DirectoryPickerSave = mocker.Mock()
    widget.DirectoryPickerSave.get_selected_path.return_value = str(tmp_path)
    widget.ImagePreview = mocker.Mock()
    widget.ThumbnailSelector = mocker.Mock()
    widget.ThumbnailSelector.load_images = mocker.Mock()
    widget.ThumbnailSelector.select_first_image = mocker.Mock()
    widget.dbSearchWidget = mocker.Mock()
    
    # FileSystemManagerのメソッドをモック化
    mock_fsm = mocker.patch('ImageTaggerWidget.FileSystemManager')
    mock_fsm.export_dataset_to_txt = mocker.Mock()
    mock_fsm.export_dataset_to_json = mocker.Mock()

    # ウィジェットを初期化
    widget.initialize(mock_config_manager, mock_image_database_manager)
    
    # 選択された画像と生成されたタグ・キャプションを設定
    widget.selected_webp = image_files
    widget.all_tags = ['sample_tag']
    widget.all_captions = ['sample_caption']
    widget.all_results = [{
        'image_path': str(image),
        'tags': [{'tag': 'sample_tag'}],
        'captions': [{'caption': 'sample_caption'}],
        'score': {'score': 0.85}
    }]

    # 保存オプションを設定
    widget.checkBoxText.setChecked(True)
    widget.checkBoxJson.setChecked(True)
    widget.checkBoxDB.setChecked(True)
    
    # ボタンクリックのメソッドを呼び出し
    widget.on_pushButtonSave_clicked()
    
    # FileSystemManagerのメソッドが正しく呼び出されたことを確認
    mock_fsm.export_dataset_to_txt.assert_called()
    mock_fsm.export_dataset_to_json.assert_called()

    # データベースに保存するメソッドが呼び出されたことを確認
    mock_image_database_manager.save_annotations.assert_called()
    mock_image_database_manager.save_score.assert_called()

def test_on_comboBoxAPI_currentIndexChanged(app, mock_config_manager, mock_image_database_manager, mocker):
    widget = ImageTaggerWidget()
    
    # 外部依存関係をモック化
    widget.DirectoryPickerSave = mocker.Mock()
    widget.ThumbnailSelector = mocker.Mock()
    widget.dbSearchWidget = mocker.Mock()
    
    # ウィジェットを初期化
    widget.initialize(mock_config_manager, mock_image_database_manager)
    
    # comboBoxAPIにアイテムを追加
    widget.comboBoxAPI.addItems(['Provider A', 'Provider B'])
    
    # モデルリストを設定
    mock_config_manager.vision_models = {
        'model1': {'name': 'Model One', 'provider': 'Provider A'},
        'model2': {'name': 'Model Two', 'provider': 'Provider B'},
        'model3': {'name': 'Model Three', 'provider': 'Provider A'}
    }
    
    # メソッドを呼び出し
    widget.on_comboBoxAPI_currentIndexChanged(0)
    
    # comboBoxModelに正しいモデルが追加されていることを確認
    expected_models = ['Model One', 'Model Three']
    actual_models = [widget.comboBoxModel.itemText(i) for i in range(widget.comboBoxModel.count())]
    assert actual_models == expected_models

```

### tests\unit\test_autcrop.py

```
import pytest
from PIL import Image, ImageDraw, ImageOps
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

from ImageEditor import AutoCrop

@pytest.fixture(scope="module")
def crop_test_images():
    """
    テスト用の画像を作成するフィクスチャ。
    各画像は仕様に基づいた枠パターンを持つ。
    """
    images = {}
    size = (256, 256)  # 基本のサイズ

    # 1. 枠のない画像
    no_borders_img = Image.new("RGB", size, (255, 0, 0))  # 赤色の単色画像
    images['no_borders'] = no_borders_img

    # 2. レターボックス画像（上下に黒い帯）
    letterbox_img = no_borders_img.copy()
    draw = ImageDraw.Draw(letterbox_img)
    border_thickness = 20
    draw.rectangle([0, 0, size[0], border_thickness], fill=(0, 0, 0))  # 上部
    draw.rectangle([0, size[1] - border_thickness, size[0], size[1]], fill=(0, 0, 0))  # 下部
    images['letterbox'] = letterbox_img

    # 3. ピラーボックス画像（左右に黒い帯）
    pillarbox_img = no_borders_img.copy()
    draw = ImageDraw.Draw(pillarbox_img)
    draw.rectangle([0, 0, border_thickness, size[1]], fill=(0, 0, 0))  # 左側
    draw.rectangle([size[0] - border_thickness, 0, size[0], size[1]], fill=(0, 0, 0))  # 右側
    images['pillarbox'] = pillarbox_img

    # 4. 両方の枠（四方に黒い帯）
    four_sides_img = no_borders_img.copy()
    draw = ImageDraw.Draw(four_sides_img)
    draw.rectangle([0, 0, size[0], border_thickness], fill=(0, 0, 0))  # 上部
    draw.rectangle([0, size[1] - border_thickness, size[0], size[1]], fill=(0, 0, 0))  # 下部
    draw.rectangle([0, 0, border_thickness, size[1]], fill=(0, 0, 0))  # 左側
    draw.rectangle([size[0] - border_thickness, 0, size[0], size[1]], fill=(0, 0, 0))  # 右側
    images['four_sides'] = four_sides_img

    # 5. グラデーションの枠付き画像
    gradient_img = Image.new("RGB", size, (255, 255, 255))
    draw = ImageDraw.Draw(gradient_img)
    for i in range(border_thickness, size[1] - border_thickness):
        gradient_color = int(255 * (i - border_thickness) / (size[1] - 2 * border_thickness))
        draw.line([(border_thickness, i), (size[0] - border_thickness, i)], fill=(gradient_color, gradient_color, gradient_color))
    draw.rectangle([0, 0, size[0], border_thickness], fill=(0, 0, 0))  # 上部
    draw.rectangle([0, size[1] - border_thickness, size[0], size[1]], fill=(0, 0, 0))  # 下部
    draw.rectangle([0, 0, border_thickness, size[1]], fill=(0, 0, 0))  # 左側
    draw.rectangle([size[0] - border_thickness, 0, size[0], size[1]], fill=(0, 0, 0))  # 右側
    images['gradient_with_borders'] = gradient_img

    # 6. グラデーションのみの画像
    pure_gradient_img = Image.new("RGB", size, (0, 0, 0))
    draw = ImageDraw.Draw(pure_gradient_img)
    for i in range(size[1]):
        gradient_color = int(255 * i / size[1])
        draw.line([(0, i), (size[0], i)], fill=(gradient_color, gradient_color, gradient_color))
    images['gradient_only'] = pure_gradient_img

    # 7. アルファチャンネル付きの画像（透明な枠付き）
    rgba_img = Image.new("RGBA", size, (255, 0, 0, 255))  # 赤色の画像
    draw = ImageDraw.Draw(rgba_img)
    draw.rectangle([0, 0, size[0], border_thickness], fill=(0, 0, 0, 0))  # 上部の透明な枠
    draw.rectangle([0, size[1] - border_thickness, size[0], size[1]], fill=(0, 0, 0, 0))  # 下部の透明な枠
    images['alpha_with_borders'] = rgba_img

    # 8. グレースケール画像
    grayscale_img = Image.new("L", size, 255)  # 白色のグレースケール画像
    draw = ImageDraw.Draw(grayscale_img)
    draw.rectangle([0, 0, size[0], border_thickness], fill=0)  # 上部の黒い枠
    draw.rectangle([0, size[1] - border_thickness, size[0], size[1]], fill=0)  # 下部の黒い枠
    images['grayscale_with_borders'] = grayscale_img

    # 9. 非標準のアスペクト比画像
    non_standard_aspect_img = Image.new("RGB", (128, 256), (255, 255, 0))  # 黄色の画像
    draw = ImageDraw.Draw(non_standard_aspect_img)
    draw.rectangle([0, 0, 128, border_thickness], fill=(0, 0, 0))  # 上部
    draw.rectangle([0, 256 - border_thickness, 128, 256], fill=(0, 0, 0))  # 下部
    images['non_standard_aspect'] = non_standard_aspect_img

    # 10. 小さい画像
    small_img = Image.new("RGB", (32, 32), (255, 0, 0))  # 小さい赤色の画像
    images['small'] = small_img

    ##11. testimg内部の画像にレターボックスを追加
    IMAGE_DIR = Path(r"testimg\1_img")
    for img_path in IMAGE_DIR.glob("*.*"):
        if img_path.suffix.lower() not in [".jpg", ".jpeg", ".png", ".webp"]:
            continue
        img = Image.open(img_path).convert("RGB")
        # 画像の高さに基づいて20%のレターボックスを計算
        width, height = img.size
        border_height = int(height * 0.2)  # 上下に20%ずつ
        # 上下に黒い帯を追加（レターボックス）
        bordered_img = ImageOps.expand(img, (0, border_height), fill=(0, 0, 0))
        # 画像のファイル名をキーとして辞書に追加
        images[img_path.stem + "_letterbox"] = bordered_img

    # 12. testimg内部の画像
    # IMAGE_DIR01 = Path(r"H:\lora\素材リスト\Otogi2_cap\金時装束1\OTOGI -Hyakki Toubatsu Emaki- 2023-06-17 05-31-06")
    # for img_path in IMAGE_DIR01.glob("*.*"):
    #     if img_path.suffix.lower() not in [".jpg", ".jpeg", ".png", ".webp"]:
    #         continue
    #     img = Image.open(img_path).convert("RGB")
    #     images[img_path.stem ] = img

    return images

# def display_images(original_img, cropped_img, title="Original and Cropped Images"):
#     """
#     元の画像とクロップ後の画像を並べて表示します。

#     Args:
#         original_img (PIL.Image.Image): 元の画像。
#         cropped_img (PIL.Image.Image): クロップ後の画像。
#         title (str): グラフ全体のタイトル。
#     """
#     fig, axes = plt.subplots(1, 2, figsize=(10, 5))

#     # 元の画像を表示
#     axes[0].imshow(original_img)
#     axes[0].set_title("Original Image")
#     axes[0].axis("off")

#     # クロップ後の画像を表示
#     axes[1].imshow(cropped_img)
#     axes[1].set_title("Cropped Image")
#     axes[1].axis("off")

#     # 全体のタイトルを設定
#     plt.suptitle(title)
#     plt.show()

# def test_image_cropping(crop_test_images):
#     """
#     テスト用画像のすべてのパターンをイテレートし、クロップ前後の画像を表示して比較する。
#     """
#     for pattern, original_img in crop_test_images.items():
#         # クロップ処理を行う
#         cropped_img = AutoCrop.auto_crop_image(original_img)

#         # クロップ前後の画像を表示して比較
#         display_images(original_img, cropped_img, title=f"{pattern.capitalize()} Cropping Test")

# @pytest.fixture(scope="module")
# def autocrop_instance():
#     """
#     AutoCropクラスのインスタンスを返すフィクスチャ。
#     """
#     return AutoCrop()

# def test_detect_border_shape(crop_test_images):
#     """
#     _detect_border_shapeメソッドのテスト。枠が検出されるか確認する。
#     """
#     # レターボックスのある画像
#     letterbox_img = crop_test_images['letterbox']
#     letterbox_np = np.array(letterbox_img)
#     # 検出結果を取得
#     detected_borders = AutoCrop._detect_border_shape(letterbox_np)
#     # クラスメソッドから直接呼び出し
#     assert set(detected_borders) == {"TOP", "BOTTOM"}, "レターボックスが検出されませんでした。"

#     # 枠のない画像
#     no_borders_img = crop_test_images['no_borders']
#     no_borders_np = np.array(no_borders_img)
#     detected_borders = AutoCrop._detect_border_shape(no_borders_np)
#     # クラスメソッドから直接呼び出し
#     assert detected_borders == [], "枠がないのに検出されました。"

# def test_get_crop_area(crop_test_images):
#     """
#     _get_crop_areaメソッドのテスト。クロップ領域が正しく計算されるか確認する。
#     """
#     # インスタンスの生成
#     autocrop_instance = AutoCrop()

#     # レターボックスのある画像
#     letterbox_img = crop_test_images['letterbox']
#     letterbox_np = np.array(letterbox_img)

#     # インスタンスメソッドから呼び出し
#     crop_area = autocrop_instance._get_crop_area(letterbox_np)
#     assert crop_area is not None, "クロップ領域が取得できませんでした。"
#     x, y, w, h = crop_area
#     # 上下の枠をクロップするので、高さが変わっているはず
#     assert h < letterbox_np.shape[0], "高さが変更されていません。"

# def test_auto_crop_image(crop_test_images):
#     """
#     _auto_crop_imageメソッドのテスト。画像が正しくクロップされるか確認する。
#     """
#     # インスタンスメソッドなのでインスタンス生成が必要
#     autocrop_instance = AutoCrop()
    
#     # レターボックスのある画像
#     letterbox_img = crop_test_images['letterbox']
    
#     # 自動クロップを実行
#     cropped_img = autocrop_instance._auto_crop_image(letterbox_img)
    
#     # クロップ後のサイズが変わっているか確認
#     assert cropped_img.size[1] < letterbox_img.size[1], "画像の高さが変更されていません。"

# import cv2

# def debug_get_crop_area(np_image: np.ndarray):
#     """
#     各ステップでの画像を収集し、後でまとめて表示する。
#     :param np_image: OpenCV形式の画像
#     :return: クロップ領域と各ステップの画像のリスト
#     """
#     images = {}
#     try:
#         # ステップ 1: 元画像
#         images["Original Image"] = np_image

#         # ステップ 2: グレースケール変換
#         gray_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2GRAY)
#         images["Gray Image"] = gray_image

#         # ステップ 3: 補色背景の生成
#         complementary_color = [255 - np.mean(np_image[..., i]) for i in range(3)]
#         background = np.full(np_image.shape, complementary_color, dtype=np.uint8)
#         images["Complementary Background"] = background

#         # ステップ 4: 差分計算
#         diff = cv2.absdiff(np_image, background)
#         images["Difference Image"] = diff

#         # ステップ 5: 差分をグレースケール化
#         gray_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
#         images["Gray Difference"] = gray_diff

#         # ステップ 6: ブラー処理 (カーネルサイズを調整)
#         blurred_diff = cv2.GaussianBlur(gray_diff, (5, 5), 0)
#         images["Blurred Difference"] = blurred_diff

#         # ステップ 7: 適応的しきい値処理
#         thresh = cv2.adaptiveThreshold(
#             blurred_diff,  # グレースケール化された差分画像を使う
#             255,  # 最大値（白）
#             cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  # 適応的しきい値の種類（ガウス法）
#             cv2.THRESH_BINARY,  # 2値化（白か黒）
#             11,  # ピクセル近傍のサイズ (奇数で指定)
#             2   # 平均値または加重平均から減算する定数
#         )
#         images["Threshold Image"] = thresh  # 適応的しきい値画像を保存

#         # ステップ 8: エッジ検出
#         edges = cv2.Canny(thresh, threshold1=30, threshold2=100)
#         images["Edge Detection"] = edges

#         # ステップ 9: 輪郭検出
#         contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
#         contour_image = np_image.copy()
#         cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)
#         images["Detected Contours"] = contour_image

#         if contours:
#             # 輪郭が見つかった場合
#             x_min, y_min, x_max, y_max = np_image.shape[1], np_image.shape[0], 0, 0
#             for contour in contours:
#                 x, y, w, h = cv2.boundingRect(contour)
#                 x_min, y_min = min(x_min, x), min(y_min, y)
#                 x_max, y_max = max(x_max, x + w), max(y_max, y + h)

#             # マスクを作成し、内側領域のみを残す
#             mask = np.zeros(np_image.shape[:2], dtype=np.uint8)
#             for contour in contours:
#                 cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)

#             # 内側の領域を取り出す
#             masked_image = cv2.bitwise_and(np_image, np_image, mask=mask)
#             images["Masked Image"] = masked_image

#             # クロップ領域を計算
#             y_coords, x_coords = np.where(mask == 255)
#             if len(x_coords) > 0 and len(y_coords) > 0:
#                 x, y = np.min(x_coords), np.min(y_coords)
#                 w, h = np.max(x_coords) - x + 1, np.max(y_coords) - y + 1

#                 extra_crop_margin = 5
#                 # クロップ領域に余分なピクセルを削る
#                 x_min = max(0, x + extra_crop_margin)
#                 y_min = max(0, y + extra_crop_margin)
#                 x_max = min(np_image.shape[1], x + w - extra_crop_margin)
#                 y_max = min(np_image.shape[0], y + h - extra_crop_margin)

#                 # クロップ領域を可視化
#                 crop_visualization = np_image.copy()
#                 cv2.rectangle(crop_visualization, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
#                 images["Crop Area"] = crop_visualization

#                 # 領域でクロップ
#                 cropped_image = np_image[y_min:y_max, x_min:x_max]
#                 images["Cropped Image"] = cropped_image

#                 return (x_min, y_min, x_max - x_min, y_max - y_min), images
#             else:
#                 print("No valid crop region found.")
#         else:
#             print("No contours found")

#         # 輪郭が見つからない場合や適切な輪郭がない場合は元の画像を返す
#         images["Cropped Image"] = np_image
#         return None, images

#     except Exception as e:
#         print(f"Error during cropping: {e}")
#         return None, images

# # テスト関数
# def test_debug_get_crop_area(crop_test_images):
#     """
#     各画像に対してクロップ処理を実行し、結果を一つのウィンドウに表示する。
#     """
#     images_dict = crop_test_images
#     for image_name, image in images_dict.items():
#         np_image = np.array(image)
#         crop_area, images = debug_get_crop_area(np_image)

#         # 画像を一つのウィンドウに表示
#         num_steps = len(images)
#         cols = 5  # 列数
#         rows = (num_steps + cols - 1) // cols  # 行数計算
#         plt.figure(figsize=(15, 5 * rows))
#         for i, (title, img) in enumerate(images.items()):
#             plt.subplot(rows, cols, i + 1)
#             if len(img.shape) == 2:
#                 plt.imshow(img, cmap='gray')
#             else:
#                 img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#                 plt.imshow(img_rgb)
#             plt.title(title)
#             plt.axis('off')
#         plt.suptitle(f"Processing Steps for {image_name}", fontsize=16)
#         plt.tight_layout()
#         plt.show()

#         if crop_area:
#             print(f"{image_name}: Crop Area - {crop_area}")
#         else:
#             print(f"{image_name}: No crop area detected.")

# if __name__ == "__main__":
#     pytest.main(["-v", __file__])

```

### tests\unit\test_caption_tags.py

```
import pytest
from unittest.mock import MagicMock
from pathlib import Path
from caption_tags import ImageAnalyzer
from module.api_utils import APIClientFactory, APIError

@pytest.fixture
def mock_api_client():
    """
    モックされたAPIクライアントを提供するフィクスチャ。
    """
    mock_client = MagicMock()
    # generate_caption メソッドが呼ばれたときに、モックのレスポンスを返す
    mock_client.generate_caption.return_value = "tags: tag1, tag2, tag3\ncaption: A sample caption\nscore: 0.85"
    return mock_client

@pytest.fixture
def mock_api_client_factory(mock_api_client):
    """
    モックされたAPIClientFactoryを提供するフィクスチャ。
    """
    factory = MagicMock(spec=APIClientFactory)
    # get_api_client メソッドが呼ばれたときに、モックのAPIクライアントを返す
    factory.get_api_client.return_value = (mock_api_client, None)
    return factory

@pytest.fixture
def mock_models_config(mock_config_manager):
    """
    モックされたモデル設定を提供するフィクスチャ。
    """
    cm = mock_config_manager
    return cm.vision_models, cm.score_models

def test_analyze_image(sample_images, mock_api_client_factory, mock_models_config):
    """
    ImageAnalyzer.analyze_image の正常系のテスト。
    """
    image_path = sample_images['rgb']

    # ImageAnalyzer のインスタンスを作成し、初期化
    analyzer = ImageAnalyzer()
    analyzer.initialize(mock_api_client_factory, mock_models_config)

    # analyze_image メソッドを呼び出し
    result = analyzer.analyze_image(image_path, model_id=1)

    # 期待される結果 sample_images
    expected_tags = [{'tag': 'tag1', 'model_id': 1}, {'tag': 'tag2', 'model_id': 1}, {'tag': 'tag3', 'model_id': 1}]
    expected_captions = [{'caption': 'a sample caption', 'model_id': 1}]
    expected_score = {'score': 0.85, 'model_id': 1}

    # 結果の検証
    assert result['tags'] == expected_tags
    assert result['captions'] == expected_captions
    assert result['score'] == expected_score
    assert result['image_path'] == str(image_path)

    # モックされたAPIクライアントのメソッドが正しく呼び出されたか確認
    mock_api_client = mock_api_client_factory.get_api_client.return_value[0]
    mock_api_client.set_image_data.assert_called_with(image_path)
    mock_api_client.generate_caption.assert_called_with(image_path, 'gpt-4o')

def test_analyze_image_with_exception(sample_images, mock_api_client_factory, mock_models_config):
    """
    APIクライアントが例外を投げた場合の ImageAnalyzer.analyze_image のテスト。
    """
    image_path = sample_images['rgb']

    # generate_caption が APIError を投げるように設定
    mock_api_client = mock_api_client_factory.get_api_client.return_value[0]
    mock_api_client.generate_caption.side_effect = APIError("API error occurred")

    analyzer = ImageAnalyzer()
    analyzer.initialize(mock_api_client_factory, mock_models_config)

    result = analyzer.analyze_image(image_path, model_id=1)

    # エラーメッセージの検証
    assert 'error' in result
    assert result['error'] == 'API Error: API error occurred'
    assert result['image_path'] == str(image_path)

def test_get_existing_annotations(tmp_path):
    """
    ImageAnalyzer.get_existing_annotations のテスト。
    """
    # テスト用の画像ファイルを作成
    image_path = tmp_path / 'test_image.jpg'
    image_path.touch()  # 空のファイルを作成

    # タグとキャプションのファイルを作成
    tag_file = image_path.with_suffix('.txt')
    caption_file = image_path.with_suffix('.caption')

    with open(tag_file, 'w', encoding='utf-8') as f:
        f.write('tag1, tag2, tag3')

    with open(caption_file, 'w', encoding='utf-8') as f:
        f.write('A sample caption, another_caption')

    # アノテーションを取得
    annotations = ImageAnalyzer.get_existing_annotations(image_path)

    # 期待されるアノテーション
    expected_annotations = {
        'tags': [{'tag': 'tag1', 'model_id': None}, {'tag': ' tag2', 'model_id': None}, {'tag': ' tag3', 'model_id': None}],
        'captions': [{'caption': 'a sample caption', 'model_id': None}, {'caption': ' another caption', 'model_id': None}],
        'score': {'score': 0, 'model_id': None},
        'model_id': None,
        'image_path': str(image_path)
    }

    # アノテーションの検証
    assert annotations == expected_annotations
    # test_imageのtextファイルを削除
    tag_file.unlink()
    caption_file.unlink()

def test_get_existing_annotations_no_files(tmp_path):
    """
    タグとキャプションファイルが存在しない場合の ImageAnalyzer.get_existing_annotations のテスト。
    """
    image_path = tmp_path / 'test_image.jpg'
    image_path.touch()

    annotations = ImageAnalyzer.get_existing_annotations(image_path)

    # アノテーションが存在しないことを確認
    assert annotations is None

```

### tests\unit\test_Image_Editor.py

```
# TEST/test_Image_Editor.py

import pytest
from pathlib import Path
from PIL import Image, ImageDraw
from ImageEditor import ImageProcessingManager, ImageProcessor, AutoCrop, Upscaler
from unittest.mock import MagicMock

@pytest.mark.parametrize("image_type, has_alpha, mode", [
    ("rgb", False, 'RGB'),
    ("rgba", True, 'RGBA'),
    ("cmyk", False, 'CMYK'),
    ("p", False, 'P')
])
def test_normalize_color_profile(mock_file_system_manager, sample_images, preferred_resolutions, image_type, has_alpha, mode):
    processor = ImageProcessor(mock_file_system_manager, target_resolution=1024, preferred_resolutions=preferred_resolutions)
    image = Image.open(sample_images[image_type])
    normalized = processor.normalize_color_profile(image, has_alpha=has_alpha, mode=mode)
    assert normalized.mode == 'RGB' if mode != 'RGBA' else 'RGBA'

def test_resize_image_with_matching_resolution(mock_file_system_manager, sample_images, preferred_resolutions):
    processor = ImageProcessor(mock_file_system_manager, target_resolution=512, preferred_resolutions=preferred_resolutions)
    img = Image.open(sample_images["rgb512"])
    resized = processor.resize_image(img)
    assert resized.size == (512, 512)

def test_resize_image_without_matching_resolution(mock_file_system_manager, sample_images, preferred_resolutions):
    processor = ImageProcessor(mock_file_system_manager, target_resolution=512, preferred_resolutions=preferred_resolutions)
    img = Image.open(sample_images["rgb"])
    resized = processor.resize_image(img)
    # 目標解像度に基づきアスペクト比を維持してリサイズ
    expected_size = (512, 384)  # 800x600 のアスペクト比を維持しつつ、500に近いサイズに調整（32の倍数）
    assert resized.size == expected_size

def test_auto_crop_image_with_letterbox(sample_images, preferred_resolutions):
    # レターボックスがある画像を作成
    # TODO: このテストは通らない
    img = Image.new('RGB', (800, 600), color='black')
    draw = ImageDraw.Draw(img)  # ImageDraw を使用
    draw.rectangle([100, 100, 700, 500], fill='white')
    cropped = AutoCrop.auto_crop_image(img)
    assert cropped.size == (600, 400)

def test_auto_crop_image_without_letterbox(sample_images, preferred_resolutions):
    # レターボックスがない画像
    img = Image.new('RGB', (800, 600), color='white')
    cropped = AutoCrop.auto_crop_image(img)
    assert cropped.size == (800, 600)

def test_process_image_rgb_no_alpha(mock_file_system_manager, sample_images, preferred_resolutions):
    manager = ImageProcessingManager(
        file_system_manager=mock_file_system_manager,
        target_resolution=512,
        preferred_resolutions=preferred_resolutions
    )
    # モックファイルシステムに画像を配置
    original_path = sample_images["rgb"]
    resized_path = mock_file_system_manager.resized_images_dir / "rgb_resized.jpg"

    # モックの挙動を定義
    mock_file_system_manager.original_images_dir = Path(original_path).parent
    mock_file_system_manager.resized_images_dir = Path(resized_path).parent

    resized_image = manager.process_image(
        db_stored_original_path=original_path,
        original_has_alpha=False,
        original_mode='RGB',
        upscaler=None
    )

    assert resized_image is not None
    assert resized_image.size == (512, 384)

def test_process_image_rgba_with_alpha(mock_file_system_manager, sample_images, preferred_resolutions):
    manager = ImageProcessingManager(
        file_system_manager=mock_file_system_manager,
        target_resolution=512,
        preferred_resolutions=preferred_resolutions
    )
    original_path = sample_images["rgba"]

    resized_image = manager.process_image(
        db_stored_original_path=original_path,
        original_has_alpha=True,
        original_mode='RGBA',
        upscaler=None
    )

    assert resized_image is not None
    assert resized_image.mode == 'RGBA'
    # サイズはレターボックスの有無により異なる場合があります

def test_upscale_image_with_model(sample_images):
    #TODO: RealESRGAN_x4plus のみ対応から対応モデルを増やす
    img = Image.open(sample_images["rgb512"])
    upscaled = Upscaler.upscale_image(img, "RealESRGAN_x4plus")
    assert upscaled.size == (2048, 2048)

```

### tests\unit\test_image_editor_02.py

```
from src.ImageEditor import ImageProcessingManager, FileSystemManager


def test_image_processing_manager_init():
    fsm = FileSystemManager()
    target_resolution = 512
    preferred_resolutions = [(512, 512), (768, 512)]

    ipm = ImageProcessingManager(fsm, target_resolution, preferred_resolutions)
    assert ipm.target_resolution == target_resolution

```

