# AutoCrop 3手法比較テスト強化プラン

**プランニング日時:** 2025/07/13 07:05  
**プランナー:** Claude Code  
**対象:** scripts/test_autocrop_effectiveness.py への古い実装統合による3手法比較  

## 📋 Executive Summary

現在のAutoCrop効果確認スクリプトを拡張し、真に異なる3つの手法（現在最適化版、現在レガシー版、境界形状検出版）の包括的比較を実現する。

## 🎯 プロジェクト目標

### 主要目標
1. **3手法の明確な比較**: 補色差分ベース2種 + 境界形状検出ベース1種
2. **実画像での適応性評価**: レターボックスや境界のない画像での各手法特性の明確化
3. **視覚的比較の改善**: 手法の根本的違いが分かりやすい比較画像生成

### 成功基準
- [ ] LegacyAutoCropクラスが境界形状検出によるクロップを実行
- [ ] 3つの手法が同一画像で並列比較可能
- [ ] 実画像テストで各手法の特性が明確に現れる
- [ ] パフォーマンス差の定量的計測

## 🏗️ アーキテクチャ設計

### 新規追加コンポーネント

#### LegacyAutoCropクラス
```python
class LegacyAutoCrop:
    """境界形状検出ベースのAutoCropレガシー実装"""
    
    def __init__(self):
        # Singleton pattern + logger initialization
        
    def crop_image(self, pil_image: Image.Image) -> tuple[Image.Image, dict]:
        """
        境界形状検出によるクロップ
        
        Returns:
            tuple: (cropped_image, crop_info)
            crop_info: {
                "detected": bool,
                "method": "border_shape_detection", 
                "borders_found": list[str],
                "crop_ratio": float,
                "processing_time": float
            }
        """
        
    def _detect_border_shape(self, image: np.ndarray) -> list[str]:
        # 提供されたコードをそのまま使用
        
    def _borders_to_crop_box(self, img_shape: tuple, borders: list[str]) -> tuple[int, int, int, int]:
        """境界情報をクロップボックス(x, y, w, h)に変換"""
        height, width = img_shape[:2]
        
        # デフォルト: 全体
        x, y, w, h = 0, 0, width, height
        
        # 境界に応じてクロップ領域を調整
        border_margin = min(width, height) // 20  # 5%のマージン
        
        if "TOP" in borders:
            y += border_margin
            h -= border_margin
        if "BOTTOM" in borders:
            h -= border_margin
        if "LEFT" in borders:
            x += border_margin
            w -= border_margin
        if "RIGHT" in borders:
            w -= border_margin
            
        return (x, y, w, h)
```

#### 拡張されたテスト関数
```python
def apply_three_autocrop_methods(img: Image.Image, params_opt: dict, params_leg: dict) -> tuple:
    """3つのAutoCrop手法を適用"""
    
    # 1. Current Optimized (補色差分・最適化パラメータ)
    opt_result, opt_info = apply_autocrop_with_params(img, params_opt)
    opt_info["method"] = "complementary_diff_optimized"
    
    # 2. Current Legacy (補色差分・固定パラメータ)
    leg_result, leg_info = apply_autocrop_with_params(img, params_leg)  
    leg_info["method"] = "complementary_diff_legacy"
    
    # 3. True Legacy (境界形状検出)
    legacy_autocrop = LegacyAutoCrop()
    true_leg_result, true_leg_info = legacy_autocrop.crop_image(img)
    
    return (opt_result, opt_info), (leg_result, leg_info), (true_leg_result, true_leg_info)

def create_three_method_comparison_image(
    original: Image.Image, 
    results: tuple, 
    test_name: str
) -> Image.Image:
    """3手法の比較画像を作成"""
    
    opt_result, opt_info = results[0]
    leg_result, leg_info = results[1] 
    true_leg_result, true_leg_info = results[2]
    
    # 4画像レイアウト: Original | Optimized | Legacy | True Legacy
    # ラベル情報も詳細化
```

### 依存関係の追加
```python
import scipy.ndimage  # エッジ強度計算用
from typing import Optional  # 型ヒント用
import time  # パフォーマンス計測用
```

## 📝 詳細実装計画

### Phase 1: Core Implementation (1-2時間)

#### Task 1.1: LegacyAutoCropクラス基盤 (30分)
```python
# ファイル: scripts/legacy_autocrop.py (新規作成)
class LegacyAutoCrop:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LegacyAutoCrop, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance
    
    def _initialize(self):
        # logger設定は簡略化（print使用）
        pass
    
    # 提供されたメソッドをすべて統合
    @staticmethod
    def _convert_to_gray(image: np.ndarray) -> np.ndarray:
        # 提供されたコードそのまま
        
    @staticmethod  
    def _calculate_edge_strength(gray_image: np.ndarray) -> np.ndarray:
        # 提供されたコードそのまま
        
    # ... 他のメソッドも同様
```

#### Task 1.2: 境界検出→クロップ変換 (45分)
```python
def _borders_to_crop_box(self, img_shape: tuple, borders: list[str]) -> tuple[int, int, int, int]:
    """
    境界リストをクロップボックスに変換
    
    Args:
        img_shape: (height, width, channels)
        borders: ["TOP", "BOTTOM", "LEFT", "RIGHT"] の組み合わせ
        
    Returns:
        (x, y, width, height): クロップボックス
    """
    height, width = img_shape[:2]
    
    # 初期値: 全体の画像
    crop_x, crop_y = 0, 0
    crop_width, crop_height = width, height
    
    # 境界サイズの計算（画像サイズの5%）
    vertical_margin = height // 20
    horizontal_margin = width // 20
    
    # 各境界に応じてクロップ領域を調整
    if "TOP" in borders:
        crop_y += vertical_margin
        crop_height -= vertical_margin
        
    if "BOTTOM" in borders:
        crop_height -= vertical_margin
        
    if "LEFT" in borders:
        crop_x += horizontal_margin
        crop_width -= horizontal_margin
        
    if "RIGHT" in borders:
        crop_width -= horizontal_margin
    
    # 最小サイズの保証
    min_size = min(width, height) // 10
    crop_width = max(crop_width, min_size)
    crop_height = max(crop_height, min_size)
    
    return (crop_x, crop_y, crop_width, crop_height)

def crop_image(self, pil_image: Image.Image) -> tuple[Image.Image, dict]:
    """境界形状検出によるクロップ"""
    start_time = time.time()
    
    # NumPy配列に変換
    np_image = np.array(pil_image)
    
    # 境界形状検出
    detected_borders = self._detect_border_shape(np_image)
    
    # クロップ実行
    if detected_borders:
        crop_box = self._borders_to_crop_box(np_image.shape, detected_borders)
        x, y, w, h = crop_box
        cropped_img = pil_image.crop((x, y, x + w, y + h))
        
        crop_info = {
            "detected": True,
            "method": "border_shape_detection",
            "borders_found": detected_borders,
            "original_size": pil_image.size,
            "crop_box": crop_box,
            "cropped_size": cropped_img.size,
            "crop_ratio": (w * h) / (pil_image.size[0] * pil_image.size[1]),
            "processing_time": time.time() - start_time
        }
    else:
        cropped_img = pil_image.copy()
        crop_info = {
            "detected": False,
            "method": "border_shape_detection", 
            "borders_found": [],
            "original_size": pil_image.size,
            "crop_box": None,
            "cropped_size": pil_image.size,
            "crop_ratio": 1.0,
            "processing_time": time.time() - start_time
        }
    
    return cropped_img, crop_info
```

#### Task 1.3: テストスクリプト統合 (45分)
```python
# ファイル: scripts/test_autocrop_effectiveness.py (修正)

# インポート追加
from legacy_autocrop import LegacyAutoCrop
import scipy.ndimage
import time

# 3手法適用関数
def apply_three_autocrop_methods(img: Image.Image, params_opt: dict, params_leg: dict) -> tuple:
    """3つのAutoCrop手法を適用"""
    results = []
    
    # 1. Current Optimized
    start_time = time.time()
    opt_result, opt_info = apply_autocrop_with_params(img, params_opt)
    opt_info["method"] = "complementary_diff_optimized"
    opt_info["processing_time"] = time.time() - start_time
    results.append((opt_result, opt_info))
    
    # 2. Current Legacy  
    start_time = time.time()
    leg_result, leg_info = apply_autocrop_with_params(img, params_leg)
    leg_info["method"] = "complementary_diff_legacy"
    leg_info["processing_time"] = time.time() - start_time
    results.append((leg_result, leg_info))
    
    # 3. True Legacy
    legacy_autocrop = LegacyAutoCrop()
    true_leg_result, true_leg_info = legacy_autocrop.crop_image(img)
    results.append((true_leg_result, true_leg_info))
    
    return tuple(results)

# 比較画像生成拡張
def create_four_method_comparison_image(
    original: Image.Image,
    results: tuple,
    test_name: str
) -> Image.Image:
    """4画像の比較画像を作成（オリジナル + 3手法）"""
    
    opt_result, opt_info = results[0]
    leg_result, leg_info = results[1]
    true_leg_result, true_leg_info = results[2]
    
    # 最大サイズ決定
    all_images = [original, opt_result, leg_result, true_leg_result]
    max_width = max(img.size[0] for img in all_images)
    max_height = max(img.size[1] for img in all_images)
    target_size = (max_width, max_height)
    
    # パディング関数
    def pad_image(img: Image.Image, target_size: tuple[int, int]) -> Image.Image:
        new_img = Image.new("RGB", target_size, (240, 240, 240))
        x_offset = (target_size[0] - img.size[0]) // 2
        y_offset = (target_size[1] - img.size[1]) // 2
        new_img.paste(img, (x_offset, y_offset))
        return new_img
    
    # 画像パディング
    padded_images = [pad_image(img, target_size) for img in all_images]
    
    # 比較画像作成（横4列レイアウト）
    text_height = 140
    comparison_width = max_width * 4 + 30  # 余白
    comparison_height = max_height + text_height
    
    comparison = Image.new("RGB", (comparison_width, comparison_height), (255, 255, 255))
    
    # 画像配置
    for i, padded_img in enumerate(padded_images):
        x_pos = i * max_width + (i * 10)  # 10px間隔
        comparison.paste(padded_img, (x_pos, text_height))
    
    # テキスト描画
    draw = ImageDraw.Draw(comparison)
    try:
        font = ImageFont.load_default()
    except:
        font = None
    
    # タイトル
    title = f"AutoCrop 3-Method Comparison: {test_name}"
    draw.text((10, 10), title, fill=(0, 0, 0), font=font)
    
    # 各画像のラベル
    labels = [
        f"Original\\n{original.size[0]}x{original.size[1]}",
        f"Optimized\\n{opt_info['cropped_size'][0]}x{opt_info['cropped_size'][1]}\\nRatio: {opt_info['crop_ratio']:.3f}\\nTime: {opt_info['processing_time']:.3f}s",
        f"Legacy\\n{leg_info['cropped_size'][0]}x{leg_info['cropped_size'][1]}\\nRatio: {leg_info['crop_ratio']:.3f}\\nTime: {leg_info['processing_time']:.3f}s",
        f"Border Detection\\n{true_leg_info['cropped_size'][0]}x{true_leg_info['cropped_size'][1]}\\nRatio: {true_leg_info['crop_ratio']:.3f}\\nTime: {true_leg_info['processing_time']:.3f}s\\nBorders: {', '.join(true_leg_info['borders_found']) if true_leg_info['borders_found'] else 'None'}"
    ]
    
    x_positions = [10 + i * (max_width + 10) for i in range(4)]
    for label, x_pos in zip(labels, x_positions):
        draw.text((x_pos, 50), label, fill=(0, 0, 0), font=font)
    
    return comparison
```

### Phase 2: Integration & Testing (1時間)

#### Task 2.1: メイン処理の修正 (30分)
```python
# main()関数の修正
def main():
    print("=== AutoCrop 3手法比較スクリプト ===")
    
    output_dir = Path("autocrop_test_results")
    output_dir.mkdir(exist_ok=True)
    
    # テストケース（既存のまま）
    test_cases = [...]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\\n{i}. テストケース: {test_case['name']}")
        
        # テスト画像作成（既存のまま）
        test_img = create_test_image_with_border(...)
        
        # パラメータ生成（既存のまま）
        legacy_params = create_legacy_autocrop_params(test_img.size, mean_brightness)
        optimized_params = create_optimized_autocrop_params(test_img.size, mean_brightness)
        
        print(f"   Testing 3 methods:")
        print(f"   - Optimized params: {optimized_params}")
        print(f"   - Legacy params: {legacy_params}")
        print(f"   - Border detection: adaptive")
        
        try:
            # 3手法適用
            three_results = apply_three_autocrop_methods(test_img, optimized_params, legacy_params)
            
            # 比較画像作成
            comparison_img = create_four_method_comparison_image(test_img, three_results, test_case['name'])
            
            # ファイル保存
            output_path = output_dir / f"{test_case['name']}_three_methods_comparison.png"
            comparison_img.save(output_path)
            
            # 結果出力
            opt_info, leg_info, true_leg_info = [result[1] for result in three_results]
            print(f"   Optimized: 検出={opt_info['detected']}, ratio={opt_info['crop_ratio']:.3f}, time={opt_info['processing_time']:.3f}s")
            print(f"   Legacy: 検出={leg_info['detected']}, ratio={leg_info['crop_ratio']:.3f}, time={leg_info['processing_time']:.3f}s")
            print(f"   Border Detection: 検出={true_leg_info['detected']}, ratio={true_leg_info['crop_ratio']:.3f}, time={true_leg_info['processing_time']:.3f}s, borders={true_leg_info['borders_found']}")
            print(f"   比較画像保存: {output_path}")
            
            # 結果記録
            results.append({
                "test_case": test_case['name'],
                "image_size": test_img.size,
                "mean_brightness": mean_brightness,
                "optimized": opt_info,
                "legacy": leg_info, 
                "border_detection": true_leg_info
            })
            
        except Exception as e:
            print(f"   エラー: {e}")
            continue
    
    # 実画像テストも3手法対応で修正
    real_results = test_real_images_three_methods(output_dir)
    
    # 結果サマリー（3手法対応）
    print_three_method_summary(results, real_results)
```

#### Task 2.2: 実画像テスト拡張 (30分)
```python
def test_real_images_three_methods(output_dir: Path) -> list:
    """実画像での3手法テスト"""
    print("\\n=== 実画像 3手法テスト ===")
    
    test_img_dir = Path("tests/resources/img/bordercrop")
    if not test_img_dir.exists():
        print(f"テスト画像ディレクトリが見つかりません: {test_img_dir}")
        return []
    
    real_results = []
    image_files = list(test_img_dir.glob("*.png")) + list(test_img_dir.glob("*.jpg")) + list(test_img_dir.glob("*.jpeg"))
    
    for img_file in sorted(image_files):
        print(f"\\n実画像 3手法テスト: {img_file.name}")
        
        try:
            test_img = Image.open(img_file)
            if test_img.mode != "RGB":
                test_img = test_img.convert("RGB")
            
            img_array = np.array(test_img)
            mean_brightness = np.mean(cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY))
            
            print(f"   画像サイズ: {test_img.size}, 平均明度: {mean_brightness:.1f}")
            
            # パラメータ生成
            legacy_params = create_legacy_autocrop_params(test_img.size, mean_brightness)
            optimized_params = create_optimized_autocrop_params(test_img.size, mean_brightness)
            
            # 3手法適用
            three_results = apply_three_autocrop_methods(test_img, optimized_params, legacy_params)
            
            # 比較画像作成
            comparison_img = create_four_method_comparison_image(test_img, three_results, f"Real_{img_file.stem}")
            
            # ファイル保存
            output_path = output_dir / f"Real_{img_file.stem}_three_methods_comparison.png"
            comparison_img.save(output_path)
            
            # 結果記録
            opt_info, leg_info, true_leg_info = [result[1] for result in three_results]
            
            real_results.append({
                "test_case": f"Real_{img_file.stem}",
                "source_file": str(img_file),
                "image_size": test_img.size,
                "mean_brightness": mean_brightness,
                "optimized": opt_info,
                "legacy": leg_info,
                "border_detection": true_leg_info
            })
            
            print(f"   比較画像保存: {output_path}")
            
        except Exception as e:
            print(f"   エラー: {e}")
            continue
    
    return real_results

def print_three_method_summary(results: list, real_results: list):
    """3手法の結果サマリーを出力"""
    print("\\n=== 3手法比較結果サマリー ===")
    
    if results:
        print("\\n--- 合成画像テスト ---")
        for result in results:
            print(f"\\n{result['test_case']}:")
            print(f"  画像サイズ: {result['image_size']}")
            print(f"  Optimized: 検出={result['optimized']['detected']}, ratio={result['optimized']['crop_ratio']:.3f}, time={result['optimized']['processing_time']:.3f}s")
            print(f"  Legacy: 検出={result['legacy']['detected']}, ratio={result['legacy']['crop_ratio']:.3f}, time={result['legacy']['processing_time']:.3f}s")
            print(f"  Border Detection: 検出={result['border_detection']['detected']}, ratio={result['border_detection']['crop_ratio']:.3f}, time={result['border_detection']['processing_time']:.3f}s")
            print(f"  Detected Borders: {result['border_detection']['borders_found']}")
    
    if real_results:
        print("\\n--- 実画像テスト ---")
        for result in real_results:
            print(f"\\n{result['test_case']}:")
            print(f"  ソース: {Path(result['source_file']).name}")
            print(f"  画像サイズ: {result['image_size']}")
            print(f"  Optimized: ratio={result['optimized']['crop_ratio']:.3f}, time={result['optimized']['processing_time']:.3f}s")
            print(f"  Legacy: ratio={result['legacy']['crop_ratio']:.3f}, time={result['legacy']['processing_time']:.3f}s")
            print(f"  Border Detection: ratio={result['border_detection']['crop_ratio']:.3f}, time={result['border_detection']['processing_time']:.3f}s")
            print(f"  Detected Borders: {result['border_detection']['borders_found']}")
    
    # パフォーマンス比較
    print("\\n--- パフォーマンス比較 ---")
    all_results = results + real_results
    if all_results:
        opt_times = [r['optimized']['processing_time'] for r in all_results]
        leg_times = [r['legacy']['processing_time'] for r in all_results]
        border_times = [r['border_detection']['processing_time'] for r in all_results]
        
        print(f"平均処理時間:")
        print(f"  Optimized: {sum(opt_times)/len(opt_times):.3f}s")
        print(f"  Legacy: {sum(leg_times)/len(leg_times):.3f}s")
        print(f"  Border Detection: {sum(border_times)/len(border_times):.3f}s")
    
    print(f"\\nテスト完了: 合成画像 {len(results)} 件, 実画像 {len(real_results)} 件")
    print("3手法の比較により、AutoCropアルゴリズムの特性差を確認できます。")
```

### Phase 3: Enhancement (30分)

#### Task 3.1: エラーハンドリング強化
```python
# LegacyAutoCropクラスにエラーハンドリング追加
def _safe_detect_border_shape(self, image: np.ndarray) -> list[str]:
    """安全な境界形状検出（エラーハンドリング付き）"""
    try:
        return self._detect_border_shape(image)
    except Exception as e:
        print(f"Border detection error: {e}")
        return []  # 検出失敗時は空リスト

def _safe_borders_to_crop_box(self, img_shape: tuple, borders: list[str]) -> tuple[int, int, int, int]:
    """安全なクロップボックス変換（エラーハンドリング付き）"""
    try:
        if not borders:
            height, width = img_shape[:2]
            return (0, 0, width, height)  # 全体を返す
        return self._borders_to_crop_box(img_shape, borders)
    except Exception as e:
        print(f"Crop box conversion error: {e}")
        height, width = img_shape[:2]
        return (0, 0, width, height)  # エラー時は全体を返す
```

#### Task 3.2: 依存関係管理
```python
# scripts/test_autocrop_effectiveness.py の先頭に依存関係チェック追加
def check_dependencies():
    """必要な依存関係をチェック"""
    try:
        import scipy.ndimage
        print("✓ scipy.ndimage available")
    except ImportError:
        print("✗ scipy.ndimage not found. Run: uv add scipy")
        return False
    
    try:
        import cv2
        print("✓ opencv-python available")
    except ImportError:
        print("✗ opencv-python not found. Run: uv add opencv-python")
        return False
    
    return True

# main()の先頭で実行
def main():
    if not check_dependencies():
        print("Required dependencies missing. Please install them first.")
        return
    
    print("=== AutoCrop 3手法比較スクリプト ===")
    # 以下、既存の処理...
```

## 📊 期待される結果

### 合成画像での予想結果
```
Small_Gradient (200x200):
  Optimized: ratio=0.504, time=0.120s
  Legacy: ratio=0.570, time=0.115s  
  Border Detection: ratio=0.640, time=0.095s, borders=['TOP', 'BOTTOM', 'LEFT', 'RIGHT']

Medium_Pattern (400x400):
  Optimized: ratio=0.597, time=0.145s
  Legacy: ratio=0.605, time=0.140s
  Border Detection: ratio=0.680, time=0.110s, borders=['TOP', 'BOTTOM', 'LEFT', 'RIGHT']
```

### 実画像での予想結果
```
Real_image_0001 (レターボックス):
  Optimized: ratio=0.001, time=0.250s  # 補色差分では検出失敗
  Legacy: ratio=0.001, time=0.245s     # 補色差分では検出失敗
  Border Detection: ratio=0.750, time=0.180s, borders=['TOP', 'BOTTOM']  # 上下黒帯検出

Real_image_0006 (ゲーム画面):
  Optimized: ratio=0.002, time=0.180s  # 補色差分では検出失敗
  Legacy: ratio=0.003, time=0.175s     # 補色差分では検出失敗
  Border Detection: ratio=1.000, time=0.150s, borders=[]  # 境界なし
```

### 手法特性の明確化
1. **補色差分ベース**: 合成画像では動作するが、実画像では機能不全
2. **境界形状検出ベース**: レターボックス検出に優れ、実画像に適応的

## 🚀 実装優先度

### 高優先度 (必須)
- [x] LegacyAutoCropクラス実装
- [x] 境界検出→クロップ変換ロジック
- [x] 3手法統合テスト関数
- [x] 4画像比較画像生成

### 中優先度 (推奨)
- [x] パフォーマンス計測
- [x] エラーハンドリング強化
- [x] 詳細結果サマリー

### 低優先度 (オプション)
- [ ] CSV/JSON結果出力
- [ ] 統計的分析レポート
- [ ] 設定可能なパラメータ

## 🔧 実装完了基準

### 機能要件
- [ ] 3つの異なる手法が同一画像で実行可能
- [ ] 境界形状検出が実際のクロップに反映される
- [ ] 実画像でのレターボックス検出が改善される
- [ ] パフォーマンス差が定量的に計測される

### 品質要件
- [ ] 全てのテストケースでエラーなく実行
- [ ] メモリ使用量が合理的範囲内
- [ ] 比較画像が視覚的に分かりやすい
- [ ] 結果サマリーが包括的

## 📈 成功評価指標

### 定量的指標
1. **実画像レターボックス検出率**: Border Detection > 50% vs Others < 5%
2. **処理時間比較**: Border Detection < Complementary Diff (軽量処理)
3. **適応性評価**: 画像タイプ別での各手法の性能差

### 定性的指標
1. **視覚的分かりやすさ**: 3手法の違いが一目で理解可能
2. **実用性評価**: 実画像での各手法の適用可能性が明確
3. **開発効率**: 今後のAutoCrop改善方針の決定に寄与

## 📋 次ステップ

1. **Phase 1実装**: LegacyAutoCropクラスと基本統合
2. **Phase 2実装**: テストスクリプト拡張と比較画像強化
3. **Phase 3実装**: エラーハンドリングとパフォーマンス計測
4. **結果検証**: 実画像での3手法の特性確認
5. **改善方針決定**: 最適な手法の選択と今後の開発方針策定

---

**プラン完了時刻:** 2025/07/13 07:05  
**推定実装時間:** 2-3時間  
**実装優先度:** 高（AutoCrop改善の基盤となる重要な比較検証）  

**次コマンド:** `@implement LegacyAutoCrop統合による3手法比較実装`