#!/usr/bin/env python3
"""
LoRAIro ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
tests/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ§‹é€ ãƒ»é‡è¤‡ãƒ»å“è³ªã‚’åˆ†æ
"""

import json
import subprocess
from pathlib import Path
from collections import defaultdict
import re

def count_lines(file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    try:
        with open(file_path) as f:
            return len(f.readlines())
    except Exception:
        return 0

def extract_test_names(file_path):
    """ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚¹ãƒˆé–¢æ•°åã‚’æŠ½å‡º"""
    tests = []
    try:
        with open(file_path) as f:
            content = f.read()
            # test_* é–¢æ•°ã‚’æŠ½å‡º
            pattern = r'def (test_\w+)\('
            tests = re.findall(pattern, content)
    except Exception:
        pass
    return tests

def analyze_directory_structure():
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’åˆ†æ"""
    test_root = Path("/workspaces/LoRAIro/tests")

    stats = {
        "total_test_files": 0,
        "total_tests": 0,
        "total_lines": 0,
        "by_directory": {},
        "test_names": defaultdict(list),
    }

    # conftest.py ã®ç¢ºèª
    conftest_files = list(test_root.rglob("conftest.py"))
    stats["conftest_locations"] = [str(f.relative_to(test_root)) for f in conftest_files]

    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    test_files = list(test_root.rglob("test_*.py"))
    stats["total_test_files"] = len(test_files)

    for test_file in test_files:
        rel_path = test_file.relative_to(test_root)
        directory = str(rel_path.parent)

        if directory not in stats["by_directory"]:
            stats["by_directory"][directory] = {
                "files": 0,
                "tests": 0,
                "lines": 0,
                "test_list": [],
            }

        lines = count_lines(test_file)
        tests = extract_test_names(test_file)

        stats["by_directory"][directory]["files"] += 1
        stats["by_directory"][directory]["tests"] += len(tests)
        stats["by_directory"][directory]["lines"] += lines
        stats["by_directory"][directory]["test_list"].append({
            "file": str(rel_path),
            "test_count": len(tests),
            "lines": lines,
            "tests": tests,
        })

        stats["total_tests"] += len(tests)
        stats["total_lines"] += lines

        # ãƒ†ã‚¹ãƒˆåã‚’è¨˜éŒ²ï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰
        for test_name in tests:
            stats["test_names"][test_name].append(str(rel_path))

    return stats

def detect_duplicates(stats):
    """é‡è¤‡ãƒ†ã‚¹ãƒˆã‚’æ¤œå‡º"""
    duplicates = []

    # åŒã˜åå‰ã®ãƒ†ã‚¹ãƒˆãŒè¤‡æ•°ç®‡æ‰€ã«å­˜åœ¨ã™ã‚‹å ´åˆ
    for test_name, locations in stats["test_names"].items():
        if len(locations) > 1:
            duplicates.append({
                "test_name": test_name,
                "locations": locations,
                "type": "same_name",
            })

    return duplicates

def analyze_fixtures(conftest_files):
    """ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã‚’åˆ†æ"""
    fixtures = {}

    for conftest_file in conftest_files:
        try:
            with open(conftest_file) as f:
                content = f.read()
                # @pytest.fixture ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’æ¤œå‡º
                pattern = r'@pytest\.fixture.*?\ndef (\w+)\('
                fixture_names = re.findall(pattern, content, re.DOTALL)
                fixtures[str(conftest_file)] = fixture_names
        except Exception:
            pass

    return fixtures

def run_pytest_collection():
    """pytest ã§å…¨ãƒ†ã‚¹ãƒˆã‚’åˆ—æŒ™"""
    try:
        result = subprocess.run(
            ["uv", "run", "pytest", "--collect-only", "-q"],
            cwd="/workspaces/LoRAIro",
            capture_output=True,
            text=True,
            timeout=30,
        )
        return result.stdout.strip()
    except Exception as e:
        return f"Error collecting tests: {e}"

def main():
    print("=" * 80)
    print("LoRAIro ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æ")
    print("=" * 80)

    # æ§‹é€ åˆ†æ
    print("\nğŸ“Š ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ åˆ†æä¸­...")
    stats = analyze_directory_structure()

    # é‡è¤‡æ¤œå‡º
    print("ğŸ” é‡è¤‡ãƒ†ã‚¹ãƒˆæ¤œå‡ºä¸­...")
    duplicates = detect_duplicates(stats)

    # ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£åˆ†æ
    print("ğŸ“ ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£åˆ†æä¸­...")
    conftest_files = [Path(p) for p in stats["conftest_locations"]]
    fixtures = analyze_fixtures(conftest_files)

    # pytest å®Ÿè¡Œ
    print("âš¡ pytest ãƒ†ã‚¹ãƒˆåˆ—æŒ™ä¸­...")
    pytest_output = run_pytest_collection()

    # çµæœå‡ºåŠ›
    print("\n" + "=" * 80)
    print("åˆ†æçµæœ")
    print("=" * 80)

    print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±:")
    print(f"  ç·ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_test_files']}")
    print(f"  ç·ãƒ†ã‚¹ãƒˆæ•°: {stats['total_tests']}")
    print(f"  ç·è¡Œæ•°: {stats['total_lines']}")
    print(f"  conftest.py æ•°: {len(conftest_files)}")

    print(f"\nğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ¥è©³ç´°:")
    for directory, dir_stats in sorted(stats["by_directory"].items()):
        print(f"\n  {directory}/")
        print(f"    ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {dir_stats['files']}")
        print(f"    ãƒ†ã‚¹ãƒˆæ•°: {dir_stats['tests']}")
        print(f"    ç·è¡Œæ•°: {dir_stats['lines']}")
        for test_file_info in dir_stats["test_list"]:
            print(f"      - {test_file_info['file']}: {test_file_info['test_count']}ä»¶")

    if duplicates:
        print(f"\nâš ï¸  é‡è¤‡ãƒ†ã‚¹ãƒˆæ¤œå‡º: {len(duplicates)}ä»¶")
        for dup in duplicates[:10]:
            print(f"    - {dup['test_name']}: {len(dup['locations'])}ç®‡æ‰€")
            for loc in dup['locations']:
                print(f"      - {loc}")

    if fixtures:
        print(f"\nğŸ”§ ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£å®šç¾©:")
        for conftest, fixture_list in fixtures.items():
            if fixture_list:
                print(f"  {conftest}:")
                for fixture in fixture_list:
                    print(f"    - {fixture}")

    print(f"\nğŸ“Š pytest åˆ—æŒ™çµæœï¼ˆå…ˆé ­20è¡Œï¼‰:")
    for line in pytest_output.split('\n')[:20]:
        if line.strip():
            print(f"  {line}")

    # JSON å‡ºåŠ›
    output_file = Path("/workspaces/LoRAIro/.serena/memories/test_analysis_results.json")
    output_file.parent.mkdir(parents=True, exist_ok=True)

    analysis_data = {
        "stats": stats,
        "duplicates": duplicates,
        "fixtures": fixtures,
        "pytest_collection": pytest_output[:1000],  # å…ˆé ­1000æ–‡å­—
    }

    with open(output_file, 'w') as f:
        json.dump(analysis_data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")

if __name__ == "__main__":
    main()
